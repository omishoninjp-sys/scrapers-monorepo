"""
å‚è§’ç¸½æœ¬èˆ–å•†å“çˆ¬èŸ² + Shopify ä¸Šæ¶å·¥å…· v2.2
v2.2: ç¼ºè²¨å•†å“è‡ªå‹•åˆªé™¤ï¼ˆå®˜ç¶²æ¶ˆå¤±æˆ–ç¼ºè²¨çš†åˆªé™¤ï¼‰
v2.1: ç¿»è­¯ä¿è­·æ©Ÿåˆ¶ã€æ—¥æ–‡å•†å“æƒæã€æ¸¬è©¦ç¿»è­¯
"""

from flask import Flask, jsonify, request
import requests
from bs4 import BeautifulSoup
import re
import json
import os
import time
from urllib.parse import urljoin
import math
import threading

app = Flask(__name__)

SHOPIFY_SHOP = ""
SHOPIFY_ACCESS_TOKEN = ""
BASE_URL = "https://www.bankaku.co.jp"
CATEGORY_URLS = [
    "https://www.bankaku.co.jp/shop/c/c1010/",
    "https://www.bankaku.co.jp/shop/c/c1020/",
]
MIN_COST_THRESHOLD = 1000
MAX_CONSECUTIVE_TRANSLATION_FAILURES = 3
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")

BROWSER_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8,zh-TW;q=0.7',
    'Referer': 'https://www.bankaku.co.jp/',
}
session = requests.Session()
session.headers.update(BROWSER_HEADERS)

scrape_status = {
    "running": False, "progress": 0, "total": 0, "current_product": "",
    "products": [], "errors": [], "uploaded": 0, "skipped": 0,
    "filtered_by_price": 0, "deleted": 0,
    "translation_failed": 0, "translation_stopped": False
}


def is_japanese_text(text):
    if not text: return False
    check = text.strip()
    if not check: return False
    jp = len(re.findall(r'[\u3040-\u309F\u30A0-\u30FF]', check))
    cn = len(re.findall(r'[\u4e00-\u9fff]', check))
    total = len(re.sub(r'[\s\d\W]', '', check))
    if total == 0: return False
    return jp > 0 and (jp / total > 0.3 or cn == 0)


def load_shopify_token():
    global SHOPIFY_ACCESS_TOKEN, SHOPIFY_SHOP
    env_token = os.environ.get('SHOPIFY_ACCESS_TOKEN', '')
    env_shop = os.environ.get('SHOPIFY_SHOP', '')
    if env_token and env_shop:
        SHOPIFY_ACCESS_TOKEN = env_token
        SHOPIFY_SHOP = env_shop.replace('https://','').replace('http://','').replace('.myshopify.com','').strip('/')
        return True
    tf = "shopify_token.json"
    if os.path.exists(tf):
        with open(tf, 'r') as f:
            d = json.load(f)
            SHOPIFY_ACCESS_TOKEN = d.get('access_token', '')
            s = d.get('shop', '')
            if s: SHOPIFY_SHOP = s.replace('https://','').replace('http://','').replace('.myshopify.com','').strip('/')
            return True
    return False


def get_shopify_headers():
    return {'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN, 'Content-Type': 'application/json'}


def shopify_api_url(endpoint):
    return f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/{endpoint}"


def calculate_selling_price(cost, weight):
    if not cost or cost <= 0: return 0
    return round((cost + (weight * 1250 if weight else 0)) / 0.7)


def translate_with_chatgpt(title, description):
    prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚ç¿»è­¯æˆç¹é«”ä¸­æ–‡ä¸¦å„ªåŒ– SEOã€‚

å•†å“åç¨±ï¼š{title}
å•†å“èªªæ˜ï¼š{description}

å›å‚³ JSONï¼ˆä¸åŠ  markdownï¼‰ï¼š
{{"title":"ç¿»è­¯åç¨±","description":"ç¿»è­¯èªªæ˜","page_title":"SEOæ¨™é¡Œ50-60å­—","meta_description":"SEOæè¿°100å­—å…§"}}

è¦å‰‡ï¼š1.å‚è§’ç¸½æœ¬èˆ–æµ·è€ç…é¤… 2.ã‚†ã‹ã‚Šå¯ä¿ç•™æˆ–è­¯ã€Œç·£ã€3.è‡ªç„¶æµæš¢ 4.å«é—œéµå­—ï¼šå‚è§’ç¸½æœ¬èˆ–ã€æ—¥æœ¬ã€æµ·è€ç…é¤…ã€ä¼´æ‰‹ç¦® 5.åªå›å‚³JSON"""
    try:
        r = requests.post("https://api.openai.com/v1/chat/completions",
            headers={"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"},
            json={"model": "gpt-4o-mini", "messages": [
                {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚"},
                {"role": "user", "content": prompt}], "temperature": 0, "max_tokens": 1000}, timeout=60)
        if r.status_code == 200:
            c = r.json()['choices'][0]['message']['content'].strip()
            if c.startswith('```'): c = c.split('\n', 1)[1]
            if c.endswith('```'): c = c.rsplit('```', 1)[0]
            t = json.loads(c.strip())
            return {'success': True, 'title': t.get('title', title), 'description': t.get('description', description),
                    'page_title': t.get('page_title', ''), 'meta_description': t.get('meta_description', '')}
        else:
            return {'success': False, 'error': f"HTTP {r.status_code}: {r.text[:200]}",
                    'title': title, 'description': description, 'page_title': '', 'meta_description': ''}
    except Exception as e:
        return {'success': False, 'error': str(e),
                'title': title, 'description': description, 'page_title': '', 'meta_description': ''}


def get_existing_skus():
    return set(get_existing_products_map().keys())


def get_existing_products_map():
    pm = {}
    url = shopify_api_url("products.json?limit=250")
    while url:
        r = requests.get(url, headers=get_shopify_headers())
        if r.status_code != 200: break
        for p in r.json().get('products', []):
            pid = p.get('id')
            for v in p.get('variants', []):
                sk = v.get('sku')
                if sk and pid: pm[sk] = pid
        lh = r.headers.get('Link', '')
        m = re.search(r'<([^>]+)>; rel="next"', lh)
        url = m.group(1) if m and 'rel="next"' in lh else None
    return pm


def get_collection_products_map(collection_id):
    pm = {}
    if not collection_id: return pm
    url = shopify_api_url(f"collections/{collection_id}/products.json?limit=250")
    while url:
        r = requests.get(url, headers=get_shopify_headers())
        if r.status_code != 200: break
        for p in r.json().get('products', []):
            pid = p.get('id')
            for v in p.get('variants', []):
                sk = v.get('sku')
                if sk and pid: pm[sk] = pid
        lh = r.headers.get('Link', '')
        m = re.search(r'<([^>]+)>; rel="next"', lh)
        url = m.group(1) if m and 'rel="next"' in lh else None
    return pm


def set_product_to_draft(pid):
    return requests.put(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers(),
        json={"product": {"id": pid, "status": "draft"}}).status_code == 200


def delete_product(pid):
    return requests.delete(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers()).status_code == 200


def update_product(pid, data):
    r = requests.put(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers(),
        json={"product": {"id": pid, **data}})
    return r.status_code == 200, r


def get_or_create_collection(ct="å‚è§’ç¸½æœ¬èˆ–"):
    r = requests.get(shopify_api_url(f'custom_collections.json?title={ct}'), headers=get_shopify_headers())
    if r.status_code == 200:
        for c in r.json().get('custom_collections', []):
            if c['title'] == ct: return c['id']
    r = requests.post(shopify_api_url('custom_collections.json'), headers=get_shopify_headers(),
        json={'custom_collection': {'title': ct, 'published': True}})
    if r.status_code == 201: return r.json()['custom_collection']['id']
    return None


def add_product_to_collection(pid, cid):
    return requests.post(shopify_api_url('collects.json'), headers=get_shopify_headers(),
        json={'collect': {'product_id': pid, 'collection_id': cid}}).status_code == 201


def publish_to_all_channels(pid):
    gu = f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/graphql.json"
    hd = {'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN, 'Content-Type': 'application/json'}
    r = requests.post(gu, headers=hd, json={'query': '{ publications(first:20){ edges{ node{ id name }}}}'})
    if r.status_code != 200: return False
    pubs = r.json().get('data', {}).get('publications', {}).get('edges', [])
    seen = set(); uq = []
    for p in pubs:
        if p['node']['name'] not in seen: seen.add(p['node']['name']); uq.append(p['node'])
    mut = """mutation publishablePublish($id:ID!,$input:[PublicationInput!]!){publishablePublish(id:$id,input:$input){userErrors{field message}}}"""
    requests.post(gu, headers=hd, json={'query': mut, 'variables': {"id": f"gid://shopify/Product/{pid}", "input": [{"publicationId": p['id']} for p in uq]}})
    return True


def parse_dimension_weight(soup):
    dimension = None; weight = None; text = soup.get_text()
    dm = re.search(r'ç¸¦\s*(\d+(?:\.\d+)?)\s*[Ã—xX]\s*æ¨ª\s*(\d+(?:\.\d+)?)\s*[Ã—xX]\s*é«˜ã•\s*(\d+(?:\.\d+)?)\s*cm', text)
    if dm:
        h, w, d = float(dm.group(1)), float(dm.group(2)), float(dm.group(3))
        dimension = {"h": h, "w": w, "d": d, "volume_weight": round((h * w * d) / 6000, 2)}
    wm = re.search(r'é‡é‡[ï¼š:]\s*(\d+(?:\.\d+)?)\s*(?:kg|g)', text, re.IGNORECASE)
    if wm:
        wv = float(wm.group(1)); unit = wm.group(0)
        weight = wv if 'kg' in unit.lower() else wv / 1000
    final = 0
    if dimension and weight: final = max(dimension['volume_weight'], weight)
    elif dimension: final = dimension['volume_weight']
    elif weight: final = weight
    else:
        cm = re.search(r'(\d+)æš', text)
        if cm: final = round((int(cm.group(1)) * 7 + 100) / 1000, 2)
    return {"dimension": dimension, "actual_weight": weight, "final_weight": round(final, 2)}


def scrape_product_list(category_urls):
    products = []; seen_skus = set()
    session.get(BASE_URL, timeout=30); time.sleep(0.5)
    for cat_url in category_urls:
        page = 1
        while page <= 10:
            url = cat_url if page == 1 else f"{cat_url.rstrip('/')}_p{page}/"
            try:
                r = session.get(url, timeout=30); r.encoding = 'utf-8'
                if r.status_code != 200: break
                if page > 1 and '_p' not in r.url: break
                soup = BeautifulSoup(r.text, 'html.parser')
                links = soup.find_all('a', href=re.compile(r'/shop/g/g[A-Za-z0-9]+/'))
                new_count = 0; seen_page = set()
                for link in links:
                    sm = re.search(r'/g/g([A-Za-z0-9]+)/', link.get('href', ''))
                    if sm:
                        sku = sm.group(1)
                        if sku in seen_page: continue
                        seen_page.add(sku)
                        if sku not in seen_skus:
                            products.append({'url': urljoin(BASE_URL, link.get('href','')), 'sku': sku})
                            seen_skus.add(sku); new_count += 1
                if new_count == 0: break
                page += 1; time.sleep(0.5)
            except: break
    return products


def scrape_product_detail(url):
    try:
        r = session.get(url, timeout=30); r.encoding = 'utf-8'
        if r.status_code != 200: return None
        soup = BeautifulSoup(r.text, 'html.parser')
        title = ""
        h1 = soup.select_one('h1')
        if h1: title = h1.get_text(strip=True)
        if not title:
            tt = soup.select_one('title')
            if tt: title = tt.get_text(strip=True).split(':')[0].split('|')[0].strip()
        desc = ""
        for sel in ['.block-goods-comment', '.item-description', '.product-description']:
            de = soup.select_one(sel)
            if de: desc = de.get_text(strip=True); break
        if not desc and h1:
            ne = h1.find_next_sibling()
            if ne: desc = ne.get_text(strip=True)[:200]
        price = 0; pt = soup.get_text()
        pm = re.search(r'([\d,]+)å††\s*\(?ç¨è¾¼\)?', pt)
        if pm: price = int(pm.group(1).replace(',', ''))
        sku = ""; um = re.search(r'/g/g([A-Za-z0-9]+)/', url)
        if um: sku = um.group(1)
        in_stock = not any(k in pt for k in ['åœ¨åº«ãŒã‚ã‚Šã¾ã›ã‚“', 'åœ¨åº«åˆ‡ã‚Œ', 'å“åˆ‡ã‚Œ', 'SOLD OUT'])
        wi = parse_dimension_weight(soup)
        images = []; seen = set()
        for il in soup.select('a[href*="/img/goods/"]'):
            href = il.get('href', '')
            if href and '/img/goods/' in href:
                fs = urljoin(BASE_URL, href)
                if fs not in seen: seen.add(fs); images.append(fs)
        if not images:
            for img in soup.select('img[src*="/img/goods/"]'):
                src = img.get('src', '')
                if src and '/img/goods/' in src and 'lazyload' not in src:
                    fs = urljoin(BASE_URL, src)
                    if fs not in seen: seen.add(fs); images.append(fs)
        return {'url': url, 'sku': sku, 'title': title, 'price': price, 'in_stock': in_stock,
                'description': desc, 'weight': wi['final_weight'], 'weight_info': wi, 'images': images[:10]}
    except Exception as e:
        print(f"[éŒ¯èª¤] {url}: {e}"); return None


def upload_to_shopify(product, collection_id=None):
    translated = translate_with_chatgpt(product['title'], product.get('description', ''))
    if not translated['success']:
        return {'success': False, 'error': 'translation_failed', 'translated': translated}
    cost = product['price']; weight = product.get('weight', 0)
    selling_price = calculate_selling_price(cost, weight)
    images = [{'src': u, 'position': i+1} for i, u in enumerate(product.get('images', []))]
    sp = {'product': {
        'title': translated['title'], 'body_html': translated['description'],
        'vendor': 'å‚è§’ç¸½æœ¬èˆ–', 'product_type': 'æµ·è€ç…é¤…',
        'status': 'active', 'published': True,
        'variants': [{'sku': product['sku'], 'price': f"{selling_price:.2f}", 'weight': weight,
            'weight_unit': 'kg', 'inventory_management': None, 'inventory_policy': 'continue', 'requires_shipping': True}],
        'images': images, 'tags': 'å‚è§’ç¸½æœ¬èˆ–, æ—¥æœ¬, æµ·è€ç…é¤…, ãˆã³ã›ã‚“ã¹ã„, ã‚†ã‹ã‚Š, ä¼´æ‰‹ç¦®, æ—¥æœ¬é›¶é£Ÿ',
        'metafields_global_title_tag': translated['page_title'],
        'metafields_global_description_tag': translated['meta_description'],
        'metafields': [{'namespace': 'custom', 'key': 'link', 'value': product['url'], 'type': 'url'}]
    }}
    r = requests.post(shopify_api_url('products.json'), headers=get_shopify_headers(), json=sp)
    if r.status_code == 201:
        cp = r.json()['product']; pid = cp['id']; vid = cp['variants'][0]['id']
        requests.put(shopify_api_url(f'variants/{vid}.json'), headers=get_shopify_headers(),
            json={'variant': {'id': vid, 'cost': f"{cost:.2f}"}})
        if collection_id: add_product_to_collection(pid, collection_id)
        publish_to_all_channels(pid)
        return {'success': True, 'product': cp, 'translated': translated, 'selling_price': selling_price, 'cost': cost}
    return {'success': False, 'error': r.text}


def run_scrape():
    global scrape_status
    try:
        scrape_status.update({"running": True, "progress": 0, "total": 0, "current_product": "",
            "products": [], "errors": [], "uploaded": 0, "skipped": 0,
            "filtered_by_price": 0, "deleted": 0,
            "translation_failed": 0, "translation_stopped": False})
        scrape_status['current_product'] = "æª¢æŸ¥ Shopify å•†å“..."
        existing_skus = get_existing_skus()
        scrape_status['current_product'] = "è¨­å®š Collection..."
        collection_id = get_or_create_collection("å‚è§’ç¸½æœ¬èˆ–")
        scrape_status['current_product'] = "å–å¾— Collection å•†å“..."
        cpm = get_collection_products_map(collection_id)
        collection_skus = set(cpm.keys())
        scrape_status['current_product'] = "çˆ¬å–å•†å“åˆ—è¡¨..."
        product_list = scrape_product_list(CATEGORY_URLS)
        scrape_status['total'] = len(product_list)
        website_skus = set(item['sku'] for item in product_list)

        # === v2.2: è¨˜éŒ„ç¼ºè²¨çš„ SKU ===
        out_of_stock_skus = set()

        ctf = 0
        for idx, item in enumerate(product_list):
            scrape_status['progress'] = idx + 1
            scrape_status['current_product'] = f"è™•ç†: {item['sku']}"

            # å·²å­˜åœ¨æ–¼ Shopify â†’ éœ€è¦æª¢æŸ¥åº«å­˜ç‹€æ…‹
            if item['sku'] in existing_skus:
                # å¦‚æœé€™å€‹ SKU ä¹Ÿåœ¨ collection è£¡ï¼Œçˆ¬è©³æƒ…ç¢ºèªæ˜¯å¦ç¼ºè²¨
                if item['sku'] in collection_skus:
                    product = scrape_product_detail(item['url'])
                    if product and not product['in_stock']:
                        out_of_stock_skus.add(item['sku'])
                    time.sleep(0.5)
                scrape_status['skipped'] += 1
                continue

            product = scrape_product_detail(item['url'])
            if not product: scrape_status['errors'].append(f"ç„¡æ³•çˆ¬å–: {item['url']}"); continue
            if product['price'] < MIN_COST_THRESHOLD: scrape_status['filtered_by_price'] += 1; continue

            # ç¼ºè²¨ â†’ ä¸ä¸Šæ¶ï¼Œè¨˜éŒ„ SKU
            if not product['in_stock']:
                out_of_stock_skus.add(item['sku'])
                scrape_status['skipped'] += 1
                continue

            result = upload_to_shopify(product, collection_id)
            if result['success']:
                existing_skus.add(product['sku']); scrape_status['uploaded'] += 1; ctf = 0
            elif result.get('error') == 'translation_failed':
                scrape_status['translation_failed'] += 1; ctf += 1
                if ctf >= MAX_CONSECUTIVE_TRANSLATION_FAILURES:
                    scrape_status['translation_stopped'] = True
                    scrape_status['errors'].append(f'ç¿»è­¯é€£çºŒå¤±æ•— {ctf} æ¬¡ï¼Œè‡ªå‹•åœæ­¢'); break
            else:
                scrape_status['errors'].append(f"ä¸Šå‚³å¤±æ•— {product['sku']}"); ctf = 0
            time.sleep(1)

        if not scrape_status['translation_stopped']:
            scrape_status['current_product'] = "æ¸…ç†ç¼ºè²¨/ä¸‹æ¶å•†å“..."

            # === v2.2: åˆä½µéœ€è¦åˆªé™¤çš„ SKU ===
            # 1. å®˜ç¶²å·²æ¶ˆå¤±çš„ SKUï¼ˆcollection æœ‰ä½†å®˜ç¶²æ²’æœ‰ï¼‰
            # 2. å®˜ç¶²é‚„åœ¨ä½†ç¼ºè²¨çš„ SKU
            skus_to_delete = (collection_skus - website_skus) | (collection_skus & out_of_stock_skus)

            for sku in skus_to_delete:
                pid = cpm.get(sku)
                if pid:
                    if delete_product(pid):
                        scrape_status['deleted'] += 1
                    else:
                        scrape_status['errors'].append(f"åˆªé™¤å¤±æ•—: {sku}")
                time.sleep(0.3)

        scrape_status['current_product'] = "å®Œæˆ" if not scrape_status['translation_stopped'] else "ç¿»è­¯ç•°å¸¸åœæ­¢"
    except Exception as e:
        scrape_status['errors'].append(str(e))
    finally:
        scrape_status['running'] = False


# ========== Flask è·¯ç”± ==========

@app.route('/')
def index():
    token_loaded = load_shopify_token()
    tc = 'green' if token_loaded else 'red'
    ts = 'âœ“ å·²è¼‰å…¥' if token_loaded else 'âœ— æœªè¨­å®š'
    html = """<!DOCTYPE html>
<html lang="zh-TW">
<head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>å‚è§’ç¸½æœ¬èˆ– çˆ¬èŸ²å·¥å…·</title>
<style>*{box-sizing:border-box}body{font-family:-apple-system,sans-serif;max-width:900px;margin:0 auto;padding:20px;background:#f5f5f5}h1{color:#333;border-bottom:2px solid #D4AF37;padding-bottom:10px}.card{background:white;border-radius:8px;padding:20px;margin-bottom:20px;box-shadow:0 2px 4px rgba(0,0,0,0.1)}.btn{background:#D4AF37;color:white;border:none;padding:12px 24px;border-radius:5px;cursor:pointer;font-size:16px;margin-right:10px;margin-bottom:10px;text-decoration:none;display:inline-block}.btn:hover{background:#B8972E}.btn:disabled{background:#ccc}.btn-secondary{background:#3498db}.btn-success{background:#27ae60}.progress-bar{width:100%;height:20px;background:#eee;border-radius:10px;overflow:hidden;margin:10px 0}.progress-fill{height:100%;background:linear-gradient(90deg,#D4AF37,#F0D078);transition:width 0.3s}.status{padding:10px;background:#f8f9fa;border-radius:5px;margin-top:10px}.log{max-height:300px;overflow-y:auto;font-family:monospace;font-size:13px;background:#1e1e1e;color:#d4d4d4;padding:15px;border-radius:5px}.stats{display:flex;gap:15px;margin-top:15px;flex-wrap:wrap}.stat{flex:1;min-width:70px;text-align:center;padding:15px;background:#f8f9fa;border-radius:5px}.stat-number{font-size:24px;font-weight:bold;color:#D4AF37}.stat-label{font-size:10px;color:#666;margin-top:5px}.nav{margin-bottom:20px}.nav a{margin-right:15px;color:#D4AF37;text-decoration:none;font-weight:bold}.alert{padding:12px 16px;border-radius:5px;margin-bottom:15px}.alert-danger{background:#fee;border:1px solid #fcc;color:#c0392b}</style></head>
<body>
<div class="nav"><a href="/">ğŸ  é¦–é </a><a href="/japanese-scan">ğŸ‡¯ğŸ‡µ æ—¥æ–‡æƒæ</a></div>
<h1>ğŸ¦ å‚è§’ç¸½æœ¬èˆ– çˆ¬èŸ²å·¥å…· <small style="font-size:14px;color:#999">v2.2</small></h1>
<div class="card"><h3>Shopify é€£ç·š</h3><p>Token: <span style="color:__TC__;">__TS__</span></p>
<button class="btn btn-secondary" onclick="testShopify()">æ¸¬è©¦é€£ç·š</button>
<button class="btn btn-secondary" onclick="testTranslate()">æ¸¬è©¦ç¿»è­¯</button>
<a href="/japanese-scan" class="btn btn-success">ğŸ‡¯ğŸ‡µ æ—¥æ–‡æƒæ</a></div>
<div class="card"><h3>é–‹å§‹çˆ¬å–</h3>
<p>çˆ¬å– bankaku.co.jp å…¨ç«™å•†å“ä¸¦ä¸Šæ¶åˆ° Shopify</p>
<p style="color:#666;font-size:14px">â€» &lt;Â¥__MIN_COST__ è·³é | <b style="color:#e74c3c">ç¿»è­¯ä¿è­·</b> é€£çºŒå¤±æ•— __MAX_FAIL__ æ¬¡åœæ­¢ | <b style="color:#e67e22">ç¼ºè²¨è‡ªå‹•åˆªé™¤</b></p>
<button class="btn" id="startBtn" onclick="startScrape()">ğŸš€ é–‹å§‹çˆ¬å–</button>
<div id="progressSection" style="display:none">
<div id="translationAlert" class="alert alert-danger" style="display:none">âš ï¸ ç¿»è­¯åŠŸèƒ½ç•°å¸¸ï¼Œå·²è‡ªå‹•åœæ­¢ï¼</div>
<div class="progress-bar"><div class="progress-fill" id="progressFill" style="width:0%"></div></div>
<div class="status" id="statusText">æº–å‚™ä¸­...</div>
<div class="stats">
<div class="stat"><div class="stat-number" id="uploadedCount">0</div><div class="stat-label">å·²ä¸Šæ¶</div></div>
<div class="stat"><div class="stat-number" id="skippedCount">0</div><div class="stat-label">å·²è·³é</div></div>
<div class="stat"><div class="stat-number" id="translationFailedCount" style="color:#e74c3c">0</div><div class="stat-label">ç¿»è­¯å¤±æ•—</div></div>
<div class="stat"><div class="stat-number" id="filteredCount">0</div><div class="stat-label">åƒ¹æ ¼éæ¿¾</div></div>
<div class="stat"><div class="stat-number" id="deletedCount" style="color:#e67e22">0</div><div class="stat-label">å·²åˆªé™¤</div></div>
<div class="stat"><div class="stat-number" id="errorCount" style="color:#e74c3c">0</div><div class="stat-label">éŒ¯èª¤</div></div>
</div></div></div>
<div class="card"><h3>åŸ·è¡Œæ—¥èªŒ</h3><div class="log" id="logArea">ç­‰å¾…é–‹å§‹...</div></div>
<script>let pollInterval=null;function log(m,t){const l=document.getElementById('logArea');const tm=new Date().toLocaleTimeString();const c={success:'#4ec9b0',error:'#f14c4c'}[t]||'#d4d4d4';l.innerHTML+='<div style="color:'+c+'">['+tm+'] '+m+'</div>';l.scrollTop=l.scrollHeight}function clearLog(){document.getElementById('logArea').innerHTML=''}async function testShopify(){log('æ¸¬è©¦é€£ç·š...');try{const r=await fetch('/api/test-shopify');const d=await r.json();if(d.success)log('âœ“ '+d.shop.name,'success');else log('âœ— '+d.error,'error')}catch(e){log('âœ— '+e.message,'error')}}async function testTranslate(){log('æ¸¬è©¦ç¿»è­¯...');try{const r=await fetch('/api/test-translate');const d=await r.json();if(d.error)log('âœ— '+d.error,'error');else if(d.success)log('âœ“ '+d.title,'success');else log('âœ— ç¿»è­¯å¤±æ•—','error')}catch(e){log('âœ— '+e.message,'error')}}async function startScrape(){clearLog();log('é–‹å§‹çˆ¬å–...');document.getElementById('startBtn').disabled=true;document.getElementById('progressSection').style.display='block';document.getElementById('translationAlert').style.display='none';try{const r=await fetch('/api/start',{method:'POST'});const d=await r.json();if(d.error){log('âœ— '+d.error,'error');document.getElementById('startBtn').disabled=false;return}log('âœ“ å·²å•Ÿå‹•','success');pollInterval=setInterval(pollStatus,1000)}catch(e){log('âœ— '+e.message,'error');document.getElementById('startBtn').disabled=false}}async function pollStatus(){try{const r=await fetch('/api/status');const d=await r.json();const p=d.total>0?(d.progress/d.total*100):0;document.getElementById('progressFill').style.width=p+'%';document.getElementById('statusText').textContent=d.current_product+' ('+d.progress+'/'+d.total+')';document.getElementById('uploadedCount').textContent=d.uploaded;document.getElementById('skippedCount').textContent=d.skipped;document.getElementById('translationFailedCount').textContent=d.translation_failed||0;document.getElementById('filteredCount').textContent=d.filtered_by_price||0;document.getElementById('deletedCount').textContent=d.deleted||0;document.getElementById('errorCount').textContent=d.errors.length;if(d.translation_stopped)document.getElementById('translationAlert').style.display='block';if(!d.running&&d.progress>0){clearInterval(pollInterval);document.getElementById('startBtn').disabled=false;if(d.translation_stopped)log('âš ï¸ ç¿»è­¯ç•°å¸¸åœæ­¢','error');else log('========== å®Œæˆ ==========','success')}}catch(e){console.error(e)}}</script></body></html>"""
    return html.replace('__TC__', tc).replace('__TS__', ts).replace('__MIN_COST__', str(MIN_COST_THRESHOLD)).replace('__MAX_FAIL__', str(MAX_CONSECUTIVE_TRANSLATION_FAILURES))



@app.route('/japanese-scan')
def japanese_scan_page():
    return '''<!DOCTYPE html>
<html lang="zh-TW">
<head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>æ—¥æ–‡å•†å“æƒæ - å‚è§’ç¸½æœ¬èˆ–</title>
<style>*{box-sizing:border-box}body{font-family:-apple-system,BlinkMacSystemFont,sans-serif;max-width:1200px;margin:0 auto;padding:20px;background:#f5f5f5}h1{color:#333;border-bottom:2px solid #27ae60;padding-bottom:10px}.card{background:white;border-radius:8px;padding:20px;margin-bottom:20px;box-shadow:0 2px 4px rgba(0,0,0,0.1)}.btn{background:#D4AF37;color:white;border:none;padding:10px 20px;border-radius:5px;cursor:pointer;font-size:14px;margin-right:10px;margin-bottom:10px}.btn:disabled{background:#ccc}.btn-danger{background:#e74c3c}.btn-success{background:#27ae60}.btn-sm{padding:5px 10px;font-size:12px}.nav{margin-bottom:20px}.nav a{margin-right:15px;color:#8B4513;text-decoration:none;font-weight:bold}.stats{display:flex;gap:15px;margin:20px 0;flex-wrap:wrap}.stat{flex:1;min-width:150px;text-align:center;padding:20px;background:#f8f9fa;border-radius:8px}.stat-number{font-size:36px;font-weight:bold}.stat-label{font-size:14px;color:#666;margin-top:5px}.product-item{display:flex;align-items:center;padding:15px;border-bottom:1px solid #eee;gap:15px}.product-item:last-child{border-bottom:none}.product-item img{width:60px;height:60px;object-fit:cover;border-radius:4px}.product-item .info{flex:1}.product-item .info .title{font-weight:bold;margin-bottom:5px;color:#c0392b}.product-item .info .meta{font-size:12px;color:#666}.no-image{width:60px;height:60px;background:#eee;display:flex;align-items:center;justify-content:center;border-radius:4px;color:#999;font-size:10px}.retranslate-status{font-size:12px;margin-top:5px}.action-bar{position:sticky;top:0;background:white;padding:15px;margin:-20px -20px 20px -20px;border-bottom:1px solid #ddd;z-index:100;display:flex;justify-content:space-between;align-items:center;flex-wrap:wrap;gap:10px}</style></head>
<body>
<div class="nav"><a href="/">ğŸ  é¦–é </a><a href="/japanese-scan">ğŸ‡¯ğŸ‡µ æ—¥æ–‡æƒæ</a></div>
<h1>ğŸ‡¯ğŸ‡µ æ—¥æ–‡å•†å“æƒæ - å‚è§’ç¸½æœ¬èˆ–</h1>
<div class="card"><p>æƒæ Shopify ä¸­å‚è§’ç¸½æœ¬èˆ– çš„æ—¥æ–‡ï¼ˆæœªç¿»è­¯ï¼‰å•†å“ã€‚</p><button class="btn" id="scanBtn" onclick="startScan()">ğŸ” é–‹å§‹æƒæ</button><span id="scanStatus"></span></div>
<div class="stats" id="statsSection" style="display:none"><div class="stat"><div class="stat-number" id="totalProducts" style="color:#3498db">0</div><div class="stat-label">å‚è§’ç¸½æœ¬èˆ–å•†å“æ•¸</div></div><div class="stat"><div class="stat-number" id="japaneseCount" style="color:#e74c3c">0</div><div class="stat-label">æ—¥æ–‡å•†å“</div></div></div>
<div class="card" id="resultsCard" style="display:none"><div class="action-bar"><div><button class="btn btn-success" id="retranslateAllBtn" onclick="retranslateAll()" disabled>ğŸ”„ å…¨éƒ¨ç¿»è­¯</button><button class="btn btn-danger" id="deleteAllBtn" onclick="deleteAllJP()" disabled>ğŸ—‘ï¸ å…¨éƒ¨åˆªé™¤</button></div><div id="progressText"></div></div><div id="results"></div></div>
<script>let jp=[];async function startScan(){document.getElementById('scanBtn').disabled=true;document.getElementById('scanStatus').textContent='æƒæä¸­...';try{const r=await fetch('/api/scan-japanese');const d=await r.json();if(d.error){alert(d.error);return}jp=d.japanese_products;document.getElementById('totalProducts').textContent=d.total_products;document.getElementById('japaneseCount').textContent=d.japanese_count;document.getElementById('statsSection').style.display='flex';renderResults(d.japanese_products);document.getElementById('resultsCard').style.display='block';document.getElementById('retranslateAllBtn').disabled=jp.length===0;document.getElementById('deleteAllBtn').disabled=jp.length===0;document.getElementById('scanStatus').textContent='å®Œæˆï¼'}catch(e){alert(e.message)}finally{document.getElementById('scanBtn').disabled=false}}function renderResults(p){const c=document.getElementById('results');if(!p.length){c.innerHTML='<p style="text-align:center;color:#27ae60;font-size:18px">âœ… æ²’æœ‰æ—¥æ–‡å•†å“</p>';return}let h='';p.forEach(i=>{const img=i.image?`<img src="${i.image}">`:`<div class="no-image">ç„¡åœ–</div>`;h+=`<div class="product-item" id="product-${i.id}">${img}<div class="info"><div class="title">${i.title}</div><div class="meta">SKU:${i.sku||'ç„¡'}|Â¥${i.price}|${i.status}</div><div class="retranslate-status" id="status-${i.id}"></div></div><div class="actions"><button class="btn btn-success btn-sm" onclick="rt1('${i.id}')" id="rt-${i.id}">ğŸ”„</button><button class="btn btn-danger btn-sm" onclick="del1('${i.id}')" id="del-${i.id}">ğŸ—‘ï¸</button></div></div>`});c.innerHTML=h}async function rt1(id){const b=document.getElementById(`rt-${id}`);const s=document.getElementById(`status-${id}`);b.disabled=true;b.textContent='...';try{const r=await fetch('/api/retranslate-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:id})});const d=await r.json();if(d.success){s.innerHTML=`<span style="color:#27ae60">âœ… ${d.new_title}</span>`;const t=document.querySelector(`#product-${id} .title`);if(t){t.textContent=d.new_title;t.style.color='#27ae60'}b.textContent='âœ“'}else{s.innerHTML=`<span style="color:#e74c3c">âŒ ${d.error}</span>`;b.disabled=false;b.textContent='ğŸ”„'}}catch(e){s.innerHTML=`<span style="color:#e74c3c">âŒ ${e.message}</span>`;b.disabled=false;b.textContent='ğŸ”„'}}async function del1(id){if(!confirm('ç¢ºå®šåˆªé™¤ï¼Ÿ'))return;const b=document.getElementById(`del-${id}`);b.disabled=true;try{const r=await fetch('/api/delete-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:id})});const d=await r.json();if(d.success)document.getElementById(`product-${id}`).remove();else{alert('å¤±æ•—');b.disabled=false}}catch(e){alert(e.message);b.disabled=false}}async function retranslateAll(){if(!confirm(`ç¿»è­¯å…¨éƒ¨ ${jp.length} å€‹ï¼Ÿ`))return;const b=document.getElementById('retranslateAllBtn');b.disabled=true;b.textContent='ç¿»è­¯ä¸­...';let s=0,f=0;for(let i=0;i<jp.length;i++){document.getElementById('progressText').textContent=`${i+1}/${jp.length}`;try{const r=await fetch('/api/retranslate-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:jp[i].id})});const d=await r.json();const st=document.getElementById(`status-${jp[i].id}`);if(d.success){s++;if(st)st.innerHTML=`<span style="color:#27ae60">âœ… ${d.new_title}</span>`;const t=document.querySelector(`#product-${jp[i].id} .title`);if(t){t.textContent=d.new_title;t.style.color='#27ae60'}}else{f++;if(st)st.innerHTML=`<span style="color:#e74c3c">âŒ ${d.error}</span>`;if(f>=3){alert('é€£çºŒå¤±æ•—');break}}}catch(e){f++}await new Promise(r=>setTimeout(r,1500))}alert(`æˆåŠŸ:${s} å¤±æ•—:${f}`);b.textContent='ğŸ”„ å…¨éƒ¨ç¿»è­¯';b.disabled=false;document.getElementById('progressText').textContent=''}async function deleteAllJP(){if(!confirm(`åˆªé™¤å…¨éƒ¨ ${jp.length} å€‹ï¼Ÿ`))return;const b=document.getElementById('deleteAllBtn');b.disabled=true;let s=0,f=0;for(let i=0;i<jp.length;i++){document.getElementById('progressText').textContent=`${i+1}/${jp.length}`;try{const r=await fetch('/api/delete-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:jp[i].id})});const d=await r.json();if(d.success){s++;const el=document.getElementById(`product-${jp[i].id}`);if(el)el.remove()}else f++}catch(e){f++}await new Promise(r=>setTimeout(r,300))}alert(`æˆåŠŸ:${s} å¤±æ•—:${f}`);b.textContent='ğŸ—‘ï¸ å…¨éƒ¨åˆªé™¤';b.disabled=false;document.getElementById('progressText').textContent=''}</script></body></html>'''




@app.route('/api/scan-japanese')
def api_scan_japanese():
    if not load_shopify_token():
        return jsonify({'error': 'æœªè¨­å®š Token'}), 400
    products = []
    url = shopify_api_url("products.json?limit=250&vendor=å‚è§’ç¸½æœ¬èˆ–")
    while url:
        r = requests.get(url, headers=get_shopify_headers())
        if r.status_code != 200: break
        for p in r.json().get('products', []):
            sku = ''; price = ''
            for v in p.get('variants', []): sku = v.get('sku', ''); price = v.get('price', ''); break
            products.append({'id': p.get('id'), 'title': p.get('title', ''), 'handle': p.get('handle', ''),
                'sku': sku, 'price': price, 'vendor': p.get('vendor', ''), 'status': p.get('status', ''),
                'created_at': p.get('created_at', ''), 'image': p.get('image', {}).get('src', '') if p.get('image') else ''})
        lh = r.headers.get('Link', '')
        m = re.search(r'<([^>]+)>; rel="next"', lh)
        url = m.group(1) if m and 'rel="next"' in lh else None
    jp = [p for p in products if is_japanese_text(p.get('title', ''))]
    return jsonify({'total_products': len(products), 'japanese_count': len(jp), 'japanese_products': jp})




@app.route('/api/retranslate-product', methods=['POST'])
def api_retranslate_product():
    if not load_shopify_token():
        return jsonify({'error': 'æœªè¨­å®š Token'}), 400
    data = request.get_json()
    pid = data.get('product_id')
    if not pid:
        return jsonify({'error': 'ç¼ºå°‘ product_id'}), 400
    resp = requests.get(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers())
    if resp.status_code != 200:
        return jsonify({'error': f'ç„¡æ³•å–å¾—: {resp.status_code}'}), 400
    product = resp.json().get('product', {})
    translated = translate_with_chatgpt(product.get('title', ''), product.get('body_html', ''))
    if not translated['success']:
        return jsonify({'success': False, 'error': f"ç¿»è­¯å¤±æ•—: {translated.get('error', 'æœªçŸ¥')}"})
    ok, r = update_product(pid, {
        'title': translated['title'],
        'body_html': translated['description'],
        'metafields_global_title_tag': translated['page_title'],
        'metafields_global_description_tag': translated['meta_description']
    })
    if ok:
        return jsonify({'success': True, 'old_title': product.get('title', ''), 'new_title': translated['title'], 'product_id': pid})
    return jsonify({'success': False, 'error': f'æ›´æ–°å¤±æ•—: {r.text[:200]}'})




@app.route('/api/delete-product', methods=['POST'])
def api_delete_product():
    if not load_shopify_token():
        return jsonify({'error': 'æœªè¨­å®š Token'}), 400
    data = request.get_json()
    pid = data.get('product_id')
    if not pid:
        return jsonify({'error': 'ç¼ºå°‘ product_id'}), 400
    return jsonify({'success': delete_product(pid), 'product_id': pid})




@app.route('/api/test-translate')
def api_test_translate():
    api_key = os.environ.get("OPENAI_API_KEY", "")
    if not api_key:
        return jsonify({'error': 'OPENAI_API_KEY æœªè¨­å®š'})
    key_preview = f"{api_key[:8]}...{api_key[-4:]}" if len(api_key) > 12 else "å¤ªçŸ­"
    result = translate_with_chatgpt("ã‚†ã‹ã‚Š 8æšå…¥", "å‚è§’ç¸½æœ¬èˆ–ã®ä¼çµ±çš„ãªæµ·è€ç…é¤…ã§ã™")
    result['key_preview'] = key_preview
    result['key_length'] = len(api_key)
    return jsonify(result)




@app.route('/api/status')
def get_status():
    return jsonify(scrape_status)


@app.route('/api/start', methods=['POST'])
def start_scrape():
    global scrape_status
    if scrape_status['running']: return jsonify({'error': 'çˆ¬å–å·²åœ¨é€²è¡Œä¸­'}), 400
    if not load_shopify_token(): return jsonify({'error': 'æœªè¨­å®š Shopify Token'}), 400
    test = translate_with_chatgpt("ãƒ†ã‚¹ãƒˆå•†å“", "ãƒ†ã‚¹ãƒˆèª¬æ˜")
    if not test['success']:
        return jsonify({'error': f"ç¿»è­¯åŠŸèƒ½ç•°å¸¸: {test.get('error', 'æœªçŸ¥')}"}), 400
    threading.Thread(target=run_scrape).start()
    return jsonify({'message': 'é–‹å§‹çˆ¬å–'})


@app.route('/api/test-shopify')
def test_shopify():
    if not load_shopify_token(): return jsonify({'success': False, 'error': 'æœªè¨­å®š Token'})
    r = requests.get(shopify_api_url('shop.json'), headers=get_shopify_headers())
    if r.status_code == 200: return jsonify({'success': True, 'shop': r.json()['shop']})
    return jsonify({'success': False, 'error': r.text}), 400


if __name__ == '__main__':
    print("=" * 50)
    print("å‚è§’ç¸½æœ¬èˆ–çˆ¬èŸ²å·¥å…· v2.2")
    print("æ–°å¢: ç¼ºè²¨å•†å“è‡ªå‹•åˆªé™¤")
    print("=" * 50)
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port, debug=False)
