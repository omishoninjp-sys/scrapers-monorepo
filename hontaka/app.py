"""
æœ¬é«˜ç ‚å±‹å•†å“çˆ¬èŸ² + Shopify ä¸Šæ¶å·¥å…·
åŠŸèƒ½ï¼š
1. çˆ¬å– hontaka-shop.com å…¨ç«™å•†å“
2. è¨ˆç®—æç©é‡é‡ vs å¯¦éš›é‡é‡ï¼Œå–å¤§å€¼
3. ä¸Šæ¶åˆ° Shopifyï¼ˆä¸é‡è¤‡ä¸Šæ¶ï¼‰
4. åŸåƒ¹å¯«å…¥æˆæœ¬åƒ¹ï¼ˆCostï¼‰
5. OpenAI ç¿»è­¯æˆç¹é«”ä¸­æ–‡
"""

from flask import Flask, render_template, jsonify, request
import requests
from bs4 import BeautifulSoup
import re
import json
import os
import time
from urllib.parse import urljoin
import math
import threading
import base64

app = Flask(__name__)

# ========== è¨­å®š ==========
SHOPIFY_SHOP = ""
SHOPIFY_ACCESS_TOKEN = ""

BASE_URL = "https://www.hontaka-shop.com"
LIST_BASE_URL = "https://www.hontaka-shop.com/shopbrand/all_items/"
LIST_PAGE_URL_TEMPLATE = "https://www.hontaka-shop.com/shopbrand/all_items/page{page}/order/"

# OpenAI API è¨­å®š
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")

# æœ€ä½åƒ¹æ ¼é–€æª»
MIN_PRICE = 1000

# è«‹æ±‚ Headers
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8,zh-TW;q=0.7',
    'Accept-Charset': 'EUC-JP,utf-8;q=0.7,*;q=0.3',
    'Connection': 'keep-alive',
}

# å…¨åŸŸè®Šæ•¸å­˜å„²çˆ¬å–ç‹€æ…‹
scrape_status = {
    "running": False,
    "progress": 0,
    "total": 0,
    "current_product": "",
    "products": [],
    "errors": [],
    "uploaded": 0,
    "skipped": 0,
    "skipped_exists": 0,
    "filtered_by_price": 0,
    "out_of_stock": 0,
    "deleted": 0
}

def load_shopify_token():
    """è¼‰å…¥ Shopify Access Token å’Œå•†åº—åç¨±"""
    global SHOPIFY_ACCESS_TOKEN, SHOPIFY_SHOP
    
    env_token = os.environ.get('SHOPIFY_ACCESS_TOKEN', '')
    env_shop = os.environ.get('SHOPIFY_SHOP', '')
    
    if env_token and env_shop:
        SHOPIFY_ACCESS_TOKEN = env_token
        SHOPIFY_SHOP = env_shop.replace('https://', '').replace('http://', '').replace('.myshopify.com', '').strip('/')
        print(f"[è¨­å®š] å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥ - å•†åº—: {SHOPIFY_SHOP}")
        return True
    
    token_file = "shopify_token.json"
    if os.path.exists(token_file):
        with open(token_file, 'r') as f:
            data = json.load(f)
            SHOPIFY_ACCESS_TOKEN = data.get('access_token', '')
            shop = data.get('shop', '')
            if shop:
                SHOPIFY_SHOP = shop.replace('https://', '').replace('http://', '').replace('.myshopify.com', '').strip('/')
            print(f"[è¨­å®š] å¾æª”æ¡ˆè¼‰å…¥ - å•†åº—: {SHOPIFY_SHOP}")
            return True
    return False

def get_shopify_headers():
    """å–å¾— Shopify API Headers"""
    return {
        'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN,
        'Content-Type': 'application/json',
    }

def shopify_api_url(endpoint):
    """å»ºç«‹ Shopify API URL"""
    return f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/{endpoint}"

def calculate_selling_price(cost, weight):
    """
    è¨ˆç®—å”®åƒ¹
    å…¬å¼ï¼š[é€²è²¨åƒ¹ + (é‡é‡ * 1250)] / 0.7 = å”®åƒ¹
    """
    if not cost or cost <= 0:
        return 0
    
    shipping_cost = weight * 1250 if weight else 0
    price = (cost + shipping_cost) / 0.7
    
    return round(price)

def clean_html_for_translation(html_text):
    """æ¸…é™¤ HTML ä¸­çš„ CSSã€script å’Œå¤šé¤˜æ¨™ç±¤ï¼Œåªä¿ç•™ç´”æ–‡å­—"""
    if not html_text:
        return ""
    
    text = html_text
    text = re.sub(r'<style[^>]*>.*?</style>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'<script[^>]*>.*?</script>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'#[\w-]+\s*\{[^}]*\}', '', text, flags=re.DOTALL)
    text = re.sub(r'\.[\w-]+\s*\{[^}]*\}', '', text, flags=re.DOTALL)
    text = re.sub(r'\s*style\s*=\s*["\'][^"\']*["\']', '', text, flags=re.IGNORECASE)
    text = re.sub(r'<br\s*/?>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'</p>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'</div>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'\n\s*\n', '\n\n', text)
    text = re.sub(r'[ \t]+', ' ', text)
    
    return text.strip()

def translate_with_chatgpt(title, description):
    """
    ä½¿ç”¨ ChatGPT ç¿»è­¯å•†å“åç¨±å’Œèªªæ˜ï¼Œä¸¦ç”Ÿæˆ SEO å…§å®¹
    """
    clean_description = clean_html_for_translation(description)
    
    prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚è«‹å°‡ä»¥ä¸‹æ—¥æœ¬ç”œé»å•†å“è³‡è¨Šç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼Œä¸¦å„ªåŒ– SEOã€‚

å•†å“åç¨±ï¼ˆæ—¥æ–‡ï¼‰ï¼š{title}
å•†å“èªªæ˜ï¼ˆæ—¥æ–‡ï¼‰ï¼š{clean_description[:1500]}

è«‹å›å‚³ JSON æ ¼å¼ï¼ˆä¸è¦åŠ  markdown æ¨™è¨˜ï¼‰ï¼š
{{
    "title": "ç¿»è­¯å¾Œçš„å•†å“åç¨±ï¼ˆç¹é«”ä¸­æ–‡ï¼Œç°¡æ½”æœ‰åŠ›ï¼Œå‰é¢åŠ ä¸Šã€Œæœ¬é«˜ç ‚å±‹ã€ï¼‰",
    "description": "ç¿»è­¯å¾Œçš„å•†å“èªªæ˜ï¼ˆç¹é«”ä¸­æ–‡ï¼Œä¿ç•™åŸæ„ä½†æ›´æµæš¢ï¼Œé©åˆé›»å•†å±•ç¤ºï¼‰",
    "page_title": "SEO é é¢æ¨™é¡Œï¼ˆç¹é«”ä¸­æ–‡ï¼ŒåŒ…å«æœ¬é«˜ç ‚å±‹å“ç‰Œå’Œå•†å“ç‰¹è‰²ï¼Œ50-60å­—ä»¥å…§ï¼‰",
    "meta_description": "SEO æè¿°ï¼ˆç¹é«”ä¸­æ–‡ï¼Œå¸å¼•é»æ“Šï¼ŒåŒ…å«é—œéµå­—ï¼Œ100å­—ä»¥å…§ï¼‰"
}}

é‡è¦è¦å‰‡ï¼š
1. é€™æ˜¯æ—¥æœ¬æœ¬é«˜ç ‚å±‹çš„é«˜ç´šæ´‹è“å­ï¼ˆã‚¨ã‚³ãƒ«ã‚»è–„é¤…ã€ãƒãƒ³ãƒ‡ãƒ«ãƒãƒ¼ã‚²ãƒ«æä»é¤…ç­‰ï¼‰
2. ã‚¨ã‚³ãƒ«ã‚» æ˜¯æ‹›ç‰Œå•†å“ï¼Œå¯ç¿»è­¯ç‚ºã€Œè–„é¤…æ²ã€æˆ–ã€Œè›‹æ²ã€
3. ãƒãƒ³ãƒ‡ãƒ«ãƒãƒ¼ã‚²ãƒ« å¯ç¿»è­¯ç‚ºã€Œæä»ç“¦ç‰‡é¤…ã€
4. ç¿»è­¯è¦è‡ªç„¶æµæš¢ï¼Œä¸è¦ç”Ÿç¡¬
5. å•†å“æ¨™é¡Œé–‹é ­å¿…é ˆæ˜¯ã€Œæœ¬é«˜ç ‚å±‹ã€
6. ã€ç¦æ­¢ä½¿ç”¨ä»»ä½•æ—¥æ–‡ã€‘æ‰€æœ‰å…§å®¹å¿…é ˆæ˜¯ç¹é«”ä¸­æ–‡æˆ–è‹±æ–‡
7. SEO å…§å®¹è¦åŒ…å«ï¼šæœ¬é«˜ç ‚å±‹ã€ç¥æˆ¶ã€æ—¥æœ¬ã€ä¼´æ‰‹ç¦®ã€é€ç¦®ç­‰é—œéµå­—
8. åªå›å‚³ JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—"""

    try:
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {OPENAI_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "gpt-4o-mini",
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚ä½ çš„è¼¸å‡ºå¿…é ˆå®Œå…¨ä½¿ç”¨ç¹é«”ä¸­æ–‡å’Œè‹±æ–‡ï¼Œçµ•å°ç¦æ­¢å‡ºç¾ä»»ä½•æ—¥æ–‡å­—å…ƒã€‚"},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0,
                "max_tokens": 1000
            },
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            content = content.strip()
            if content.startswith('```'):
                content = content.split('\n', 1)[1]
            if content.endswith('```'):
                content = content.rsplit('```', 1)[0]
            content = content.strip()
            
            translated = json.loads(content)
            
            trans_title = translated.get('title', title)
            if not trans_title.startswith('æœ¬é«˜ç ‚å±‹'):
                trans_title = f"æœ¬é«˜ç ‚å±‹ {trans_title}"
            
            return {
                'success': True,
                'title': trans_title,
                'description': translated.get('description', description),
                'page_title': translated.get('page_title', ''),
                'meta_description': translated.get('meta_description', '')
            }
        else:
            print(f"[OpenAI éŒ¯èª¤] {response.status_code}: {response.text}")
            return {
                'success': False,
                'title': f"æœ¬é«˜ç ‚å±‹ {title}",
                'description': description,
                'page_title': '',
                'meta_description': ''
            }
            
    except Exception as e:
        print(f"[ç¿»è­¯éŒ¯èª¤] {e}")
        return {
            'success': False,
            'title': f"æœ¬é«˜ç ‚å±‹ {title}",
            'description': description,
            'page_title': '',
            'meta_description': ''
        }

def download_image_to_base64(img_url, max_retries=3):
    """ä¸‹è¼‰åœ–ç‰‡ä¸¦è½‰æ›ç‚º Base64"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
        'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
        'Referer': 'https://www.hontaka-shop.com/',
        'Connection': 'keep-alive',
    }
    
    # é‡å° akamaized.net CDN èª¿æ•´ headers
    if 'akamaized.net' in img_url:
        headers['Referer'] = 'https://www.hontaka-shop.com/'
    
    for attempt in range(max_retries):
        try:
            response = requests.get(img_url, headers=headers, timeout=30)
            if response.status_code == 200:
                content_type = response.headers.get('Content-Type', 'image/jpeg')
                if 'jpeg' in content_type or 'jpg' in content_type:
                    img_format = 'image/jpeg'
                elif 'png' in content_type:
                    img_format = 'image/png'
                elif 'webp' in content_type:
                    img_format = 'image/webp'
                elif 'gif' in content_type:
                    img_format = 'image/gif'
                else:
                    img_format = 'image/jpeg'
                
                img_base64 = base64.b64encode(response.content).decode('utf-8')
                return {
                    'success': True,
                    'base64': img_base64,
                    'content_type': img_format
                }
            else:
                print(f"[åœ–ç‰‡ä¸‹è¼‰] ç¬¬ {attempt+1} æ¬¡å˜—è©¦å¤±æ•—: HTTP {response.status_code}")
        except Exception as e:
            print(f"[åœ–ç‰‡ä¸‹è¼‰] ç¬¬ {attempt+1} æ¬¡å˜—è©¦ç•°å¸¸: {e}")
        
        time.sleep(1)
    
    return {'success': False}

def get_existing_products_map():
    """å–å¾— Shopify å·²å­˜åœ¨çš„å•†å“ï¼Œå›å‚³ {sku: product_id} å­—å…¸"""
    products_map = {}
    url = shopify_api_url("products.json?limit=250")
    
    while url:
        response = requests.get(url, headers=get_shopify_headers())
        if response.status_code != 200:
            print(f"Error fetching products: {response.status_code}")
            break
        
        data = response.json()
        for product in data.get('products', []):
            product_id = product.get('id')
            for variant in product.get('variants', []):
                sku = variant.get('sku')
                if sku and product_id:
                    products_map[sku] = product_id
        
        link_header = response.headers.get('Link', '')
        if 'rel="next"' in link_header:
            match = re.search(r'<([^>]+)>; rel="next"', link_header)
            if match:
                url = match.group(1)
            else:
                url = None
        else:
            url = None
    
    return products_map

def get_collection_products_map(collection_id):
    """åªå–å¾—ç‰¹å®š Collection å…§çš„å•†å“"""
    products_map = {}
    if not collection_id:
        return products_map
    
    url = shopify_api_url(f"collections/{collection_id}/products.json?limit=250")
    
    while url:
        response = requests.get(url, headers=get_shopify_headers())
        if response.status_code != 200:
            break
        
        data = response.json()
        for product in data.get('products', []):
            product_id = product.get('id')
            for variant in product.get('variants', []):
                sku = variant.get('sku')
                if sku and product_id:
                    products_map[sku] = product_id
        
        link_header = response.headers.get('Link', '')
        if 'rel="next"' in link_header:
            match = re.search(r'<([^>]+)>; rel="next"', link_header)
            if match:
                url = match.group(1)
            else:
                url = None
        else:
            url = None
    
    print(f"[INFO] Collection å…§æœ‰ {len(products_map)} å€‹å•†å“")
    return products_map

def set_product_to_draft(product_id):
    """å°‡ Shopify å•†å“è¨­ç‚ºè‰ç¨¿"""
    url = shopify_api_url(f"products/{product_id}.json")
    response = requests.put(url, headers=get_shopify_headers(), json={
        "product": {"id": product_id, "status": "draft"}
    })
    if response.status_code == 200:
        print(f"[è¨­ç‚ºè‰ç¨¿] Product ID: {product_id}")
        return True
    return False

def get_or_create_collection(collection_title="æœ¬é«˜ç ‚å±‹"):
    """å–å¾—æˆ–å»ºç«‹ Collection"""
    response = requests.get(
        shopify_api_url(f'custom_collections.json?title={collection_title}'),
        headers=get_shopify_headers()
    )
    
    if response.status_code == 200:
        collections = response.json().get('custom_collections', [])
        for col in collections:
            if col['title'] == collection_title:
                print(f"[INFO] æ‰¾åˆ°ç¾æœ‰ Collection: {collection_title} (ID: {col['id']})")
                return col['id']
    
    response = requests.post(
        shopify_api_url('custom_collections.json'),
        headers=get_shopify_headers(),
        json={
            'custom_collection': {
                'title': collection_title,
                'published': True
            }
        }
    )
    
    if response.status_code == 201:
        collection_id = response.json()['custom_collection']['id']
        print(f"[INFO] å»ºç«‹æ–° Collection: {collection_title} (ID: {collection_id})")
        return collection_id
    
    print(f"[ERROR] ç„¡æ³•å»ºç«‹ Collection: {response.text}")
    return None

def add_product_to_collection(product_id, collection_id):
    """å°‡å•†å“åŠ å…¥ Collection"""
    response = requests.post(
        shopify_api_url('collects.json'),
        headers=get_shopify_headers(),
        json={
            'collect': {
                'product_id': product_id,
                'collection_id': collection_id
            }
        }
    )
    return response.status_code == 201

def publish_to_all_channels(product_id):
    """ç™¼å¸ƒåˆ°æ‰€æœ‰éŠ·å”®æ¸ é“"""
    print(f"[ç™¼å¸ƒ] æ­£åœ¨ç™¼å¸ƒå•†å“ {product_id} åˆ°æ‰€æœ‰æ¸ é“...")
    
    graphql_url = f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/graphql.json"
    headers = {
        'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN,
        'Content-Type': 'application/json',
    }
    
    query = """
    {
      publications(first: 20) {
        edges {
          node {
            id
            name
            supportsFuturePublishing
          }
        }
      }
    }
    """
    
    response = requests.post(graphql_url, headers=headers, json={'query': query})
    
    if response.status_code != 200:
        print(f"[ç™¼å¸ƒ] ç„¡æ³•å–å¾—æ¸ é“åˆ—è¡¨: {response.status_code}")
        return False
    
    result = response.json()
    publications = result.get('data', {}).get('publications', {}).get('edges', [])
    
    seen_names = set()
    unique_publications = []
    for pub in publications:
        name = pub['node']['name']
        if name not in seen_names:
            seen_names.add(name)
            unique_publications.append(pub['node'])
    
    print(f"[ç™¼å¸ƒ] æ‰¾åˆ° {len(unique_publications)} å€‹éŠ·å”®æ¸ é“")
    
    publication_inputs = [{"publicationId": pub['id']} for pub in unique_publications]
    
    mutation = """
    mutation publishablePublish($id: ID!, $input: [PublicationInput!]!) {
      publishablePublish(id: $id, input: $input) {
        publishable {
          availablePublicationsCount {
            count
          }
        }
        userErrors {
          field
          message
        }
      }
    }
    """
    
    variables = {
        "id": f"gid://shopify/Product/{product_id}",
        "input": publication_inputs
    }
    
    pub_response = requests.post(graphql_url, headers=headers, json={
        'query': mutation,
        'variables': variables
    })
    
    if pub_response.status_code == 200:
        pub_result = pub_response.json()
        data = pub_result.get('data') or {}
        publishable_publish = data.get('publishablePublish') or {}
        errors = publishable_publish.get('userErrors') or []
        
        if errors:
            real_errors = [e for e in errors if 'does not exist' not in e.get('message', '')]
            if real_errors:
                print(f"[ç™¼å¸ƒ] éŒ¯èª¤: {real_errors}")
        
        return True
    else:
        print(f"[ç™¼å¸ƒ] GraphQL è«‹æ±‚å¤±æ•—: {pub_response.status_code}")
        return False

def parse_dimension_weight(text):
    """
    è§£æå°ºå¯¸å’Œé‡é‡
    å°ºå¯¸æ ¼å¼: 248Ã—248 Ã—121 mm æˆ– 248Ã— 248Ã— 121 mm
    é‡é‡æ ¼å¼: 1477ï½‡ æˆ– 1477g
    """
    result = {
        'dimension': None,
        'actual_weight': None,
        'volume_weight': 0,
        'final_weight': 0
    }
    
    # æ¨™æº–åŒ–æ–‡å­—
    text = text.replace('Ã—', 'x').replace('ï¼¸', 'x').replace('ï½˜', 'x')
    text = text.replace('ï½ï½', 'mm').replace('ï½‡', 'g').replace('ï½‹ï½‡', 'kg')
    text = text.replace(',', '').replace('ï¼Œ', '')
    text = re.sub(r'\s+', ' ', text)
    
    # è§£æå°ºå¯¸ - æ ¼å¼: 248x248 x121 mm æˆ– 248x 248x 121 mm
    dim_pattern = r'(\d+(?:\.\d+)?)\s*[xXÃ—]\s*(\d+(?:\.\d+)?)\s*[xXÃ—]?\s*(\d+(?:\.\d+)?)\s*mm'
    dim_match = re.search(dim_pattern, text, re.IGNORECASE)
    
    if dim_match:
        l, w, h = float(dim_match.group(1)), float(dim_match.group(2)), float(dim_match.group(3))
        # æç©é‡é‡ = (é•· Ã— å¯¬ Ã— é«˜) / 6000000 (mmÂ³ è½‰ kg)
        volume_weight = (l * w * h) / 6000000
        volume_weight = round(volume_weight, 2)
        result['dimension'] = {'length': l, 'width': w, 'height': h}
        result['volume_weight'] = volume_weight
        print(f"[å°ºå¯¸] {l}x{w}x{h}mm -> æç©é‡é‡: {volume_weight}kg")
    
    # è§£æé‡é‡ - æ ¼å¼: 1477g æˆ– 1.5kg
    weight_pattern = r'é‡é‡[ï¼š:\s]*(\d+(?:\.\d+)?)\s*(g|kg|ï½‡|ï½‹ï½‡)'
    weight_match = re.search(weight_pattern, text, re.IGNORECASE)
    
    if weight_match:
        weight_val = float(weight_match.group(1))
        unit = weight_match.group(2).lower()
        if 'kg' in unit:
            actual_weight = weight_val
        else:
            actual_weight = weight_val / 1000
        result['actual_weight'] = round(actual_weight, 3)
        print(f"[é‡é‡] {result['actual_weight']}kg")
    
    # è¨ˆç®—æœ€çµ‚é‡é‡ï¼ˆå–è¼ƒå¤§å€¼ï¼‰
    if result['volume_weight'] and result['actual_weight']:
        result['final_weight'] = max(result['volume_weight'], result['actual_weight'])
    elif result['volume_weight']:
        result['final_weight'] = result['volume_weight']
    elif result['actual_weight']:
        result['final_weight'] = result['actual_weight']
    
    return result

def scrape_product_list():
    """çˆ¬å–å•†å“åˆ—è¡¨ - æ”¯æ´å¤šé """
    products = []
    page_num = 1
    max_pages = 20
    
    while page_num <= max_pages:
        if page_num == 1:
            url = LIST_BASE_URL
        else:
            url = LIST_PAGE_URL_TEMPLATE.format(page=page_num)
        
        print(f"[INFO] æ­£åœ¨è¼‰å…¥ç¬¬ {page_num} é : {url}")
        
        try:
            response = requests.get(url, headers=HEADERS, timeout=30)
            response.encoding = 'euc-jp'
            
            if response.status_code != 200:
                print(f"[ERROR] è¼‰å…¥é é¢å¤±æ•—: HTTP {response.status_code}")
                break
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # å°‹æ‰¾å•†å“é€£çµ: /shopdetail/{12ä½æ•¸å­—}/
            product_links = soup.find_all('a', href=re.compile(r'/shopdetail/\d{12}/'))
            
            if not product_links:
                print(f"[INFO] ç¬¬ {page_num} é æ²’æœ‰æ‰¾åˆ°å•†å“ï¼Œåœæ­¢")
                break
            
            seen_skus = set()
            page_products = []
            
            for link in product_links:
                href = link.get('href', '')
                if not href or '/shopdetail/' not in href:
                    continue
                
                # æå– SKU: /shopdetail/{12-digit}/
                sku_match = re.search(r'/shopdetail/(\d{12})/', href)
                if not sku_match:
                    continue
                
                sku = sku_match.group(1)
                
                if sku in seen_skus:
                    continue
                seen_skus.add(sku)
                
                # æ§‹å»ºå®Œæ•´ URLï¼ˆä¸å« all_items è·¯å¾‘ï¼‰
                full_url = f"{BASE_URL}/shopdetail/{sku}/"
                page_products.append({
                    'url': full_url,
                    'sku': sku
                })
            
            if not page_products:
                print(f"[INFO] ç¬¬ {page_num} é æ²’æœ‰æ–°å•†å“ï¼Œåœæ­¢")
                break
            
            print(f"[INFO] ç¬¬ {page_num} é æ‰¾åˆ° {len(page_products)} å€‹å•†å“")
            products.extend(page_products)
            
            page_num += 1
            time.sleep(0.5)
            
        except Exception as e:
            print(f"[ERROR] è¼‰å…¥é é¢å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            break
    
    # å»é‡
    unique_products = []
    seen = set()
    for p in products:
        if p['sku'] not in seen:
            seen.add(p['sku'])
            unique_products.append(p)
    
    print(f"[INFO] å…±æ”¶é›† {len(unique_products)} å€‹ä¸é‡è¤‡å•†å“")
    return unique_products

def scrape_product_detail(url):
    """çˆ¬å–å–®ä¸€å•†å“è©³ç´°è³‡è¨Š"""
    product = {
        'url': url,
        'title': '',
        'price': 0,
        'description': '',
        'weight': 0,
        'images': [],
        'in_stock': True,
        'sku': '',
        'product_code': '',
        'content': '',
        'allergens': '',
        'shelf_life': '',
        'size_text': '',
        'weight_text': ''
    }
    
    sku_match = re.search(r'/shopdetail/(\d{12})/', url)
    if sku_match:
        product['sku'] = sku_match.group(1)
    
    try:
        print(f"[è¼‰å…¥] {url}")
        response = requests.get(url, headers=HEADERS, timeout=30)
        response.encoding = 'euc-jp'
        
        if response.status_code != 200:
            print(f"[ERROR] è¼‰å…¥é é¢å¤±æ•—: HTTP {response.status_code}")
            return product
        
        soup = BeautifulSoup(response.text, 'html.parser')
        page_text = soup.get_text()
        
        # ========== å•†å“åç¨± ==========
        # å¾é é¢æ¨™é¡Œæˆ– h1 å–å¾—
        title_tag = soup.find('title')
        if title_tag:
            title_text = title_tag.get_text(strip=True)
            # æ ¼å¼: ã‚¨ã‚³ãƒ«ã‚» E50 ã€”33050ã€•-æœ¬é«˜ç ‚å±‹
            title_parts = title_text.split('-')
            if title_parts:
                product['title'] = title_parts[0].strip()
        
        # å‚™ç”¨ï¼šå¾ meta æˆ– h2 å–å¾—
        if not product['title']:
            h2 = soup.find('h2')
            if h2:
                product['title'] = h2.get_text(strip=True)
        
        print(f"[æ¨™é¡Œ] {product['title']}")
        
        # æå–å•†å“ç·¨ç¢¼ (ã€”33050ã€• æ ¼å¼)
        code_match = re.search(r'ã€”(\d+)ã€•', product['title'])
        if code_match:
            product['product_code'] = code_match.group(1)
            print(f"[å•†å“ç·¨ç¢¼] {product['product_code']}")
        
        # ========== åƒ¹æ ¼ ==========
        # å„ªå…ˆå¾ hidden input å–å¾—åƒ¹æ ¼: <input type="hidden" name="price1" value="1188">
        price_input = soup.find('input', {'name': 'price1'})
        if price_input and price_input.get('value'):
            try:
                product['price'] = int(price_input.get('value').replace(',', ''))
            except:
                pass
        
        # å‚™ç”¨ï¼šå¾ M_price2 input å–å¾—
        if not product['price']:
            price_input2 = soup.find('input', {'id': 'M_price2'})
            if price_input2 and price_input2.get('value'):
                try:
                    product['price'] = int(price_input2.get('value').replace(',', ''))
                except:
                    pass
        
        # å†å‚™ç”¨ï¼šå¾é é¢æ–‡å­—æŠ“å–
        if not product['price']:
            price_pattern = r'(\d{1,3}(?:,\d{3})*)\s*å††'
            price_matches = re.findall(price_pattern, page_text)
            if price_matches:
                for pm in price_matches:
                    try:
                        price_val = int(pm.replace(',', ''))
                        if price_val >= 100:
                            product['price'] = price_val
                            break
                    except:
                        pass
        
        print(f"[åƒ¹æ ¼] Â¥{product['price']}")
        
        # ========== åº«å­˜ç‹€æ…‹ ==========
        if 'å£²åˆ‡ã‚Œ' in page_text or 'åœ¨åº«ãªã—' in page_text or 'SOLD OUT' in page_text:
            product['in_stock'] = False
            print(f"[åº«å­˜] ç„¡åº«å­˜")
        
        # ========== å•†å“èªªæ˜ ==========
        desc_parts = []
        
        # å°‹æ‰¾å•†å“èªªæ˜å€å¡Š - å¾é é¢çµæ§‹ä¸­æå–
        # æ ¼å¼é€šå¸¸æ˜¯: åç§°ï¼šç„¼è“å­ --- å•†å“èª¬æ˜ ---
        desc_match = re.search(r'å•†å“[èª¬èªª]æ˜[ï¼š:]\s*(.+?)(?=---|\n\n|å†…å®¹é‡|è³å‘³æœŸé™)', page_text, re.DOTALL)
        if desc_match:
            desc_parts.append(desc_match.group(1).strip())
        
        # å…§å®¹é‡
        content_match = re.search(r'å†…å®¹é‡[ï¼š:]\s*(.+?)(?=---|\n|è³å‘³æœŸé™|ç‰¹å®šåŸææ–™)', page_text)
        if content_match:
            product['content'] = content_match.group(1).strip()
            desc_parts.append(f"å…§å®¹é‡ï¼š{product['content']}")
        
        # è³å‘³æœŸé™
        shelf_match = re.search(r'è³å‘³æœŸé™[ï¼š:]\s*(\d+æ—¥?)', page_text)
        if shelf_match:
            product['shelf_life'] = shelf_match.group(1)
            desc_parts.append(f"è³å‘³æœŸé™ï¼š{product['shelf_life']}")
        
        # éæ•åŸ
        allergen_match = re.search(r'ç‰¹å®šåŸææ–™ç­‰?\d*å“ç›®[ï¼š:]\s*(.+?)(?=---|åŸææ–™å|\n\n)', page_text)
        if allergen_match:
            product['allergens'] = allergen_match.group(1).strip()
        
        # å°ºå¯¸
        size_match = re.search(r'ã‚µã‚¤ã‚º[ï¼š:]\s*(.+?)(?=---|é‡é‡|\n)', page_text)
        if size_match:
            product['size_text'] = size_match.group(1).strip()
        
        # é‡é‡
        weight_match = re.search(r'é‡é‡[ï¼š:]\s*(.+?)(?=---|ä¿å­˜|\n)', page_text)
        if weight_match:
            product['weight_text'] = weight_match.group(1).strip()
        
        product['description'] = '\n\n'.join(desc_parts) if desc_parts else ''
        
        # ========== è¨ˆç®—é‡é‡ ==========
        combined_text = f"ã‚µã‚¤ã‚ºï¼š{product['size_text']} é‡é‡ï¼š{product['weight_text']}"
        weight_info = parse_dimension_weight(combined_text)
        product['weight'] = weight_info['final_weight']
        print(f"[æœ€çµ‚é‡é‡] {product['weight']}kg")
        
        # ========== åœ–ç‰‡ ==========
        images = []
        seen_images = set()
        
        # å¾ makeshop-multi-images.akamaized.net æ‰¾åœ–ç‰‡
        # å•†å“ä¸»åœ–æ ¼å¼: https://makeshop-multi-images.akamaized.net/shophontaka/shopimages/44/01/9_000000000144.jpg
        # é—œè¯å•†å“æ ¼å¼: https://makeshop-multi-images.akamaized.net/shophontaka/itemimages/... (è¦æ’é™¤)
        img_tags = soup.find_all('img', src=re.compile(r'makeshop-multi-images\.akamaized\.net'))
        for img in img_tags:
            src = img.get('src', '')
            if src and 'shophontaka' in src:
                # æ’é™¤é—œè¯å•†å“çš„åœ–ç‰‡ï¼ˆitemimages è·¯å¾‘ï¼‰
                if '/itemimages/' in src:
                    continue
                
                # åªæŠ“ shopimages è·¯å¾‘çš„åœ–ç‰‡
                if '/shopimages/' not in src:
                    continue
                
                # éæ¿¾æ‰ç¸®åœ–ï¼ˆä»¥ s é–‹é ­çš„æª”åï¼‰
                # ç¸®åœ–æ ¼å¼: s9_000000000144.jpg
                # ä¸»åœ–æ ¼å¼: 9_000000000144.jpg
                filename = src.split('/')[-1].split('?')[0]
                if filename.startswith('s') and filename[1].isdigit():
                    continue
                
                # ç§»é™¤ query string ä¾†å»é‡
                clean_src = src.split('?')[0]
                if clean_src not in seen_images:
                    seen_images.add(clean_src)
                    images.append(src)
        
        # å‚™ç”¨ï¼šå¾æ•´å€‹ HTML æ‰¾åœ–ç‰‡ URLï¼ˆåªæ‰¾ shopimagesï¼‰
        if not images:
            script_text = str(soup)
            img_pattern = r'(https://makeshop-multi-images\.akamaized\.net/shophontaka/shopimages/[^"\']+\.(?:jpg|jpeg|png|gif))'
            found_images = re.findall(img_pattern, script_text, re.IGNORECASE)
            for img_url in found_images:
                filename = img_url.split('/')[-1].split('?')[0]
                # éæ¿¾ç¸®åœ–
                if filename.startswith('s') and filename[1].isdigit():
                    continue
                clean_url = img_url.split('?')[0]
                if clean_url not in seen_images:
                    seen_images.add(clean_url)
                    images.append(img_url)
        
        product['images'] = images[:10]
        print(f"[åœ–ç‰‡] æ‰¾åˆ° {len(product['images'])} å¼µåœ–ç‰‡")
        
    except Exception as e:
        print(f"[ERROR] çˆ¬å–å•†å“è©³ç´°å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
    
    return product

def upload_to_shopify(product, collection_id=None):
    """ä¸Šå‚³å•†å“åˆ° Shopify"""
    
    original_title = product['title']
    
    print(f"[ç¿»è­¯] æ­£åœ¨ç¿»è­¯: {original_title[:30]}...")
    translated = translate_with_chatgpt(original_title, product.get('description', ''))
    
    if translated['success']:
        print(f"[ç¿»è­¯æˆåŠŸ] {translated['title'][:30]}...")
    else:
        print(f"[ç¿»è­¯å¤±æ•—] ä½¿ç”¨åŸæ–‡")
    
    cost = product['price']
    weight = product.get('weight', 0)
    selling_price = calculate_selling_price(cost, weight)
    
    print(f"[åƒ¹æ ¼è¨ˆç®—] é€²è²¨åƒ¹: Â¥{cost}, é‡é‡: {weight}kg, å”®åƒ¹: Â¥{selling_price}")
    
    # ä¸‹è¼‰åœ–ç‰‡ä¸¦è½‰æ›ç‚º Base64
    images_base64 = []
    img_urls = product.get('images', [])
    print(f"[åœ–ç‰‡] é–‹å§‹ä¸‹è¼‰ {len(img_urls)} å¼µåœ–ç‰‡...")
    
    for idx, img_url in enumerate(img_urls):
        if not img_url or not img_url.startswith('http'):
            continue
        
        print(f"[åœ–ç‰‡] ä¸‹è¼‰ä¸­ ({idx+1}/{len(img_urls)}): {img_url[:60]}...")
        result = download_image_to_base64(img_url)
        
        if result['success']:
            images_base64.append({
                'attachment': result['base64'],
                'position': idx + 1,
                'filename': f"hontaka_{product['sku']}_{idx+1}.jpg"
            })
            print(f"[åœ–ç‰‡] âœ“ ä¸‹è¼‰æˆåŠŸ ({idx+1}/{len(img_urls)})")
        else:
            print(f"[åœ–ç‰‡] âœ— ä¸‹è¼‰å¤±æ•— ({idx+1}/{len(img_urls)})")
        
        time.sleep(0.5)
    
    print(f"[åœ–ç‰‡] æˆåŠŸä¸‹è¼‰ {len(images_base64)}/{len(img_urls)} å¼µåœ–ç‰‡")
    
    # ä½¿ç”¨å•†å“ç·¨ç¢¼ä½œç‚º SKUï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
    sku = product.get('product_code') or product['sku']
    
    shopify_product = {
        'product': {
            'title': translated['title'],
            'body_html': translated['description'],
            'vendor': 'æœ¬é«˜ç ‚å±‹',
            'product_type': 'è¥¿å¼ç”œé»',
            'status': 'active',
            'published': True,
            'variants': [{
                'sku': sku,
                'price': f"{selling_price:.2f}",
                'weight': product.get('weight', 0),
                'weight_unit': 'kg',
                'inventory_management': None,
                'inventory_policy': 'continue',
                'requires_shipping': True
            }],
            'images': images_base64,
            'tags': 'æœ¬é«˜ç ‚å±‹, æ—¥æœ¬, ç¥æˆ¶, è¥¿å¼ç”œé», ä¼´æ‰‹ç¦®, æ—¥æœ¬ä»£è³¼, é€ç¦®, ã‚¨ã‚³ãƒ«ã‚», è–„é¤…',
            'metafields_global_title_tag': translated['page_title'],
            'metafields_global_description_tag': translated['meta_description'],
            'metafields': [
                {
                    'namespace': 'custom',
                    'key': 'link',
                    'value': product['url'],
                    'type': 'url'
                }
            ]
        }
    }
    
    response = requests.post(
        shopify_api_url('products.json'),
        headers=get_shopify_headers(),
        json=shopify_product
    )
    
    print(f"[DEBUG] Shopify å›æ‡‰: {response.status_code}")
    
    if response.status_code == 201:
        created_product = response.json()['product']
        product_id = created_product['id']
        variant_id = created_product['variants'][0]['id']
        
        created_images = created_product.get('images', [])
        print(f"[DEBUG] å•†å“å»ºç«‹æˆåŠŸ: ID={product_id}")
        print(f"[DEBUG] Shopify å¯¦éš›å»ºç«‹åœ–ç‰‡: {len(created_images)}/{len(images_base64)} å¼µ")
        
        # æ›´æ–°æˆæœ¬åƒ¹
        update_cost_response = requests.put(
            shopify_api_url(f'variants/{variant_id}.json'),
            headers=get_shopify_headers(),
            json={
                'variant': {
                    'id': variant_id,
                    'cost': f"{cost:.2f}"
                }
            }
        )
        print(f"[DEBUG] æ›´æ–° Cost å›æ‡‰: {update_cost_response.status_code}")
        
        if collection_id:
            add_product_to_collection(product_id, collection_id)
        
        publish_to_all_channels(product_id)
        
        return {'success': True, 'product': created_product, 'translated': translated, 'selling_price': selling_price, 'cost': cost}
    else:
        print(f"[ERROR] Shopify éŒ¯èª¤: {response.text}")
        return {'success': False, 'error': response.text}

# ========== Flask è·¯ç”± ==========

@app.route('/')
def index():
    """é¦–é """
    token_loaded = load_shopify_token()
    token_status = '<span style="color: green;">âœ“ å·²è¼‰å…¥</span>' if token_loaded else '<span style="color: red;">âœ— æœªè¨­å®š</span>'
    
    return f'''<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æœ¬é«˜ç ‚å±‹ çˆ¬èŸ²å·¥å…·</title>
    <style>
        * {{ box-sizing: border-box; }}
        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; background: #f5f5f5; }}
        h1 {{ color: #333; border-bottom: 2px solid #8B4513; padding-bottom: 10px; }}
        .card {{ background: white; border-radius: 8px; padding: 20px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        .btn {{ background: #8B4513; color: white; border: none; padding: 12px 24px; border-radius: 5px; cursor: pointer; font-size: 16px; margin-right: 10px; }}
        .btn:hover {{ background: #A0522D; }}
        .btn:disabled {{ background: #ccc; cursor: not-allowed; }}
        .btn-secondary {{ background: #3498db; }}
        .btn-secondary:hover {{ background: #2980b9; }}
        .progress-bar {{ width: 100%; height: 20px; background: #eee; border-radius: 10px; overflow: hidden; margin: 10px 0; }}
        .progress-fill {{ height: 100%; background: linear-gradient(90deg, #8B4513, #D2691E); transition: width 0.3s; }}
        .status {{ padding: 10px; background: #f8f9fa; border-radius: 5px; margin-top: 10px; }}
        .log {{ max-height: 300px; overflow-y: auto; font-family: monospace; font-size: 13px; background: #1e1e1e; color: #d4d4d4; padding: 15px; border-radius: 5px; }}
        .stats {{ display: flex; gap: 15px; margin-top: 15px; flex-wrap: wrap; }}
        .stat {{ flex: 1; min-width: 80px; text-align: center; padding: 15px; background: #f8f9fa; border-radius: 5px; }}
        .stat-number {{ font-size: 24px; font-weight: bold; color: #8B4513; }}
        .stat-label {{ font-size: 12px; color: #666; margin-top: 5px; }}
    </style>
</head>
<body>
    <h1>ğŸª æœ¬é«˜ç ‚å±‹ çˆ¬èŸ²å·¥å…·</h1>
    
    <div class="card">
        <h3>Shopify é€£ç·šç‹€æ…‹</h3>
        <p>Token: {token_status}</p>
        <button class="btn btn-secondary" onclick="testShopify()">æ¸¬è©¦é€£ç·š</button>
    </div>
    
    <div class="card">
        <h3>é–‹å§‹çˆ¬å–</h3>
        <p>çˆ¬å– hontaka-shop.com å…¨ç«™å•†å“ä¸¦ä¸Šæ¶åˆ° Shopify</p>
        <p style="color: #666; font-size: 14px;">â€» æˆæœ¬åƒ¹ä½æ–¼ Â¥{MIN_PRICE} çš„å•†å“å°‡è‡ªå‹•è·³é</p>
        <button class="btn" id="startBtn" onclick="startScrape()">ğŸš€ é–‹å§‹çˆ¬å–</button>
        
        <div id="progressSection" style="display: none;">
            <div class="progress-bar">
                <div class="progress-fill" id="progressFill" style="width: 0%"></div>
            </div>
            <div class="status" id="statusText">æº–å‚™ä¸­...</div>
            
            <div class="stats">
                <div class="stat">
                    <div class="stat-number" id="uploadedCount">0</div>
                    <div class="stat-label">å·²ä¸Šæ¶</div>
                </div>
                <div class="stat">
                    <div class="stat-number" id="skippedCount">0</div>
                    <div class="stat-label">å·²å­˜åœ¨</div>
                </div>
                <div class="stat">
                    <div class="stat-number" id="filteredCount">0</div>
                    <div class="stat-label">åƒ¹æ ¼éæ¿¾</div>
                </div>
                <div class="stat">
                    <div class="stat-number" id="outOfStockCount">0</div>
                    <div class="stat-label">ç„¡åº«å­˜</div>
                </div>
                <div class="stat">
                    <div class="stat-number" id="deletedCount" style="color: #e67e22;">0</div>
                    <div class="stat-label">è¨­ç‚ºè‰ç¨¿</div>
                </div>
                <div class="stat">
                    <div class="stat-number" id="errorCount">0</div>
                    <div class="stat-label">éŒ¯èª¤</div>
                </div>
            </div>
        </div>
    </div>
    
    <div class="card">
        <h3>åŸ·è¡Œæ—¥èªŒ</h3>
        <div class="log" id="logArea">ç­‰å¾…é–‹å§‹...</div>
    </div>

    <script>
        let pollInterval = null;
        function log(msg, type = '') {{
            const logArea = document.getElementById('logArea');
            const time = new Date().toLocaleTimeString();
            const color = type === 'success' ? '#4ec9b0' : type === 'error' ? '#f14c4c' : '#d4d4d4';
            logArea.innerHTML += '<div style="color:' + color + '">[' + time + '] ' + msg + '</div>';
            logArea.scrollTop = logArea.scrollHeight;
        }}
        function clearLog() {{ document.getElementById('logArea').innerHTML = ''; }}
        async function testShopify() {{
            log('æ¸¬è©¦ Shopify é€£ç·š...');
            try {{
                const res = await fetch('/api/test-shopify');
                const data = await res.json();
                if (data.success) log('âœ“ é€£ç·šæˆåŠŸï¼å•†åº—: ' + data.shop.name, 'success');
                else log('âœ— é€£ç·šå¤±æ•—: ' + data.error, 'error');
            }} catch (e) {{ log('âœ— è«‹æ±‚å¤±æ•—: ' + e.message, 'error'); }}
        }}
        async function startScrape() {{
            clearLog(); log('é–‹å§‹çˆ¬å–æµç¨‹...');
            document.getElementById('startBtn').disabled = true;
            document.getElementById('progressSection').style.display = 'block';
            try {{
                const res = await fetch('/api/start-scrape', {{ method: 'POST' }});
                const data = await res.json();
                if (!data.success) {{ log('âœ— ' + data.error, 'error'); document.getElementById('startBtn').disabled = false; return; }}
                log('âœ“ çˆ¬å–ä»»å‹™å·²å•Ÿå‹•', 'success');
                pollInterval = setInterval(pollStatus, 1000);
            }} catch (e) {{ log('âœ— ' + e.message, 'error'); document.getElementById('startBtn').disabled = false; }}
        }}
        async function pollStatus() {{
            try {{
                const res = await fetch('/api/status');
                const data = await res.json();
                const percent = data.total > 0 ? (data.progress / data.total * 100) : 0;
                document.getElementById('progressFill').style.width = percent + '%';
                document.getElementById('statusText').textContent = data.current_product + ' (' + data.progress + '/' + data.total + ')';
                document.getElementById('uploadedCount').textContent = data.uploaded;
                document.getElementById('skippedCount').textContent = data.skipped_exists || 0;
                document.getElementById('filteredCount').textContent = data.filtered_by_price || 0;
                document.getElementById('outOfStockCount').textContent = data.out_of_stock || 0;
                document.getElementById('deletedCount').textContent = data.deleted || 0;
                document.getElementById('errorCount').textContent = data.errors.length;
                if (!data.running && data.progress > 0) {{
                    clearInterval(pollInterval);
                    document.getElementById('startBtn').disabled = false;
                    log('========== çˆ¬å–å®Œæˆ ==========', 'success');
                }}
            }} catch (e) {{ console.error(e); }}
        }}
    </script>
</body>
</html>'''

@app.route('/api/status')
def get_status():
    """å–å¾—çˆ¬å–ç‹€æ…‹"""
    return jsonify(scrape_status)

@app.route('/api/start-scrape', methods=['POST'])
def start_scrape():
    """é–‹å§‹çˆ¬å–"""
    global scrape_status
    
    if scrape_status['running']:
        return jsonify({'success': False, 'error': 'çˆ¬å–æ­£åœ¨é€²è¡Œä¸­'})
    
    if not load_shopify_token():
        return jsonify({'success': False, 'error': 'æ‰¾ä¸åˆ° Shopify è¨­å®š'})
    
    thread = threading.Thread(target=run_scrape)
    thread.start()
    
    return jsonify({'success': True, 'message': 'é–‹å§‹çˆ¬å–'})

@app.route('/api/start', methods=['POST'])
def api_start():
    """Cron-job è§¸ç™¼ç«¯é»"""
    global scrape_status
    
    if scrape_status['running']:
        return jsonify({'success': False, 'error': 'çˆ¬å–æ­£åœ¨é€²è¡Œä¸­'})
    
    if not load_shopify_token():
        return jsonify({'success': False, 'error': 'æ‰¾ä¸åˆ° Shopify è¨­å®š'})
    
    thread = threading.Thread(target=run_scrape)
    thread.start()
    
    return jsonify({'success': True, 'message': 'æœ¬é«˜ç ‚å±‹ çˆ¬èŸ²å·²å•Ÿå‹•'})

def run_scrape():
    """åŸ·è¡Œçˆ¬å–æµç¨‹"""
    global scrape_status
    
    try:
        scrape_status = {
            "running": True,
            "progress": 0,
            "total": 0,
            "current_product": "",
            "products": [],
            "errors": [],
            "uploaded": 0,
            "skipped": 0,
            "skipped_exists": 0,
            "filtered_by_price": 0,
            "out_of_stock": 0,
            "deleted": 0
        }
        
        # 1. å–å¾—æˆ–å»ºç«‹ Collection
        scrape_status['current_product'] = "æ­£åœ¨è¨­å®š Collection..."
        collection_id = get_or_create_collection("æœ¬é«˜ç ‚å±‹")
        print(f"[INFO] Collection ID: {collection_id}")
        
        # 2. å–å¾— Collection å…§çš„å•†å“
        scrape_status['current_product'] = "æ­£åœ¨å–å¾— Collection å…§å•†å“..."
        collection_products_map = get_collection_products_map(collection_id)
        existing_skus = set(collection_products_map.keys())
        print(f"[INFO] æœ¬é«˜ç ‚å±‹ Collection å…§æœ‰ {len(existing_skus)} å€‹å•†å“")
        
        # 3. çˆ¬å–å•†å“åˆ—è¡¨
        scrape_status['current_product'] = "æ­£åœ¨çˆ¬å–å•†å“åˆ—è¡¨..."
        product_list = scrape_product_list()
        scrape_status['total'] = len(product_list)
        print(f"[INFO] æ‰¾åˆ° {len(product_list)} å€‹å•†å“")
        
        # å–å¾—å®˜ç¶²æ‰€æœ‰ SKU
        website_skus = set()
        
        # 4. é€ä¸€è™•ç†å•†å“
        for idx, item in enumerate(product_list):
            scrape_status['progress'] = idx + 1
            scrape_status['current_product'] = f"è™•ç†ä¸­: {item['sku']}"
            
            # çˆ¬å–è©³ç´°è³‡è¨Š
            print(f"[çˆ¬å–] ({idx+1}/{len(product_list)}) {item['url']}")
            product = scrape_product_detail(item['url'])
            
            # ä½¿ç”¨å•†å“ç·¨ç¢¼ä½œç‚º SKU
            actual_sku = product.get('product_code') or product['sku']
            website_skus.add(actual_sku)
            
            # æª¢æŸ¥åº«å­˜
            if not product.get('in_stock', True):
                print(f"[è·³é] ç„¡åº«å­˜: {product.get('title', item['sku'])}")
                scrape_status['out_of_stock'] += 1
                continue
            
            # æª¢æŸ¥åƒ¹æ ¼é–€æª»
            if product.get('price', 0) < MIN_PRICE:
                print(f"[è·³é] åƒ¹æ ¼ä½æ–¼{MIN_PRICE}å††: {product.get('title', item['sku'])} (Â¥{product.get('price', 0)})")
                scrape_status['filtered_by_price'] += 1
                continue
            
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if actual_sku in existing_skus:
                print(f"[è·³é] å·²å­˜åœ¨: {actual_sku}")
                scrape_status['skipped_exists'] += 1
                continue
            
            # æª¢æŸ¥å¿…è¦è³‡è¨Š
            if not product.get('title') or not product.get('price'):
                print(f"[è·³é] è³‡è¨Šä¸å®Œæ•´: {item['sku']}")
                scrape_status['errors'].append({
                    'sku': item['sku'],
                    'error': 'è³‡è¨Šä¸å®Œæ•´'
                })
                continue
            
            # ä¸Šå‚³åˆ° Shopify
            result = upload_to_shopify(product, collection_id)
            
            if result['success']:
                translated_title = result.get('translated', {}).get('title', product['title'])
                print(f"[æˆåŠŸ] {translated_title}")
                existing_skus.add(actual_sku)
                scrape_status['uploaded'] += 1
                scrape_status['products'].append({
                    'sku': actual_sku,
                    'title': translated_title,
                    'original_title': product['title'],
                    'price': product['price'],
                    'selling_price': result.get('selling_price', 0),
                    'weight': product['weight'],
                    'status': 'success'
                })
            else:
                print(f"[å¤±æ•—] {product['title']}: {result['error']}")
                scrape_status['errors'].append({
                    'sku': actual_sku,
                    'title': product['title'],
                    'error': result['error']
                })
            
            time.sleep(1)
        
        # 5. è¨­ç‚ºè‰ç¨¿ï¼šCollection å…§ä½†å®˜ç¶²å·²ä¸‹æ¶çš„å•†å“
        scrape_status['current_product'] = "æ­£åœ¨æª¢æŸ¥å·²ä¸‹æ¶å•†å“..."
        skus_to_draft = existing_skus - website_skus
        
        if skus_to_draft:
            print(f"[INFO] ç™¼ç¾ {len(skus_to_draft)} å€‹å•†å“éœ€è¦è¨­ç‚ºè‰ç¨¿")
            for sku in skus_to_draft:
                scrape_status['current_product'] = f"è¨­ç‚ºè‰ç¨¿: {sku}"
                product_id = collection_products_map.get(sku)
                if product_id and set_product_to_draft(product_id):
                    scrape_status['deleted'] += 1
                time.sleep(0.5)
        else:
            print(f"[INFO] æ²’æœ‰éœ€è¦è¨­ç‚ºè‰ç¨¿çš„å•†å“")
        
        scrape_status['current_product'] = "å®Œæˆï¼"
        
    except Exception as e:
        print(f"[ERROR] çˆ¬å–éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        scrape_status['errors'].append({'error': str(e)})
    finally:
        scrape_status['running'] = False

@app.route('/api/test-shopify')
def test_shopify():
    """æ¸¬è©¦ Shopify é€£ç·š"""
    if not load_shopify_token():
        return jsonify({'success': False, 'error': 'æ‰¾ä¸åˆ° Shopify è¨­å®š'})
    
    response = requests.get(
        shopify_api_url('shop.json'),
        headers=get_shopify_headers()
    )
    
    if response.status_code == 200:
        return jsonify({'success': True, 'shop': response.json()['shop']})
    else:
        return jsonify({'success': False, 'error': response.text}), 400

@app.route('/api/test-scrape')
def test_scrape():
    """æ¸¬è©¦çˆ¬å–å–®ä¸€å•†å“"""
    test_url = "https://www.hontaka-shop.com/shopdetail/000000000006/"
    product = scrape_product_detail(test_url)
    
    if product.get('price') and product.get('weight'):
        product['selling_price'] = calculate_selling_price(product['price'], product['weight'])
    
    return jsonify(product)

if __name__ == '__main__':
    print("=" * 50)
    print("æœ¬é«˜ç ‚å±‹ çˆ¬èŸ²å·¥å…·")
    print("=" * 50)
    
    port = int(os.environ.get('PORT', 8080))
    print(f"é–‹å•Ÿç€è¦½å™¨è¨ªå•: http://localhost:{port}")
    print("=" * 50)
    
    app.run(host='0.0.0.0', port=port, debug=False)
