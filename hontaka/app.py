"""
æœ¬é«˜ç ‚å±‹å•†å“çˆ¬èŸ² + Shopify ä¸Šæ¶å·¥å…· v2.2
v2.1: ç¿»è­¯ä¿è­·æ©Ÿåˆ¶ã€æ—¥æ–‡å•†å“æƒæã€æ¸¬è©¦ç¿»è­¯
v2.2: ç¼ºè²¨å•†å“è‡ªå‹•åˆªé™¤ - å®˜ç¶²æ¶ˆå¤±æˆ–ç¼ºè²¨çš†ç›´æ¥åˆªé™¤
"""

from flask import Flask, jsonify, request
import requests
from bs4 import BeautifulSoup
import re
import json
import os
import time
from urllib.parse import urljoin
import math
import threading
import base64

app = Flask(__name__)

SHOPIFY_SHOP = ""
SHOPIFY_ACCESS_TOKEN = ""
BASE_URL = "https://www.hontaka-shop.com"
LIST_BASE_URL = "https://www.hontaka-shop.com/shopbrand/all_items/"
LIST_PAGE_URL_TEMPLATE = "https://www.hontaka-shop.com/shopbrand/all_items/page{page}/order/"
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
MIN_PRICE = 1000
MAX_CONSECUTIVE_TRANSLATION_FAILURES = 3

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8,zh-TW;q=0.7',
    'Accept-Charset': 'EUC-JP,utf-8;q=0.7,*;q=0.3',
}

scrape_status = {
    "running": False, "progress": 0, "total": 0, "current_product": "",
    "products": [], "errors": [], "uploaded": 0, "skipped": 0,
    "skipped_exists": 0, "filtered_by_price": 0, "out_of_stock": 0, "deleted": 0,
    "translation_failed": 0, "translation_stopped": False
}


def is_japanese_text(text):
    if not text: return False
    check = text.replace('\u672c\u9ad8\u7802\u5c4b', '').strip()
    if not check: return False
    jp = len(re.findall(r'[\u3040-\u309F\u30A0-\u30FF]', check))
    cn = len(re.findall(r'[\u4e00-\u9fff]', check))
    total = len(re.sub(r'[\s\d\W]', '', check))
    if total == 0: return False
    return jp > 0 and (jp / total > 0.3 or cn == 0)


def load_shopify_token():
    global SHOPIFY_ACCESS_TOKEN, SHOPIFY_SHOP
    env_token = os.environ.get('SHOPIFY_ACCESS_TOKEN', '')
    env_shop = os.environ.get('SHOPIFY_SHOP', '')
    if env_token and env_shop:
        SHOPIFY_ACCESS_TOKEN = env_token
        SHOPIFY_SHOP = env_shop.replace('https://','').replace('http://','').replace('.myshopify.com','').strip('/')
        return True
    tf = "shopify_token.json"
    if os.path.exists(tf):
        with open(tf, 'r') as f:
            d = json.load(f)
            SHOPIFY_ACCESS_TOKEN = d.get('access_token', '')
            s = d.get('shop', '')
            if s: SHOPIFY_SHOP = s.replace('https://','').replace('http://','').replace('.myshopify.com','').strip('/')
            return True
    return False


def get_shopify_headers():
    return {'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN, 'Content-Type': 'application/json'}


def shopify_api_url(endpoint):
    return f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/{endpoint}"


def calculate_selling_price(cost, weight):
    if not cost or cost <= 0: return 0
    return round((cost + (weight * 1250 if weight else 0)) / 0.7)


def clean_html_for_translation(html_text):
    if not html_text: return ""
    text = html_text
    text = re.sub(r'<style[^>]*>.*?</style>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'<script[^>]*>.*?</script>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'#[\w-]+\s*\{[^}]*\}', '', text, flags=re.DOTALL)
    text = re.sub(r'\.[\w-]+\s*\{[^}]*\}', '', text, flags=re.DOTALL)
    text = re.sub(r'\s*style\s*=\s*["\'][^"\']*["\']', '', text, flags=re.IGNORECASE)
    text = re.sub(r'<br\s*/?>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'</p>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'</div>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'\n\s*\n', '\n\n', text)
    return text.strip()


def translate_with_chatgpt(title, description, retry=False):
    clean_desc = clean_html_for_translation(description)
    prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚ç¿»è­¯æˆç¹é«”ä¸­æ–‡ä¸¦å„ªåŒ– SEOã€‚

å•†å“åç¨±ï¼š{title}
å•†å“èªªæ˜ï¼š{clean_desc[:1500]}

å›å‚³ JSONï¼ˆä¸åŠ  markdownï¼‰ï¼š
{{"title":"åç¨±ï¼ˆå‰åŠ ã€Œæœ¬é«˜ç ‚å±‹ã€ï¼‰","description":"èªªæ˜","page_title":"SEOæ¨™é¡Œ50-60å­—","meta_description":"SEOæè¿°100å­—å…§"}}

è¦å‰‡ï¼š1.æœ¬é«˜ç ‚å±‹æ´‹è“å­ 2.ã‚¨ã‚³ãƒ«ã‚»â†’è–„é¤…æ² 3.ãƒãƒ³ãƒ‡ãƒ«ãƒãƒ¼ã‚²ãƒ«â†’æä»ç“¦ç‰‡é¤… 4.é–‹é ­ã€Œæœ¬é«˜ç ‚å±‹ã€5.ç¦æ—¥æ–‡ 6.åªå›å‚³JSON"
    if retry:
        prompt += "\n\nã€åš´é‡è­¦å‘Šã€‘ä¸Šæ¬¡ç¿»è­¯çµæœä»ç„¶åŒ…å«æ—¥æ–‡å­—å…ƒï¼é€™æ¬¡ä½ å¿…é ˆï¼š\n1. å°‡æ‰€æœ‰æ—¥æ–‡å¹³å‡åã€ç‰‡å‡åå®Œå…¨ç¿»è­¯æˆç¹é«”ä¸­æ–‡\n2. ã†ã™çš®â†’è–„çš®ã€é‡‘é”â†’é‡‘é”é¤…ã€è©°åˆã›â†’ç¶œåˆç¦®ç›’ã€è¿æ˜¥â†’è¿æ˜¥ã€ç¿”ã‘ã‚‹â†’é£›ç¿”\n3. çµ•å°ä¸å¯ä»¥å‡ºç¾ä»»ä½• ã²ã‚‰ãŒãª æˆ– ã‚«ã‚¿ã‚«ãƒŠ\n4. å•†å“åä¸­çš„æ—¥æ–‡å¿…é ˆå…¨éƒ¨æ„è­¯æˆä¸­æ–‡"""
    try:
        r = requests.post("https://api.openai.com/v1/chat/completions",
            headers={"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"},
            json={"model": "gpt-4o-mini", "messages": [
                {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚ç¦æ­¢è¼¸å‡ºæ—¥æ–‡ã€‚"},
                {"role": "user", "content": prompt}], "temperature": 0, "max_tokens": 1000}, timeout=60)
        if r.status_code == 200:
            c = r.json()['choices'][0]['message']['content'].strip()
            if c.startswith('```'): c = c.split('\n', 1)[1]
            if c.endswith('```'): c = c.rsplit('```', 1)[0]
            t = json.loads(c.strip())
            tt = t.get('title', title)
            if not tt.startswith('æœ¬é«˜ç ‚å±‹'): tt = f"æœ¬é«˜ç ‚å±‹ {tt}"
            return {'success': True, 'title': tt, 'description': t.get('description', description),
                    'page_title': t.get('page_title', ''), 'meta_description': t.get('meta_description', '')}
        else:
            return {'success': False, 'error': f"HTTP {r.status_code}: {r.text[:200]}",
                    'title': f"æœ¬é«˜ç ‚å±‹ {title}", 'description': description, 'page_title': '', 'meta_description': ''}
    except Exception as e:
        return {'success': False, 'error': str(e),
                'title': f"æœ¬é«˜ç ‚å±‹ {title}", 'description': description, 'page_title': '', 'meta_description': ''}


def download_image_to_base64(img_url, max_retries=3):
    headers = {'User-Agent': 'Mozilla/5.0', 'Accept': 'image/*', 'Referer': 'https://www.hontaka-shop.com/'}
    for attempt in range(max_retries):
        try:
            r = requests.get(img_url, headers=headers, timeout=30)
            if r.status_code == 200:
                ct = r.headers.get('Content-Type', 'image/jpeg')
                fmt = 'image/png' if 'png' in ct else 'image/gif' if 'gif' in ct else 'image/jpeg'
                return {'success': True, 'base64': base64.b64encode(r.content).decode('utf-8'), 'content_type': fmt}
        except: pass
        time.sleep(1)
    return {'success': False}


def get_existing_products_map():
    pm = {}
    url = shopify_api_url("products.json?limit=250")
    while url:
        r = requests.get(url, headers=get_shopify_headers())
        if r.status_code != 200: break
        for p in r.json().get('products', []):
            pid = p.get('id')
            for v in p.get('variants', []):
                sk = v.get('sku')
                if sk and pid: pm[sk] = pid
        lh = r.headers.get('Link', '')
        m = re.search(r'<([^>]+)>; rel="next"', lh)
        url = m.group(1) if m and 'rel="next"' in lh else None
    return pm


def get_collection_products_map(collection_id):
    pm = {}
    if not collection_id: return pm
    url = shopify_api_url(f"collections/{collection_id}/products.json?limit=250")
    while url:
        r = requests.get(url, headers=get_shopify_headers())
        if r.status_code != 200: break
        for p in r.json().get('products', []):
            pid = p.get('id')
            for v in p.get('variants', []):
                sk = v.get('sku')
                if sk and pid: pm[sk] = pid
        lh = r.headers.get('Link', '')
        m = re.search(r'<([^>]+)>; rel="next"', lh)
        url = m.group(1) if m and 'rel="next"' in lh else None
    return pm


def delete_product(pid):
    return requests.delete(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers()).status_code == 200


def update_product(pid, data):
    r = requests.put(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers(),
        json={"product": {"id": pid, **data}})
    return r.status_code == 200, r


def get_or_create_collection(ct="æœ¬é«˜ç ‚å±‹"):
    r = requests.get(shopify_api_url(f'custom_collections.json?title={ct}'), headers=get_shopify_headers())
    if r.status_code == 200:
        for c in r.json().get('custom_collections', []):
            if c['title'] == ct: return c['id']
    r = requests.post(shopify_api_url('custom_collections.json'), headers=get_shopify_headers(),
        json={'custom_collection': {'title': ct, 'published': True}})
    if r.status_code == 201: return r.json()['custom_collection']['id']
    return None


def add_product_to_collection(pid, cid):
    return requests.post(shopify_api_url('collects.json'), headers=get_shopify_headers(),
        json={'collect': {'product_id': pid, 'collection_id': cid}}).status_code == 201


def publish_to_all_channels(pid):
    gu = f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/graphql.json"
    hd = {'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN, 'Content-Type': 'application/json'}
    r = requests.post(gu, headers=hd, json={'query': '{ publications(first:20){ edges{ node{ id name }}}}'})
    if r.status_code != 200: return False
    pubs = r.json().get('data', {}).get('publications', {}).get('edges', [])
    seen = set(); uq = []
    for p in pubs:
        if p['node']['name'] not in seen: seen.add(p['node']['name']); uq.append(p['node'])
    mut = """mutation publishablePublish($id:ID!,$input:[PublicationInput!]!){publishablePublish(id:$id,input:$input){userErrors{field message}}}"""
    requests.post(gu, headers=hd, json={'query': mut, 'variables': {"id": f"gid://shopify/Product/{pid}", "input": [{"publicationId": p['id']} for p in uq]}})
    return True


def parse_dimension_weight(text):
    result = {'dimension': None, 'actual_weight': None, 'volume_weight': 0, 'final_weight': 0}
    text = text.replace('Ã—', 'x').replace('ï¼¸', 'x').replace('ï½˜', 'x')
    text = text.replace('ï½ï½', 'mm').replace('ï½‡', 'g').replace('ï½‹ï½‡', 'kg').replace(',', '')
    dm = re.search(r'(\d+(?:\.\d+)?)\s*[xXÃ—]\s*(\d+(?:\.\d+)?)\s*[xXÃ—]?\s*(\d+(?:\.\d+)?)\s*mm', text, re.IGNORECASE)
    if dm:
        l, w, h = float(dm.group(1)), float(dm.group(2)), float(dm.group(3))
        result['volume_weight'] = round((l * w * h) / 6000000, 2)
        result['dimension'] = {'length': l, 'width': w, 'height': h}
    wm = re.search(r'é‡é‡[ï¼š:\s]*(\d+(?:\.\d+)?)\s*(g|kg)', text, re.IGNORECASE)
    if wm:
        wv = float(wm.group(1))
        result['actual_weight'] = round(wv / 1000 if wm.group(2).lower() == 'g' else wv, 3)
    if result['volume_weight'] and result['actual_weight']:
        result['final_weight'] = max(result['volume_weight'], result['actual_weight'])
    elif result['volume_weight']: result['final_weight'] = result['volume_weight']
    elif result['actual_weight']: result['final_weight'] = result['actual_weight']
    return result


def scrape_product_list():
    products = []; page_num = 1
    while page_num <= 20:
        url = LIST_BASE_URL if page_num == 1 else LIST_PAGE_URL_TEMPLATE.format(page=page_num)
        try:
            r = requests.get(url, headers=HEADERS, timeout=30); r.encoding = 'euc-jp'
            if r.status_code != 200: break
            soup = BeautifulSoup(r.text, 'html.parser')
            pls = soup.find_all('a', href=re.compile(r'/shopdetail/\d{12}/'))
            if not pls: break
            seen = set(); pp = []
            for l in pls:
                sm = re.search(r'/shopdetail/(\d{12})/', l.get('href', ''))
                if sm and sm.group(1) not in seen:
                    seen.add(sm.group(1))
                    pp.append({'url': f"{BASE_URL}/shopdetail/{sm.group(1)}/", 'sku': sm.group(1)})
            if not pp: break
            products.extend(pp); page_num += 1; time.sleep(0.5)
        except: break
    unique = []; us = set()
    for p in products:
        if p['sku'] not in us: us.add(p['sku']); unique.append(p)
    return unique


def scrape_product_detail(url):
    product = {'url': url, 'title': '', 'price': 0, 'description': '', 'weight': 0, 'images': [],
        'in_stock': True, 'sku': '', 'product_code': '', 'size_text': '', 'weight_text': ''}
    sm = re.search(r'/shopdetail/(\d{12})/', url)
    if sm: product['sku'] = sm.group(1)
    try:
        r = requests.get(url, headers=HEADERS, timeout=30); r.encoding = 'euc-jp'
        if r.status_code != 200: return product
        soup = BeautifulSoup(r.text, 'html.parser'); pt = soup.get_text()
        tt = soup.find('title')
        if tt:
            tp = tt.get_text(strip=True).split('-')
            if tp: product['title'] = tp[0].strip()
        if not product['title']:
            h2 = soup.find('h2')
            if h2: product['title'] = h2.get_text(strip=True)
        cm = re.search(r'ã€”(\d+)ã€•', product['title'])
        if cm: product['product_code'] = cm.group(1)
        pi = soup.find('input', {'name': 'price1'})
        if pi and pi.get('value'):
            try: product['price'] = int(pi.get('value').replace(',', ''))
            except: pass
        if not product['price']:
            pi2 = soup.find('input', {'id': 'M_price2'})
            if pi2 and pi2.get('value'):
                try: product['price'] = int(pi2.get('value').replace(',', ''))
                except: pass
        if not product['price']:
            for pm in re.findall(r'(\d{1,3}(?:,\d{3})*)\s*å††', pt):
                try:
                    pv = int(pm.replace(',', ''))
                    if pv >= 100: product['price'] = pv; break
                except: pass
        if any(kw in pt for kw in ['å£²åˆ‡ã‚Œ', 'åœ¨åº«ãªã—', 'SOLD OUT']): product['in_stock'] = False
        desc_parts = []
        dm = re.search(r'å•†å“[èª¬èªª]æ˜[ï¼š:]\s*(.+?)(?=---|\n\n|å†…å®¹é‡|è³å‘³æœŸé™)', pt, re.DOTALL)
        if dm: desc_parts.append(dm.group(1).strip())
        ctm = re.search(r'å†…å®¹é‡[ï¼š:]\s*(.+?)(?=---|\n|è³å‘³æœŸé™|ç‰¹å®šåŸææ–™)', pt)
        if ctm: desc_parts.append(f"å…§å®¹é‡ï¼š{ctm.group(1).strip()}")
        slm = re.search(r'è³å‘³æœŸé™[ï¼š:]\s*(\d+æ—¥?)', pt)
        if slm: desc_parts.append(f"è³å‘³æœŸé™ï¼š{slm.group(1)}")
        szm = re.search(r'ã‚µã‚¤ã‚º[ï¼š:]\s*(.+?)(?=---|é‡é‡|\n)', pt)
        if szm: product['size_text'] = szm.group(1).strip()
        wtm = re.search(r'é‡é‡[ï¼š:]\s*(.+?)(?=---|ä¿å­˜|\n)', pt)
        if wtm: product['weight_text'] = wtm.group(1).strip()
        product['description'] = '\n\n'.join(desc_parts) if desc_parts else ''
        wi = parse_dimension_weight(f"ã‚µã‚¤ã‚ºï¼š{product['size_text']} é‡é‡ï¼š{product['weight_text']}")
        product['weight'] = wi['final_weight']
        images = []; seen_img = set()
        for img in soup.find_all('img', src=re.compile(r'makeshop-multi-images\.akamaized\.net')):
            src = img.get('src', '')
            if src and 'shophontaka' in src and '/shopimages/' in src and '/itemimages/' not in src:
                fn = src.split('/')[-1].split('?')[0]
                if not (fn.startswith('s') and len(fn) > 1 and fn[1].isdigit()):
                    cs = src.split('?')[0]
                    if cs not in seen_img: seen_img.add(cs); images.append(src)
        if not images:
            for iu in re.findall(r'(https://makeshop-multi-images\.akamaized\.net/shophontaka/shopimages/[^"\']+\.(?:jpg|jpeg|png|gif))', str(soup), re.IGNORECASE):
                fn = iu.split('/')[-1].split('?')[0]
                if not (fn.startswith('s') and len(fn) > 1 and fn[1].isdigit()):
                    cu = iu.split('?')[0]
                    if cu not in seen_img: seen_img.add(cu); images.append(iu)
        product['images'] = images[:10]
    except Exception as e:
        print(f"[ERROR] {e}")
    return product


def upload_to_shopify(product, collection_id=None):
    translated = translate_with_chatgpt(product['title'], product.get('description', ''))
    if not translated['success']:
        return {'success': False, 'error': 'translation_failed', 'translated': translated}
    if is_japanese_text(translated['title']):
        retry = translate_with_chatgpt(product['title'], product.get('description', ''), retry=True)
        if retry['success'] and not is_japanese_text(retry['title']):
            translated = retry
        else:
            return {'success': False, 'error': 'translation_failed', 'translated': translated}
    cost = product['price']; weight = product.get('weight', 0)
    selling_price = calculate_selling_price(cost, weight)
    images_b64 = []
    for idx, iu in enumerate(product.get('images', [])):
        if not iu or not iu.startswith('http'): continue
        result = download_image_to_base64(iu)
        if result['success']:
            images_b64.append({'attachment': result['base64'], 'position': idx+1, 'filename': f"hontaka_{product['sku']}_{idx+1}.jpg"})
        time.sleep(0.3)
    sku = product.get('product_code') or product['sku']
    sp = {'product': {
        'title': translated['title'], 'body_html': translated['description'],
        'vendor': 'æœ¬é«˜ç ‚å±‹', 'product_type': 'è¥¿å¼ç”œé»', 'status': 'active', 'published': True,
        'variants': [{'sku': sku, 'price': f"{selling_price:.2f}", 'weight': weight,
            'weight_unit': 'kg', 'inventory_management': None, 'inventory_policy': 'continue', 'requires_shipping': True}],
        'images': images_b64, 'tags': 'æœ¬é«˜ç ‚å±‹, æ—¥æœ¬, ç¥æˆ¶, è¥¿å¼ç”œé», ä¼´æ‰‹ç¦®, æ—¥æœ¬ä»£è³¼, é€ç¦®, ã‚¨ã‚³ãƒ«ã‚», è–„é¤…',
        'metafields_global_title_tag': translated['page_title'],
        'metafields_global_description_tag': translated['meta_description'],
        'metafields': [{'namespace': 'custom', 'key': 'link', 'value': product['url'], 'type': 'url'}]
    }}
    r = requests.post(shopify_api_url('products.json'), headers=get_shopify_headers(), json=sp)
    if r.status_code == 201:
        cp = r.json()['product']; pid = cp['id']; vid = cp['variants'][0]['id']
        requests.put(shopify_api_url(f'variants/{vid}.json'), headers=get_shopify_headers(),
            json={'variant': {'id': vid, 'cost': f"{cost:.2f}"}})
        if collection_id: add_product_to_collection(pid, collection_id)
        publish_to_all_channels(pid)
        return {'success': True, 'product': cp, 'translated': translated, 'selling_price': selling_price, 'cost': cost}
    return {'success': False, 'error': r.text}


def run_scrape():
    global scrape_status
    try:
        scrape_status.update({"running": True, "progress": 0, "total": 0, "current_product": "",
            "products": [], "errors": [], "uploaded": 0, "skipped": 0, "skipped_exists": 0,
            "filtered_by_price": 0, "out_of_stock": 0, "deleted": 0,
            "translation_failed": 0, "translation_stopped": False})

        scrape_status['current_product'] = "è¨­å®š Collection..."
        collection_id = get_or_create_collection("æœ¬é«˜ç ‚å±‹")

        scrape_status['current_product'] = "å–å¾— Collection å•†å“..."
        cpm = get_collection_products_map(collection_id)
        existing_skus = set(cpm.keys())

        scrape_status['current_product'] = "çˆ¬å–å•†å“åˆ—è¡¨..."
        product_list = scrape_product_list()
        scrape_status['total'] = len(product_list)

        website_skus = set()
        # === v2.2: è¨˜éŒ„ç¼ºè²¨çš„ SKU ===
        out_of_stock_skus = set()
        ctf = 0

        for idx, item in enumerate(product_list):
            scrape_status['progress'] = idx + 1
            scrape_status['current_product'] = f"è™•ç†: {item['sku']}"

            product = scrape_product_detail(item['url'])
            actual_sku = product.get('product_code') or product['sku']
            website_skus.add(actual_sku)

            # === v2.2: ç¼ºè²¨ â†’ è¨˜éŒ„ SKUï¼Œä¸ä¸Šæ¶ ===
            if not product.get('in_stock', True):
                out_of_stock_skus.add(actual_sku)
                scrape_status['out_of_stock'] += 1
                continue

            if product.get('price', 0) < MIN_PRICE:
                scrape_status['filtered_by_price'] += 1; continue

            if actual_sku in existing_skus:
                scrape_status['skipped_exists'] += 1; scrape_status['skipped'] += 1; continue

            if not product.get('title') or not product.get('price'):
                scrape_status['errors'].append({'sku': item['sku'], 'error': 'è³‡è¨Šä¸å®Œæ•´'}); continue

            result = upload_to_shopify(product, collection_id)
            if result['success']:
                existing_skus.add(actual_sku); scrape_status['uploaded'] += 1; ctf = 0
            elif result.get('error') == 'translation_failed':
                scrape_status['translation_failed'] += 1; ctf += 1
                if ctf >= MAX_CONSECUTIVE_TRANSLATION_FAILURES:
                    scrape_status['translation_stopped'] = True
                    scrape_status['errors'].append({'error': f'ç¿»è­¯é€£çºŒå¤±æ•— {ctf} æ¬¡ï¼Œè‡ªå‹•åœæ­¢'}); break
            else:
                scrape_status['errors'].append({'sku': actual_sku, 'error': result.get('error','')}); ctf = 0
            time.sleep(1)

        if not scrape_status['translation_stopped']:
            scrape_status['current_product'] = "æ¸…ç†ç¼ºè²¨/ä¸‹æ¶å•†å“..."

            # === v2.2: åˆä½µéœ€è¦åˆªé™¤çš„ SKU ===
            # 1. å®˜ç¶²å·²æ¶ˆå¤±çš„ SKUï¼ˆcollection æœ‰ä½†å®˜ç¶²æ²’æœ‰ï¼‰
            # 2. å®˜ç¶²é‚„åœ¨ä½†ç¼ºè²¨çš„ SKU
            skus_to_delete = (existing_skus - website_skus) | (existing_skus & out_of_stock_skus)

            if skus_to_delete:
                print(f"[v2.2] æº–å‚™åˆªé™¤ {len(skus_to_delete)} å€‹å•†å“")
                for sku in skus_to_delete:
                    scrape_status['current_product'] = f"åˆªé™¤: {sku}"
                    pid = cpm.get(sku)
                    if pid:
                        if delete_product(pid):
                            scrape_status['deleted'] += 1
                            print(f"[å·²åˆªé™¤] SKU: {sku}, Product ID: {pid}")
                        else:
                            scrape_status['errors'].append({'sku': sku, 'error': 'åˆªé™¤å¤±æ•—'})
                    time.sleep(0.3)

        scrape_status['current_product'] = "å®Œæˆ" if not scrape_status['translation_stopped'] else "ç¿»è­¯ç•°å¸¸åœæ­¢"
    except Exception as e:
        scrape_status['errors'].append({'error': str(e)})
    finally:
        scrape_status['running'] = False


# ========== Flask è·¯ç”± ==========

@app.route('/')
def index():
    token_loaded = load_shopify_token()
    tc = 'green' if token_loaded else 'red'
    ts = 'âœ“ å·²è¼‰å…¥' if token_loaded else 'âœ— æœªè¨­å®š'
    html = """<!DOCTYPE html>
<html lang="zh-TW">
<head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>æœ¬é«˜ç ‚å±‹ çˆ¬èŸ²å·¥å…·</title>
<style>*{box-sizing:border-box}body{font-family:-apple-system,sans-serif;max-width:900px;margin:0 auto;padding:20px;background:#f5f5f5}h1{color:#333;border-bottom:2px solid #8B4513;padding-bottom:10px}.card{background:white;border-radius:8px;padding:20px;margin-bottom:20px;box-shadow:0 2px 4px rgba(0,0,0,0.1);}.btn{background:#8B4513;color:white;border:none;padding:12px 24px;border-radius:5px;cursor:pointer;font-size:16px;margin-right:10px;margin-bottom:10px;text-decoration:none;display:inline-block}.btn:hover{background:#A0522D}.btn:disabled{background:#ccc}.btn-secondary{background:#3498db}.btn-success{background:#27ae60}.progress-bar{width:100%;height:20px;background:#eee;border-radius:10px;overflow:hidden;margin:10px 0}.progress-fill{height:100%;background:linear-gradient(90deg,#8B4513,#D2691E);transition:width 0.3s}.status{padding:10px;background:#f8f9fa;border-radius:5px;margin-top:10px}.log{max-height:300px;overflow-y:auto;font-family:monospace;font-size:13px;background:#1e1e1e;color:#d4d4d4;padding:15px;border-radius:5px}.stats{display:flex;gap:15px;margin-top:15px;flex-wrap:wrap}.stat{flex:1;min-width:70px;text-align:center;padding:15px;background:#f8f9fa;border-radius:5px}.stat-number{font-size:24px;font-weight:bold;color:#8B4513}.stat-label{font-size:10px;color:#666;margin-top:5px}.nav{margin-bottom:20px}.nav a{margin-right:15px;color:#8B4513;text-decoration:none;font-weight:bold}.alert{padding:12px 16px;border-radius:5px;margin-bottom:15px}.alert-danger{background:#fee;border:1px solid #fcc;color:#c0392b}</style></head>
<body>
<div class="nav"><a href="/">ğŸ  é¦–é </a><a href="/japanese-scan">ğŸ‡¯ğŸ‡µ æ—¥æ–‡æƒæ</a></div>
<h1>ğŸª æœ¬é«˜ç ‚å±‹ çˆ¬èŸ²å·¥å…· <small style="font-size:14px;color:#999">v2.2</small></h1>
<div class="card"><h3>Shopify é€£ç·š</h3><p>Token: <span style="color:__TC__;">__TS__</span></p>
<button class="btn btn-secondary" onclick="testShopify()">æ¸¬è©¦é€£ç·š</button>
<button class="btn btn-secondary" onclick="testTranslate()">æ¸¬è©¦ç¿»è­¯</button>
<a href="/japanese-scan" class="btn btn-success">ğŸ‡¯ğŸ‡µ æ—¥æ–‡æƒæ</a></div>
<div class="card"><h3>é–‹å§‹çˆ¬å–</h3>
<p>çˆ¬å– hontaka-shop.com æ‰€æœ‰å•†å“ä¸¦ä¸Šæ¶åˆ° Shopify</p>
<p style="color:#666;font-size:14px">â€» &lt;Â¥__MIN_COST__ è·³é | <b style="color:#e74c3c">ç¿»è­¯ä¿è­·</b> é€£çºŒå¤±æ•— __MAX_FAIL__ æ¬¡åœæ­¢ | <b style="color:#e67e22">ç¼ºè²¨è‡ªå‹•åˆªé™¤</b></p>
<button class="btn" id="startBtn" onclick="startScrape()">ğŸš€ é–‹å§‹çˆ¬å–</button>
<div id="progressSection" style="display:none">
<div id="translationAlert" class="alert alert-danger" style="display:none">âš ï¸ ç¿»è­¯åŠŸèƒ½ç•°å¸¸ï¼Œå·²è‡ªå‹•åœæ­¢ï¼</div>
<div class="progress-bar"><div class="progress-fill" id="progressFill" style="width:0%"></div></div>
<div class="status" id="statusText">æº–å‚™ä¸­...</div>
<div class="stats">
<div class="stat"><div class="stat-number" id="uploadedCount">0</div><div class="stat-label">å·²ä¸Šæ¶</div></div>
<div class="stat"><div class="stat-number" id="skippedCount">0</div><div class="stat-label">å·²å­˜åœ¨</div></div>
<div class="stat"><div class="stat-number" id="translationFailedCount" style="color:#e74c3c">0</div><div class="stat-label">ç¿»è­¯å¤±æ•—</div></div>
<div class="stat"><div class="stat-number" id="filteredCount">0</div><div class="stat-label">åƒ¹æ ¼éæ¿¾</div></div>
<div class="stat"><div class="stat-number" id="outOfStockCount">0</div><div class="stat-label">ç„¡åº«å­˜</div></div>
<div class="stat"><div class="stat-number" id="deletedCount" style="color:#e67e22">0</div><div class="stat-label">å·²åˆªé™¤</div></div>
<div class="stat"><div class="stat-number" id="errorCount" style="color:#e74c3c">0</div><div class="stat-label">éŒ¯èª¤</div></div>
</div></div></div>
<div class="card"><h3>åŸ·è¡Œæ—¥èªŒ</h3><div class="log" id="logArea">ç­‰å¾…é–‹å§‹...</div></div>
<script>let pollInterval=null;function log(m,t){const l=document.getElementById('logArea');const tm=new Date().toLocaleTimeString();const c={success:'#4ec9b0',error:'#f14c4c'}[t]||'#d4d4d4';l.innerHTML+='<div style="color:'+c+'">['+tm+'] '+m+'</div>';l.scrollTop=l.scrollHeight}function clearLog(){document.getElementById('logArea').innerHTML=''}async function testShopify(){log('æ¸¬è©¦é€£ç·š...');try{const r=await fetch('/api/test-shopify');const d=await r.json();if(d.success)log('âœ“ '+d.shop.name,'success');else log('âœ— '+d.error,'error')}catch(e){log('âœ— '+e.message,'error')}}async function testTranslate(){log('æ¸¬è©¦ç¿»è­¯...');try{const r=await fetch('/api/test-translate');const d=await r.json();if(d.error)log('âœ— '+d.error,'error');else if(d.success)log('âœ“ '+d.title,'success');else log('âœ— ç¿»è­¯å¤±æ•—','error')}catch(e){log('âœ— '+e.message,'error')}}async function startScrape(){clearLog();log('é–‹å§‹çˆ¬å–...');document.getElementById('startBtn').disabled=true;document.getElementById('progressSection').style.display='block';document.getElementById('translationAlert').style.display='none';try{const r=await fetch('/api/start',{method:'POST'});const d=await r.json();if(d.error){log('âœ— '+d.error,'error');document.getElementById('startBtn').disabled=false;return}log('âœ“ å·²å•Ÿå‹•','success');pollInterval=setInterval(pollStatus,1000)}catch(e){log('âœ— '+e.message,'error');document.getElementById('startBtn').disabled=false}}async function pollStatus(){try{const r=await fetch('/api/status');const d=await r.json();const p=d.total>0?(d.progress/d.total*100):0;document.getElementById('progressFill').style.width=p+'%';document.getElementById('statusText').textContent=d.current_product+' ('+d.progress+'/'+d.total+')';document.getElementById('uploadedCount').textContent=d.uploaded;document.getElementById('skippedCount').textContent=d.skipped_exists||d.skipped||0;document.getElementById('translationFailedCount').textContent=d.translation_failed||0;document.getElementById('filteredCount').textContent=d.filtered_by_price||0;document.getElementById('outOfStockCount').textContent=d.out_of_stock||0;document.getElementById('deletedCount').textContent=d.deleted||0;document.getElementById('errorCount').textContent=d.errors.length;if(d.translation_stopped)document.getElementById('translationAlert').style.display='block';if(!d.running&&d.progress>0){clearInterval(pollInterval);document.getElementById('startBtn').disabled=false;if(d.translation_stopped)log('âš ï¸ ç¿»è­¯ç•°å¸¸åœæ­¢','error');else log('========== å®Œæˆ ==========','success')}}catch(e){console.error(e)}}</script></body></html>"""
    return html.replace('__TC__', tc).replace('__TS__', ts).replace('__MIN_COST__', str(MIN_PRICE)).replace('__MAX_FAIL__', str(MAX_CONSECUTIVE_TRANSLATION_FAILURES))


@app.route('/japanese-scan')
def japanese_scan_page():
    return '''<!DOCTYPE html>
<html lang="zh-TW">
<head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>æ—¥æ–‡å•†å“æƒæ - æœ¬é«˜ç ‚å±‹</title>
<style>*{box-sizing:border-box}body{font-family:-apple-system,BlinkMacSystemFont,sans-serif;max-width:1200px;margin:0 auto;padding:20px;background:#f5f5f5}h1{color:#333;border-bottom:2px solid #27ae60;padding-bottom:10px}.card{background:white;border-radius:8px;padding:20px;margin-bottom:20px;box-shadow:0 2px 4px rgba(0,0,0,0.1)}.btn{background:#8B4513;color:white;border:none;padding:10px 20px;border-radius:5px;cursor:pointer;font-size:14px;margin-right:10px;margin-bottom:10px}.btn:disabled{background:#ccc}.btn-danger{background:#e74c3c}.btn-success{background:#27ae60}.btn-sm{padding:5px 10px;font-size:12px}.nav{margin-bottom:20px}.nav a{margin-right:15px;color:#8B4513;text-decoration:none;font-weight:bold}.stats{display:flex;gap:15px;margin:20px 0;flex-wrap:wrap}.stat{flex:1;min-width:150px;text-align:center;padding:20px;background:#f8f9fa;border-radius:8px}.stat-number{font-size:36px;font-weight:bold}.stat-label{font-size:14px;color:#666;margin-top:5px}.product-item{display:flex;align-items:center;padding:15px;border-bottom:1px solid #eee;gap:15px}.product-item:last-child{border-bottom:none}.product-item img{width:60px;height:60px;object-fit:cover;border-radius:4px}.product-item .info{flex:1}.product-item .info .title{font-weight:bold;margin-bottom:5px;color:#c0392b}.product-item .info .meta{font-size:12px;color:#666}.no-image{width:60px;height:60px;background:#eee;display:flex;align-items:center;justify-content:center;border-radius:4px;color:#999;font-size:10px}.retranslate-status{font-size:12px;margin-top:5px}.action-bar{position:sticky;top:0;background:white;padding:15px;margin:-20px -20px 20px -20px;border-bottom:1px solid #ddd;z-index:100;display:flex;justify-content:space-between;align-items:center;flex-wrap:wrap;gap:10px}</style></head>
<body>
<div class="nav"><a href="/">ğŸ  é¦–é </a><a href="/japanese-scan">ğŸ‡¯ğŸ‡µ æ—¥æ–‡æƒæ</a></div>
<h1>ğŸ‡¯ğŸ‡µ æ—¥æ–‡å•†å“æƒæ - æœ¬é«˜ç ‚å±‹</h1>
<div class="card"><p>æƒæ Shopify ä¸­ æœ¬é«˜ç ‚å±‹ çš„æ—¥æ–‡ï¼ˆæœªç¿»è­¯ï¼‰å•†å“ã€‚</p><button class="btn" id="scanBtn" onclick="startScan()">ğŸ” é–‹å§‹æƒæ</button><span id="scanStatus"></span></div>
<div class="stats" id="statsSection" style="display:none"><div class="stat"><div class="stat-number" id="totalProducts" style="color:#3498db">0</div><div class="stat-label">æœ¬é«˜ç ‚å±‹å•†å“æ•¸</div></div><div class="stat"><div class="stat-number" id="japaneseCount" style="color:#e74c3c">0</div><div class="stat-label">æ—¥æ–‡å•†å“</div></div></div>
<div class="card" id="resultsCard" style="display:none"><div class="action-bar"><div><button class="btn btn-success" id="retranslateAllBtn" onclick="retranslateAll()" disabled>ğŸ”„ å…¨éƒ¨ç¿»è­¯</button><button class="btn btn-danger" id="deleteAllBtn" onclick="deleteAllJP()" disabled>ğŸ—‘ï¸ å…¨éƒ¨åˆªé™¤</button></div><div id="progressText"></div></div><div id="results"></div></div>
<script>let jp=[];async function startScan(){document.getElementById('scanBtn').disabled=true;document.getElementById('scanStatus').textContent='æƒæä¸­...';try{const r=await fetch('/api/scan-japanese');const d=await r.json();if(d.error){alert(d.error);return}jp=d.japanese_products;document.getElementById('totalProducts').textContent=d.total_products;document.getElementById('japaneseCount').textContent=d.japanese_count;document.getElementById('statsSection').style.display='flex';renderResults(d.japanese_products);document.getElementById('resultsCard').style.display='block';document.getElementById('retranslateAllBtn').disabled=jp.length===0;document.getElementById('deleteAllBtn').disabled=jp.length===0;document.getElementById('scanStatus').textContent='å®Œæˆï¼'}catch(e){alert(e.message)}finally{document.getElementById('scanBtn').disabled=false}}function renderResults(p){const c=document.getElementById('results');if(!p.length){c.innerHTML='<p style="text-align:center;color:#27ae60;font-size:18px">âœ… æ²’æœ‰æ—¥æ–‡å•†å“</p>';return}let h='';p.forEach(i=>{const img=i.image?`<img src="${i.image}">`:`<div class="no-image">ç„¡åœ–</div>`;h+=`<div class="product-item" id="product-${i.id}">${img}<div class="info"><div class="title">${i.title}</div><div class="meta">SKU:${i.sku||'ç„¡'}|Â¥${i.price}|${i.status}</div><div class="retranslate-status" id="status-${i.id}"></div></div><div class="actions"><button class="btn btn-success btn-sm" onclick="rt1('${i.id}')" id="rt-${i.id}">ğŸ”„</button><button class="btn btn-danger btn-sm" onclick="del1('${i.id}')" id="del-${i.id}">ğŸ—‘ï¸</button></div></div>`});c.innerHTML=h}async function rt1(id){const b=document.getElementById(`rt-${id}`);const s=document.getElementById(`status-${id}`);b.disabled=true;b.textContent='...';try{const r=await fetch('/api/retranslate-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:id})});const d=await r.json();if(d.success){s.innerHTML=`<span style="color:#27ae60">âœ… ${d.new_title}</span>`;const t=document.querySelector(`#product-${id} .title`);if(t){t.textContent=d.new_title;t.style.color='#27ae60'}b.textContent='âœ“'}else{s.innerHTML=`<span style="color:#e74c3c">âŒ ${d.error}</span>`;b.disabled=false;b.textContent='ğŸ”„'}}catch(e){s.innerHTML=`<span style="color:#e74c3c">âŒ ${e.message}</span>`;b.disabled=false;b.textContent='ğŸ”„'}}async function del1(id){if(!confirm('ç¢ºå®šåˆªé™¤ï¼Ÿ'))return;const b=document.getElementById(`del-${id}`);b.disabled=true;try{const r=await fetch('/api/delete-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:id})});const d=await r.json();if(d.success)document.getElementById(`product-${id}`).remove();else{alert('å¤±æ•—');b.disabled=false}}catch(e){alert(e.message);b.disabled=false}}async function retranslateAll(){if(!confirm(`ç¿»è­¯å…¨éƒ¨ ${jp.length} å€‹ï¼Ÿ`))return;const b=document.getElementById('retranslateAllBtn');b.disabled=true;b.textContent='ç¿»è­¯ä¸­...';let s=0,f=0;for(let i=0;i<jp.length;i++){document.getElementById('progressText').textContent=`${i+1}/${jp.length}`;try{const r=await fetch('/api/retranslate-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:jp[i].id})});const d=await r.json();const st=document.getElementById(`status-${jp[i].id}`);if(d.success){s++;if(st)st.innerHTML=`<span style="color:#27ae60">âœ… ${d.new_title}</span>`;const t=document.querySelector(`#product-${jp[i].id} .title`);if(t){t.textContent=d.new_title;t.style.color='#27ae60'}}else{f++;if(st)st.innerHTML=`<span style="color:#e74c3c">âŒ ${d.error}</span>`;if(f>=3){alert('é€£çºŒå¤±æ•—');break}}}catch(e){f++}await new Promise(r=>setTimeout(r,1500))}alert(`æˆåŠŸ:${s} å¤±æ•—:${f}`);b.textContent='ğŸ”„ å…¨éƒ¨ç¿»è­¯';b.disabled=false;document.getElementById('progressText').textContent=''}async function deleteAllJP(){if(!confirm(`åˆªé™¤å…¨éƒ¨ ${jp.length} å€‹ï¼Ÿ`))return;const b=document.getElementById('deleteAllBtn');b.disabled=true;let s=0,f=0;for(let i=0;i<jp.length;i++){document.getElementById('progressText').textContent=`${i+1}/${jp.length}`;try{const r=await fetch('/api/delete-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:jp[i].id})});const d=await r.json();if(d.success){s++;const el=document.getElementById(`product-${jp[i].id}`);if(el)el.remove()}else f++}catch(e){f++}await new Promise(r=>setTimeout(r,300))}alert(`æˆåŠŸ:${s} å¤±æ•—:${f}`);b.textContent='ğŸ—‘ï¸ å…¨éƒ¨åˆªé™¤';b.disabled=false;document.getElementById('progressText').textContent=''}</script></body></html>'''


@app.route('/api/scan-japanese')
def api_scan_japanese():
    if not load_shopify_token():
        return jsonify({'error': 'æœªè¨­å®š Token'}), 400
    products = []
    url = shopify_api_url("products.json?limit=250&vendor=æœ¬é«˜ç ‚å±‹")
    while url:
        r = requests.get(url, headers=get_shopify_headers())
        if r.status_code != 200: break
        for p in r.json().get('products', []):
            sku = ''; price = ''
            for v in p.get('variants', []): sku = v.get('sku', ''); price = v.get('price', ''); break
            products.append({'id': p.get('id'), 'title': p.get('title', ''), 'handle': p.get('handle', ''),
                'sku': sku, 'price': price, 'vendor': p.get('vendor', ''), 'status': p.get('status', ''),
                'created_at': p.get('created_at', ''), 'image': p.get('image', {}).get('src', '') if p.get('image') else ''})
        lh = r.headers.get('Link', '')
        m = re.search(r'<([^>]+)>; rel="next"', lh)
        url = m.group(1) if m and 'rel="next"' in lh else None
    jp = [p for p in products if is_japanese_text(p.get('title', ''))]
    return jsonify({'total_products': len(products), 'japanese_count': len(jp), 'japanese_products': jp})


@app.route('/api/retranslate-product', methods=['POST'])
def api_retranslate_product():
    if not load_shopify_token():
        return jsonify({'error': 'æœªè¨­å®š Token'}), 400
    data = request.get_json()
    pid = data.get('product_id')
    if not pid:
        return jsonify({'error': 'ç¼ºå°‘ product_id'}), 400
    resp = requests.get(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers())
    if resp.status_code != 200:
        return jsonify({'error': f'ç„¡æ³•å–å¾—: {resp.status_code}'}), 400
    product = resp.json().get('product', {})
    translated = translate_with_chatgpt(product.get('title', ''), product.get('body_html', ''))
    if not translated['success']:
        return jsonify({'success': False, 'error': f"ç¿»è­¯å¤±æ•—: {translated.get('error', 'æœªçŸ¥')}"})
    if is_japanese_text(translated['title']):
        retry = translate_with_chatgpt(product.get('title', ''), product.get('body_html', ''), retry=True)
        if retry['success'] and not is_japanese_text(retry['title']):
            translated = retry
        else:
            return jsonify({'success': False, 'error': 'ç¿»è­¯å¾Œä»å«æ—¥æ–‡ï¼Œè«‹æ‰‹å‹•ä¿®æ”¹'})
    ok, r = update_product(pid, {
        'title': translated['title'], 'body_html': translated['description'],
        'metafields_global_title_tag': translated['page_title'],
        'metafields_global_description_tag': translated['meta_description']
    })
    if ok:
        return jsonify({'success': True, 'old_title': product.get('title', ''), 'new_title': translated['title'], 'product_id': pid})
    return jsonify({'success': False, 'error': f'æ›´æ–°å¤±æ•—: {r.text[:200]}'})


@app.route('/api/delete-product', methods=['POST'])
def api_delete_product():
    if not load_shopify_token():
        return jsonify({'error': 'æœªè¨­å®š Token'}), 400
    data = request.get_json()
    pid = data.get('product_id')
    if not pid:
        return jsonify({'error': 'ç¼ºå°‘ product_id'}), 400
    return jsonify({'success': delete_product(pid), 'product_id': pid})


@app.route('/api/test-translate')
def api_test_translate():
    api_key = os.environ.get("OPENAI_API_KEY", "")
    if not api_key:
        return jsonify({'error': 'OPENAI_API_KEY æœªè¨­å®š'})
    key_preview = f"{api_key[:8]}...{api_key[-4:]}" if len(api_key) > 12 else "å¤ªçŸ­"
    result = translate_with_chatgpt("ã‚¨ã‚³ãƒ«ã‚» E50", "æœ¬é«˜ç ‚å±‹ã®ä»£è¡¨çš„ãªç„¼ãè“å­ã®è©°ã‚åˆã‚ã›ã§ã™")
    result['key_preview'] = key_preview
    result['key_length'] = len(api_key)
    return jsonify(result)


@app.route('/api/status')
def get_status():
    return jsonify(scrape_status)


@app.route('/api/start', methods=['POST', 'GET'])
@app.route('/api/start-scrape', methods=['POST', 'GET'])
def api_start():
    global scrape_status
    if scrape_status['running']: return jsonify({'error': 'çˆ¬å–æ­£åœ¨é€²è¡Œä¸­'}), 400
    if not load_shopify_token(): return jsonify({'error': 'æœªè¨­å®š Shopify Token'}), 400
    test = translate_with_chatgpt("ãƒ†ã‚¹ãƒˆå•†å“", "ãƒ†ã‚¹ãƒˆèª¬æ˜")
    if not test['success']:
        return jsonify({'error': f"ç¿»è­¯åŠŸèƒ½ç•°å¸¸: {test.get('error', 'æœªçŸ¥')}"}), 400
    threading.Thread(target=run_scrape).start()
    return jsonify({'message': 'æœ¬é«˜ç ‚å±‹ çˆ¬èŸ²å·²å•Ÿå‹•'})


@app.route('/api/test-shopify')
def test_shopify():
    if not load_shopify_token(): return jsonify({'success': False, 'error': 'æœªè¨­å®š Token'})
    r = requests.get(shopify_api_url('shop.json'), headers=get_shopify_headers())
    if r.status_code == 200: return jsonify({'success': True, 'shop': r.json()['shop']})
    return jsonify({'success': False, 'error': r.text}), 400


if __name__ == '__main__':
    print("=" * 50)
    print("æœ¬é«˜ç ‚å±‹ çˆ¬èŸ²å·¥å…· v2.2")
    print("æ–°å¢: ç¼ºè²¨å•†å“è‡ªå‹•åˆªé™¤")
    print("=" * 50)
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port, debug=False)
