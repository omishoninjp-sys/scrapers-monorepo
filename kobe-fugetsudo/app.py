"""
ç¥æˆ¶é¢¨æœˆå ‚å•†å“çˆ¬èŸ² + Shopify ä¸Šæ¶å·¥å…·
åŠŸèƒ½ï¼š
1. çˆ¬å– shop.fugetsudo-kobe.jp æ‰€æœ‰åˆ†é å•†å“
2. éæ¿¾æˆæœ¬åƒ¹ä½æ–¼ 1000 å††çš„å•†å“
3. è¨ˆç®—æç©é‡é‡ vs å¯¦éš›é‡é‡ï¼Œå–å¤§å€¼
4. ä¸Šæ¶åˆ° Shopifyï¼ˆä¸é‡è¤‡ä¸Šæ¶ï¼‰
5. åŸåƒ¹å¯«å…¥æˆæœ¬åƒ¹ï¼ˆCostï¼‰
"""

from flask import Flask, render_template, jsonify, request
import requests
from bs4 import BeautifulSoup
import re
import json
import os
import sys
import time
from urllib.parse import urljoin, urlencode
import math

# è™•ç† PyInstaller æ‰“åŒ…å¾Œçš„è·¯å¾‘
if getattr(sys, 'frozen', False):
    # åŸ·è¡Œçš„æ˜¯ exe
    BASE_DIR = os.path.dirname(sys.executable)
    TEMPLATE_DIR = os.path.join(sys._MEIPASS, 'templates')
else:
    # åŸ·è¡Œçš„æ˜¯ py
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    TEMPLATE_DIR = os.path.join(BASE_DIR, 'templates')

app = Flask(__name__, template_folder=TEMPLATE_DIR)

# ========== è¨­å®š ==========
SHOPIFY_SHOP = ""  # å¾ shopify_token.json è®€å–
SHOPIFY_ACCESS_TOKEN = ""  # å¾ shopify_token.json è®€å–

BASE_URL = "https://shop.fugetsudo-kobe.jp"
# å•†å“åˆ—è¡¨é é¢ï¼ˆåˆ†é  URLï¼‰- éœ€è¦å®Œæ•´åƒæ•¸
LIST_URL_TEMPLATE = "https://shop.fugetsudo-kobe.jp/shop/shopbrand.html?page={page}&search=&sort=&money1=&money2=&prize1=&company1=&content1=&originalcode1=&category=&subcategory="

# æœ€ä½æˆæœ¬åƒ¹é–€æª»
MIN_COST_THRESHOLD = 1000

# æ¨¡æ“¬ç€è¦½å™¨ Headers
BROWSER_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8,zh-TW;q=0.7,zh;q=0.6',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
    'Referer': 'https://shop.fugetsudo-kobe.jp/',
}

# å»ºç«‹ Session ä¿æŒ cookies
session = requests.Session()
session.headers.update(BROWSER_HEADERS)

# OpenAI API è¨­å®š (å¾ç’°å¢ƒè®Šæ•¸è®€å–)
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")

def load_shopify_token():
    """è¼‰å…¥ Shopify Access Token å’Œå•†åº—åç¨± (å„ªå…ˆå¾ç’°å¢ƒè®Šæ•¸è®€å–)"""
    global SHOPIFY_ACCESS_TOKEN, SHOPIFY_SHOP
    
    # å„ªå…ˆå¾ç’°å¢ƒè®Šæ•¸è®€å–
    env_token = os.environ.get('SHOPIFY_ACCESS_TOKEN', '')
    env_shop = os.environ.get('SHOPIFY_SHOP', '')
    
    if env_token and env_shop:
        SHOPIFY_ACCESS_TOKEN = env_token
        SHOPIFY_SHOP = env_shop.replace('https://', '').replace('http://', '').replace('.myshopify.com', '').strip('/')
        print(f"[è¨­å®š] å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥ - å•†åº—: {SHOPIFY_SHOP}")
        return True
    
    # å‚™ç”¨ï¼šå¾æª”æ¡ˆè®€å–
    token_file = os.path.join(BASE_DIR, "shopify_token.json")
    if os.path.exists(token_file):
        with open(token_file, 'r') as f:
            data = json.load(f)
            SHOPIFY_ACCESS_TOKEN = data.get('access_token', '')
            shop = data.get('shop', '')
            if shop:
                SHOPIFY_SHOP = shop.replace('https://', '').replace('http://', '').replace('.myshopify.com', '').strip('/')
            
            print(f"[è¨­å®š] å¾æª”æ¡ˆè¼‰å…¥ - å•†åº—: {SHOPIFY_SHOP}")
            print(f"[è¨­å®š] Token: {SHOPIFY_ACCESS_TOKEN[:20]}..." if SHOPIFY_ACCESS_TOKEN else "[è¨­å®š] Token: æœªè¨­å®š")
            return True
    print(f"[éŒ¯èª¤] æ‰¾ä¸åˆ°è¨­å®š")
    return False

def calculate_selling_price(cost, weight):
    """
    è¨ˆç®—å”®åƒ¹
    å…¬å¼ï¼š[é€²è²¨åƒ¹ + (é‡é‡ * 1250)] / 0.7 = å”®åƒ¹
    """
    if not cost or cost <= 0:
        return 0
    
    shipping_cost = weight * 1250 if weight else 0
    price = (cost + shipping_cost) / 0.7
    
    # å››æ¨äº”å…¥åˆ°æ•´æ•¸
    price = round(price)
    
    return price

def translate_with_chatgpt(title, description):
    """
    ä½¿ç”¨ ChatGPT ç¿»è­¯å•†å“åç¨±å’Œèªªæ˜ï¼Œä¸¦ç”Ÿæˆ SEO å…§å®¹
    """
    prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚è«‹å°‡ä»¥ä¸‹æ—¥æœ¬é£Ÿå“å•†å“è³‡è¨Šç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼Œä¸¦å„ªåŒ– SEOã€‚

å•†å“åç¨±ï¼ˆæ—¥æ–‡ï¼‰ï¼š{title}
å•†å“èªªæ˜ï¼ˆæ—¥æ–‡ï¼‰ï¼š{description}

è«‹å›å‚³ JSON æ ¼å¼ï¼ˆä¸è¦åŠ  markdown æ¨™è¨˜ï¼‰ï¼š
{{
    "title": "ç¿»è­¯å¾Œçš„å•†å“åç¨±ï¼ˆç¹é«”ä¸­æ–‡ï¼Œç°¡æ½”æœ‰åŠ›ï¼‰",
    "description": "ç¿»è­¯å¾Œçš„å•†å“èªªæ˜ï¼ˆç¹é«”ä¸­æ–‡ï¼Œä¿ç•™åŸæ„ä½†æ›´æµæš¢ï¼Œé©åˆé›»å•†å±•ç¤ºï¼‰",
    "page_title": "SEO é é¢æ¨™é¡Œï¼ˆç¹é«”ä¸­æ–‡ï¼ŒåŒ…å«å“ç‰Œå’Œå•†å“ç‰¹è‰²ï¼Œ50-60å­—ä»¥å…§ï¼‰",
    "meta_description": "SEO æè¿°ï¼ˆç¹é«”ä¸­æ–‡ï¼Œå¸å¼•é»æ“Šï¼ŒåŒ…å«é—œéµå­—ï¼Œ100å­—ä»¥å…§ï¼‰"
}}

æ³¨æ„ï¼š
1. é€™æ˜¯æ—¥æœ¬ç¥æˆ¶é¢¨æœˆå ‚çš„é«˜ç´šæ³•è˜­é…¥ã€é¤…ä¹¾ç¦®ç›’
2. ã€é‡è¦ã€‘å•†å“åç¨±çš„é–‹é ­å¿…é ˆæ˜¯ã€Œç¥æˆ¶é¢¨æœˆå ‚ã€å››å€‹å­—ï¼Œä¾‹å¦‚ï¼šã€Œç¥æˆ¶é¢¨æœˆå ‚ æ³•è˜­é…¥ç¦®ç›’ 12å…¥ã€
3. ã‚´ãƒ¼ãƒ•ãƒ« ç¿»è­¯ç‚ºã€Œæ³•è˜­é…¥ã€
4. ãƒ—ãƒ†ã‚£ãƒ¼ã‚´ãƒ¼ãƒ•ãƒ« ç¿»è­¯ç‚ºã€Œè¿·ä½ æ³•è˜­é…¥ã€
5. ãƒŸãƒ‹ã‚´ãƒ¼ãƒ•ãƒ« ç¿»è­¯ç‚ºã€Œå°æ³•è˜­é…¥ã€
6. ç¥æˆ¸ã¶ã£ã› ç¿»è­¯ç‚ºã€Œç¥æˆ¶å¸ƒé›ªã€
7. ãƒ¬ã‚¹ãƒãƒ¯ãƒ¼ãƒ« ç¿»è­¯ç‚ºã€Œé›·æ–¯æ³¢ç“¦ã€æˆ–ä¿ç•™ã€ŒLespoirã€
8. ç¿»è­¯è¦è‡ªç„¶æµæš¢ï¼Œä¸è¦ç”Ÿç¡¬
9. SEO å…§å®¹è¦åŒ…å«ï¼šç¥æˆ¶é¢¨æœˆå ‚ã€æ—¥æœ¬ã€æ³•è˜­é…¥ã€ä¼´æ‰‹ç¦®ç­‰é—œéµå­—
10. åªå›å‚³ JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—"""

    try:
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {OPENAI_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "gpt-4o-mini",
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ï¼Œå°ˆé–€è™•ç†æ—¥æœ¬å‚³çµ±ç”œé»çš„ä¸­æ–‡ç¿»è­¯ã€‚å•†å“åç¨±é–‹é ­ä¸€å®šè¦åŠ ä¸Šå“ç‰Œåã€Œç¥æˆ¶é¢¨æœˆå ‚ã€ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0,
                "max_tokens": 1000
            },
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            # æ¸…ç†å¯èƒ½çš„ markdown æ¨™è¨˜
            content = content.strip()
            if content.startswith('```'):
                content = content.split('\n', 1)[1]
            if content.endswith('```'):
                content = content.rsplit('```', 1)[0]
            content = content.strip()
            
            translated = json.loads(content)
            
            # ç¢ºä¿æ¨™é¡Œé–‹é ­æœ‰ã€Œç¥æˆ¶é¢¨æœˆå ‚ã€
            translated_title = translated.get('title', title)
            if not translated_title.startswith('ç¥æˆ¶é¢¨æœˆå ‚'):
                translated_title = f"ç¥æˆ¶é¢¨æœˆå ‚ {translated_title}"
            
            return {
                'success': True,
                'title': translated_title,
                'description': translated.get('description', description),
                'page_title': translated.get('page_title', ''),
                'meta_description': translated.get('meta_description', '')
            }
        else:
            print(f"[OpenAI éŒ¯èª¤] {response.status_code}: {response.text}")
            return {
                'success': False,
                'title': f"ç¥æˆ¶é¢¨æœˆå ‚ {title}",
                'description': description,
                'page_title': '',
                'meta_description': ''
            }
            
    except Exception as e:
        print(f"[ç¿»è­¯éŒ¯èª¤] {e}")
        return {
            'success': False,
            'title': f"ç¥æˆ¶é¢¨æœˆå ‚ {title}",
            'description': description,
            'page_title': '',
            'meta_description': ''
        }

# å…¨åŸŸè®Šæ•¸å­˜å„²çˆ¬å–ç‹€æ…‹
scrape_status = {
    "running": False,
    "progress": 0,
    "total": 0,
    "current_product": "",
    "products": [],
    "errors": [],
    "uploaded": 0,
    "skipped": 0,
    "filtered_by_price": 0,
    "deleted": 0
}

def get_shopify_headers():
    """å–å¾— Shopify API Headers"""
    return {
        'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN,
        'Content-Type': 'application/json',
    }

def shopify_api_url(endpoint):
    """å»ºç«‹ Shopify API URL"""
    return f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/{endpoint}"

def get_existing_skus():
    """å–å¾— Shopify å·²å­˜åœ¨çš„ SKU åˆ—è¡¨ï¼ˆåªå›å‚³ SKU setï¼Œå‘ä¸‹ç›¸å®¹ï¼‰"""
    products_map = get_existing_products_map()
    return set(products_map.keys())

def get_existing_products_map():
    """å–å¾— Shopify å·²å­˜åœ¨çš„å•†å“ï¼Œå›å‚³ {sku: product_id} å­—å…¸"""
    products_map = {}
    url = shopify_api_url("products.json?limit=250")
    
    while url:
        response = requests.get(url, headers=get_shopify_headers())
        if response.status_code != 200:
            print(f"Error fetching products: {response.status_code}")
            break
        
        data = response.json()
        for product in data.get('products', []):
            product_id = product.get('id')
            for variant in product.get('variants', []):
                sku = variant.get('sku')
                if sku and product_id:
                    products_map[sku] = product_id
        
        # è™•ç†åˆ†é 
        link_header = response.headers.get('Link', '')
        if 'rel="next"' in link_header:
            match = re.search(r'<([^>]+)>; rel="next"', link_header)
            if match:
                url = match.group(1)
            else:
                url = None
        else:
            url = None
    
    return products_map

def get_collection_products_map(collection_id):
    """åªå–å¾—ç‰¹å®š Collection å…§çš„å•†å“ï¼Œå›å‚³ {sku: product_id} å­—å…¸"""
    products_map = {}
    
    if not collection_id:
        print("[WARNING] æ²’æœ‰ Collection IDï¼Œè·³é")
        return products_map
    
    url = shopify_api_url(f"collections/{collection_id}/products.json?limit=250")
    
    while url:
        response = requests.get(url, headers=get_shopify_headers())
        if response.status_code != 200:
            print(f"Error fetching collection products: {response.status_code}")
            break
        
        data = response.json()
        for product in data.get('products', []):
            product_id = product.get('id')
            for variant in product.get('variants', []):
                sku = variant.get('sku')
                if sku and product_id:
                    products_map[sku] = product_id
        
        # è™•ç†åˆ†é 
        link_header = response.headers.get('Link', '')
        if 'rel="next"' in link_header:
            match = re.search(r'<([^>]+)>; rel="next"', link_header)
            if match:
                url = match.group(1)
            else:
                url = None
        else:
            url = None
    
    print(f"[INFO] Collection å…§æœ‰ {len(products_map)} å€‹å•†å“")
    return products_map

def set_product_to_draft(product_id):
    """å°‡ Shopify å•†å“è¨­ç‚ºè‰ç¨¿ï¼ˆè€Œéåˆªé™¤ï¼‰"""
    url = shopify_api_url(f"products/{product_id}.json")
    
    response = requests.put(url, headers=get_shopify_headers(), json={
        "product": {
            "id": product_id,
            "status": "draft"
        }
    })
    
    if response.status_code == 200:
        print(f"[è¨­ç‚ºè‰ç¨¿] Product ID: {product_id}")
        return True
    else:
        print(f"[è¨­ç‚ºè‰ç¨¿å¤±æ•—] Product ID: {product_id}, éŒ¯èª¤: {response.status_code}")
        return False

def parse_dimension_weight(soup, page_text):
    """
    è§£æå¯¸æ³•å’Œé‡é‡
    å¾ .detailTxt çš„è¡¨æ ¼ä¸­æ‰¾ã€Œã‚µã‚¤ã‚ºã€æ¬„ä½
    æ ¼å¼ï¼š6.0Ã—14.4Ã—9.2cm æˆ– 14.4Ã—15.7Ã—5.5cm
    
    æç©é‡é‡è¨ˆç®—ï¼šé•·*å¯¬*é«˜/6000 (cmç‚ºå–®ä½)
    """
    dimension = None
    weight = None
    
    # æ–¹æ³•1ï¼šå¾ .detailTxt çš„è¡¨æ ¼çµæ§‹ä¸­æ‰¾ã‚µã‚¤ã‚º
    detail_txt = soup.select_one('.detailTxt')
    if detail_txt:
        # æ‰¾æ‰€æœ‰ row
        rows = detail_txt.select('.row')
        for row in rows:
            cells = row.select('.cell')
            if len(cells) >= 2:
                label = cells[0].get_text(strip=True)
                value = cells[1].get_text(strip=True)
                
                if 'ã‚µã‚¤ã‚º' in label:
                    # è§£æå°ºå¯¸ï¼š6.0Ã—14.4Ã—9.2cm
                    # å¯èƒ½ç”¨ Ã— æˆ– x æˆ– X
                    size_match = re.search(r'([\d.]+)\s*[Ã—xX]\s*([\d.]+)\s*[Ã—xX]\s*([\d.]+)\s*cm', value)
                    if size_match:
                        d1 = float(size_match.group(1))
                        d2 = float(size_match.group(2))
                        d3 = float(size_match.group(3))
                        # æç©é‡é‡ = é•·*å¯¬*é«˜/6000 (cmç‚ºå–®ä½)
                        volume_weight = (d1 * d2 * d3) / 6000
                        volume_weight = round(volume_weight, 2)
                        dimension = {
                            "d1": d1, 
                            "d2": d2, 
                            "d3": d3, 
                            "size_str": value,
                            "volume_weight": volume_weight
                        }
                        print(f"[DEBUG] å°ºå¯¸: {d1} Ã— {d2} Ã— {d3} cm, æç©é‡é‡: {volume_weight} kg")
                    break
    
    # æ–¹æ³•2ï¼šå¦‚æœæ–¹æ³•1æ²’æ‰¾åˆ°ï¼Œå¾æ•´å€‹é é¢æ–‡å­—æ‰¾
    if not dimension:
        # å˜—è©¦æ‰¾ ã‚µã‚¤ã‚º å¾Œé¢çš„å°ºå¯¸
        size_patterns = [
            r'ã‚µã‚¤ã‚º[^\d]*([\d.]+)\s*[Ã—xX]\s*([\d.]+)\s*[Ã—xX]\s*([\d.]+)\s*cm',
            r'([\d.]+)\s*[Ã—xX]\s*([\d.]+)\s*[Ã—xX]\s*([\d.]+)\s*cm',
        ]
        
        for pattern in size_patterns:
            size_match = re.search(pattern, page_text)
            if size_match:
                d1 = float(size_match.group(1))
                d2 = float(size_match.group(2))
                d3 = float(size_match.group(3))
                volume_weight = (d1 * d2 * d3) / 6000
                volume_weight = round(volume_weight, 2)
                dimension = {
                    "d1": d1, 
                    "d2": d2, 
                    "d3": d3, 
                    "volume_weight": volume_weight
                }
                print(f"[DEBUG] å°ºå¯¸(å‚™ç”¨): {d1} Ã— {d2} Ã— {d3} cm, æç©é‡é‡: {volume_weight} kg")
                break
    
    # è¨ˆç®—æœ€çµ‚é‡é‡
    final_weight = 0
    if dimension:
        final_weight = dimension['volume_weight']
    else:
        # å¦‚æœå®Œå…¨æ‰¾ä¸åˆ°å°ºå¯¸ï¼Œè¨­ç‚º 0ï¼Œä¸è¦äº‚çŒœ
        print(f"[WARNING] æ‰¾ä¸åˆ°å°ºå¯¸è³‡è¨Šï¼Œé‡é‡è¨­ç‚º 0")
        final_weight = 0
    
    return {
        "dimension": dimension,
        "actual_weight": weight,
        "final_weight": round(final_weight, 2)
    }

def scrape_product_list():
    """
    çˆ¬å–æ‰€æœ‰åˆ†é çš„å•†å“åˆ—è¡¨
    URL æ ¼å¼ï¼šshopbrand.html?page=1, page=2, page=3...
    å•†å“é€£çµæ ¼å¼ï¼š/shop/shopdetail.html?brandcode=000000000539&amp;search=&amp;sort=
    """
    products = []
    seen_skus = set()
    
    # å…ˆè¨ªå•é¦–é å–å¾— cookies
    session.get(BASE_URL, timeout=30)
    time.sleep(0.5)
    
    page = 1
    max_pages = 20  # æœ€å¤šçˆ¬ 20 é 
    
    while page <= max_pages:
        url = LIST_URL_TEMPLATE.format(page=page)
        print(f"[çˆ¬å–] {url}")
        
        try:
            response = session.get(url, timeout=30)
            # é¢¨æœˆå ‚ä½¿ç”¨ EUC-JP ç·¨ç¢¼
            response.encoding = 'euc-jp'
            
            if response.status_code != 200:
                print(f"[çµæŸ] é é¢ä¸å­˜åœ¨ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
                break
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # DEBUG: å°å‡ºæ‰€æœ‰ <a> æ¨™ç±¤çš„ href
            all_links = soup.find_all('a')
            print(f"[DEBUG] é é¢å…±æœ‰ {len(all_links)} å€‹é€£çµ")
            
            # æ‰¾å«æœ‰ shopdetail çš„é€£çµ
            shopdetail_links = [a for a in all_links if a.get('href') and 'shopdetail' in a.get('href', '')]
            print(f"[DEBUG] å«æœ‰ shopdetail çš„é€£çµ: {len(shopdetail_links)} å€‹")
            
            if shopdetail_links:
                print(f"[DEBUG] ç¯„ä¾‹é€£çµ: {shopdetail_links[0].get('href')[:100]}")
            
            # æ‰¾æ‰€æœ‰å•†å“é€£çµ - ä½¿ç”¨æ›´å¯¬é¬†çš„åŒ¹é…
            product_links = []
            for link in all_links:
                href = link.get('href', '')
                if 'shopdetail' in href and 'brandcode=' in href:
                    product_links.append(link)
            
            print(f"[DEBUG] æ‰¾åˆ° {len(product_links)} å€‹å•†å“é€£çµ")
            
            new_count = 0
            seen_brandcodes = set()
            
            for link in product_links:
                href = link.get('href', '')
                if not href:
                    continue
                
                # è§£æå•†å“ç·¨è™Ÿ (brandcode)
                sku_match = re.search(r'brandcode=(\d+)', href)
                
                if sku_match:
                    brandcode = sku_match.group(1)
                    
                    # è·³éå·²è™•ç†çš„ brandcodeï¼ˆåŒä¸€å•†å“å¯èƒ½æœ‰å¤šå€‹é€£çµï¼‰
                    if brandcode in seen_brandcodes:
                        continue
                    seen_brandcodes.add(brandcode)
                    
                    sku = f"FGT-{brandcode}"
                    
                    # ä½¿ç”¨è©³æƒ…é  URL æ ¼å¼
                    full_url = f"{BASE_URL}/shopdetail/{brandcode}/"
                    
                    if sku not in seen_skus:
                        products.append({
                            'url': full_url,
                            'sku': sku,
                            'brandcode': brandcode
                        })
                        seen_skus.add(sku)
                        new_count += 1
            
            print(f"[é€²åº¦] æ–°å¢ {new_count} å€‹å•†å“ï¼Œç´¯è¨ˆ {len(products)} å€‹")
            
            # å¦‚æœé€™é æ²’æœ‰æ–°å•†å“ï¼Œå¯èƒ½åˆ°åº•äº†
            if new_count == 0:
                print(f"[çµæŸ] æ²’æœ‰æ–°å•†å“")
                break
            
            # æª¢æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é 
            next_page = soup.find('a', href=re.compile(rf'page={page + 1}'))
            if not next_page:
                # å˜—è©¦æ‰¾ã€Œæ¬¡ã¸ã€æˆ–ã€ŒNextã€é€£çµ
                next_link = soup.find('a', string=re.compile(r'æ¬¡|next', re.IGNORECASE))
                if not next_link:
                    print(f"[çµæŸ] æ²’æœ‰ä¸‹ä¸€é ")
                    break
            
            page += 1
            time.sleep(0.5)
            
        except Exception as e:
            print(f"[éŒ¯èª¤] çˆ¬å–å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            break
    
    print(f"[å®Œæˆ] å…±æ‰¾åˆ° {len(products)} å€‹å•†å“")
    return products

def scrape_product_detail(url):
    """çˆ¬å–å–®ä¸€å•†å“è©³ç´°è³‡è¨Š - ç¥æˆ¶é¢¨æœˆå ‚"""
    try:
        response = session.get(url, timeout=30)
        # é¢¨æœˆå ‚ä½¿ç”¨ EUC-JP ç·¨ç¢¼
        response.encoding = 'euc-jp'
        
        if response.status_code != 200:
            print(f"[éŒ¯èª¤] ç‹€æ…‹ç¢¼: {response.status_code} - {url}")
            return None
        
        soup = BeautifulSoup(response.text, 'html.parser')
        page_text = soup.get_text()
        
        # === å•†å“åç¨± ===
        # å¾ #itemInfo h2 å–å¾—
        title = ""
        title_elem = soup.select_one('#itemInfo h2')
        if title_elem:
            title = title_elem.get_text(strip=True)
        
        if not title:
            # å‚™ç”¨ï¼šå¾ og:title meta å–å¾—
            og_title = soup.find('meta', property='og:title')
            if og_title:
                title = og_title.get('content', '').split('ï¼')[0].strip()
        
        print(f"[DEBUG] æ¨™é¡Œ: {title}")
        
        # === å•†å“èªªæ˜ ===
        # å¾ .detailTxt å–å¾—
        description = ""
        desc_elem = soup.select_one('.detailTxt')
        if desc_elem:
            # åªå–ç¬¬ä¸€æ®µæ–‡å­—ï¼Œä¸è¦æ•´å€‹è¦æ ¼è¡¨
            first_p = desc_elem.find('p')
            if first_p:
                description = first_p.get_text(strip=True)
            else:
                description = desc_elem.get_text(strip=True)[:500]
        
        # å‚™ç”¨ï¼šå¾ og:description
        if not description:
            og_desc = soup.find('meta', property='og:description')
            if og_desc:
                description = og_desc.get('content', '')[:500]
        
        print(f"[DEBUG] èªªæ˜: {description[:50]}..." if description else "[DEBUG] èªªæ˜: ç„¡")
        
        # === åƒ¹æ ¼ ===
        # å„ªå…ˆå¾ meta product:price:amount å–å¾—ï¼ˆæœ€æº–ç¢ºï¼‰
        price = 0
        price_meta = soup.find('meta', property='product:price:amount')
        if price_meta:
            try:
                price = int(price_meta.get('content', '0'))
            except:
                pass
        
        # å‚™ç”¨ï¼šå¾é é¢æ–‡å­—è§£æ ç¨è¾¼XXXå††
        if not price:
            price_match = re.search(r'ç¨è¾¼\s*([\d,]+)\s*å††', page_text)
            if price_match:
                price = int(price_match.group(1).replace(',', ''))
        
        print(f"[DEBUG] åƒ¹æ ¼: {price}")
        
        # === å•†å“ç·¨è™Ÿï¼ˆSKUï¼‰===
        # å¾ URL å–å¾— brandcode
        sku = ""
        brandcode_match = re.search(r'/shopdetail/(\d+)/', url)
        if brandcode_match:
            sku = f"FGT-{brandcode_match.group(1)}"
        else:
            # å¾é é¢å–å¾—å•†å“ã‚³ãƒ¼ãƒ‰
            code_match = re.search(r'å•†å“ã‚³ãƒ¼ãƒ‰\s*[ï¼š:]\s*(\d+)', page_text)
            if code_match:
                sku = f"FGT-{code_match.group(1)}"
        
        print(f"[DEBUG] SKU: {sku}")
        
        # === åº«å­˜ç‹€æ…‹ ===
        in_stock = True
        # æª¢æŸ¥ã€Œæ®‹ã‚Šã‚ã¨ã€æˆ–ç„¡åº«å­˜é—œéµå­—
        if 'åœ¨åº«ãŒã‚ã‚Šã¾ã›ã‚“' in page_text or 'åœ¨åº«åˆ‡ã‚Œ' in page_text or 'å“åˆ‡ã‚Œ' in page_text or 'SOLD OUT' in page_text:
            in_stock = False
        
        # æª¢æŸ¥æœ‰æ²’æœ‰åº«å­˜æ•¸é‡é¡¯ç¤º
        stock_match = re.search(r'æ®‹ã‚Šã‚ã¨(\d+)å€‹', page_text)
        if stock_match:
            stock_count = int(stock_match.group(1))
            in_stock = stock_count > 0
        
        print(f"[DEBUG] åº«å­˜: {'æœ‰' if in_stock else 'ç„¡'}")
        
        # === é‡é‡ ===
        weight_info = parse_dimension_weight(soup, page_text)
        
        # === åœ–ç‰‡ ===
        images = []
        seen_images = set()
        
        # å¾ .M_imageMain å–å¾—ä¸»åœ–
        main_images = soup.select('.M_imageMain img')
        for img in main_images:
            src = img.get('src', '')
            if src and 'noimage' not in src.lower():
                # æŠŠç¸®åœ– URL æ”¹æˆå¤§åœ–
                full_src = src.replace('/s1_', '/1_').replace('/s2_', '/2_').replace('/s3_', '/3_').replace('/s4_', '/4_').replace('/s5_', '/5_').replace('/s6_', '/6_')
                if full_src not in seen_images:
                    seen_images.add(full_src)
                    images.append(full_src)
        
        # å¾ .M_imageCatalog å–å¾—ç¸®åœ–ï¼ˆè½‰å¤§åœ–ï¼‰
        thumb_images = soup.select('.M_imageCatalog img')
        for img in thumb_images:
            src = img.get('src', '')
            if src and 'noimage' not in src.lower():
                # ç¸®åœ–æ ¼å¼: s1_000000000020.jpg â†’ 1_000000000020.jpg
                full_src = re.sub(r'/s(\d)_', r'/\1_', src)
                if full_src not in seen_images:
                    seen_images.add(full_src)
                    images.append(full_src)
        
        # å¾ og:image å–å¾—
        if not images:
            og_image = soup.find('meta', property='og:image')
            if og_image:
                img_url = og_image.get('content', '')
                if img_url:
                    images.append(img_url)
        
        print(f"[DEBUG] æ‰¾åˆ° {len(images)} å¼µåœ–ç‰‡")
        
        # === è¦æ ¼è³‡è¨Š ===
        specs = {}
        
        # å…§å®¹é‡
        content_match = re.search(r'å†…å®¹é‡[^\d]*?([\w\d]+(?:å€‹|æš|å…¥|g|kg|æœ¬|ç¼¶))', page_text)
        if content_match:
            specs['content'] = content_match.group(1).strip()
        
        # è³å‘³æœŸé™
        expiry_match = re.search(r'è³å‘³æœŸ[é–“é™][^\d]*?(?:å‡ºè·æ—¥ã‚ˆã‚Š)?ç´„?(\d+æ—¥?)', page_text)
        if expiry_match:
            specs['expiry'] = expiry_match.group(1).strip()
        
        # ç‰¹å®šåŸææ–™ï¼ˆéæ•åŸï¼‰
        allergen_match = re.search(r'ç‰¹å®šåŸææ–™ç­‰\d*å“ç›®[^\w]*([\wãƒ»]+)', page_text)
        if allergen_match:
            specs['allergen'] = allergen_match.group(1).strip()
        
        # å°ºå¯¸
        size_match = re.search(r'ã‚µã‚¤ã‚º[^\d]*([\d.]+[Ã—xX][\d.]+(?:[Ã—xX][\d.]+)?)\s*cm', page_text)
        if size_match:
            specs['size'] = size_match.group(1) + 'cm'
        
        return {
            'url': url,
            'sku': sku,
            'title': title,
            'price': price,
            'in_stock': in_stock,
            'description': description,
            'weight': weight_info['final_weight'],
            'weight_info': weight_info,
            'images': images[:10],
            'specs': specs
        }
        
    except Exception as e:
        print(f"[éŒ¯èª¤] çˆ¬å–å•†å“å¤±æ•— {url}: {e}")
        import traceback
        traceback.print_exc()
        return None

def get_or_create_collection(collection_title="ç¥æˆ¶é¢¨æœˆå ‚"):
    """å–å¾—æˆ–å»ºç«‹ Collection"""
    response = requests.get(
        shopify_api_url(f'custom_collections.json?title={collection_title}'),
        headers=get_shopify_headers()
    )
    
    if response.status_code == 200:
        collections = response.json().get('custom_collections', [])
        for col in collections:
            if col['title'] == collection_title:
                return col['id']
    
    # ä¸å­˜åœ¨å‰‡å»ºç«‹
    response = requests.post(
        shopify_api_url('custom_collections.json'),
        headers=get_shopify_headers(),
        json={
            'custom_collection': {
                'title': collection_title,
                'published': True
            }
        }
    )
    
    if response.status_code == 201:
        return response.json()['custom_collection']['id']
    
    return None

def add_product_to_collection(product_id, collection_id):
    """å°‡å•†å“åŠ å…¥ Collection"""
    response = requests.post(
        shopify_api_url('collects.json'),
        headers=get_shopify_headers(),
        json={
            'collect': {
                'product_id': product_id,
                'collection_id': collection_id
            }
        }
    )
    return response.status_code == 201

def publish_to_all_channels(product_id):
    """ç™¼å¸ƒåˆ°æ‰€æœ‰éŠ·å”®æ¸ é“ï¼ˆä½¿ç”¨ GraphQLï¼‰"""
    print(f"[ç™¼å¸ƒ] æ­£åœ¨ç™¼å¸ƒå•†å“ {product_id} åˆ°æ‰€æœ‰æ¸ é“...")
    
    graphql_url = f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/graphql.json"
    headers = {
        'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN,
        'Content-Type': 'application/json',
    }
    
    query = """
    {
      publications(first: 20) {
        edges {
          node {
            id
            name
            supportsFuturePublishing
          }
        }
      }
    }
    """
    
    response = requests.post(graphql_url, headers=headers, json={'query': query})
    
    if response.status_code != 200:
        print(f"[ç™¼å¸ƒ] ç„¡æ³•å–å¾—æ¸ é“åˆ—è¡¨: {response.status_code}")
        return False
    
    result = response.json()
    publications = result.get('data', {}).get('publications', {}).get('edges', [])
    
    seen_names = set()
    unique_publications = []
    for pub in publications:
        name = pub['node']['name']
        if name not in seen_names:
            seen_names.add(name)
            unique_publications.append(pub['node'])
    
    print(f"[ç™¼å¸ƒ] æ‰¾åˆ° {len(unique_publications)} å€‹éŠ·å”®æ¸ é“")
    
    publication_inputs = [{"publicationId": pub['id']} for pub in unique_publications]
    
    mutation = """
    mutation publishablePublish($id: ID!, $input: [PublicationInput!]!) {
      publishablePublish(id: $id, input: $input) {
        publishable {
          availablePublicationsCount {
            count
          }
        }
        userErrors {
          field
          message
        }
      }
    }
    """
    
    variables = {
        "id": f"gid://shopify/Product/{product_id}",
        "input": publication_inputs
    }
    
    pub_response = requests.post(graphql_url, headers=headers, json={
        'query': mutation,
        'variables': variables
    })
    
    if pub_response.status_code == 200:
        pub_result = pub_response.json()
        data = pub_result.get('data') or {}
        publishable_publish = data.get('publishablePublish') or {}
        errors = publishable_publish.get('userErrors') or []
        
        if errors:
            real_errors = [e for e in errors if 'does not exist' not in e.get('message', '')]
            if real_errors:
                print(f"[ç™¼å¸ƒ] éŒ¯èª¤: {real_errors}")
        
        return True
    else:
        print(f"[ç™¼å¸ƒ] GraphQL è«‹æ±‚å¤±æ•—: {pub_response.status_code}")
        return False

def upload_to_shopify(product, collection_id=None):
    """ä¸Šå‚³å•†å“åˆ° Shopify"""
    
    # ç¿»è­¯å•†å“åç¨±å’Œèªªæ˜
    print(f"[ç¿»è­¯] æ­£åœ¨ç¿»è­¯: {product['title'][:30]}...")
    translated = translate_with_chatgpt(product['title'], product.get('description', ''))
    
    if translated['success']:
        print(f"[ç¿»è­¯æˆåŠŸ] {translated['title'][:30]}...")
    else:
        print(f"[ç¿»è­¯å¤±æ•—] ä½¿ç”¨åŸæ–‡")
    
    # è¨ˆç®—å”®åƒ¹
    cost = product['price']
    weight = product.get('weight', 0)
    selling_price = calculate_selling_price(cost, weight)
    
    print(f"[åƒ¹æ ¼è¨ˆç®—] é€²è²¨åƒ¹: Â¥{cost}, é‡é‡: {weight}kg, å”®åƒ¹: Â¥{selling_price}")
    
    # æº–å‚™åœ–ç‰‡è³‡æ–™
    images = []
    for idx, img_url in enumerate(product.get('images', [])):
        images.append({
            'src': img_url,
            'position': idx + 1
        })
    
    # å»ºç«‹å•†å“è³‡æ–™
    shopify_product = {
        'product': {
            'title': translated['title'],
            'body_html': translated['description'],
            'vendor': 'ç¥æˆ¶é¢¨æœˆå ‚',
            'product_type': 'æ³•è˜­é…¥',
            'status': 'active',
            'published': True,
            'variants': [{
                'sku': product['sku'],
                'price': f"{selling_price:.2f}",
                'weight': product.get('weight', 0),
                'weight_unit': 'kg',
                'inventory_management': None,
                'inventory_policy': 'continue',
                'requires_shipping': True
            }],
            'images': images,
            'tags': 'ç¥æˆ¶é¢¨æœˆå ‚, æ—¥æœ¬, æ³•è˜­é…¥, ã‚´ãƒ¼ãƒ•ãƒ«, ä¼´æ‰‹ç¦®, æ—¥æœ¬é›¶é£Ÿ, ç¥æˆ¶',
            'metafields_global_title_tag': translated['page_title'],
            'metafields_global_description_tag': translated['meta_description'],
            'metafields': [
                {
                    'namespace': 'custom',
                    'key': 'link',
                    'value': product['url'],
                    'type': 'url'
                }
            ]
        }
    }
    
    # ç™¼é€è«‹æ±‚
    response = requests.post(
        shopify_api_url('products.json'),
        headers=get_shopify_headers(),
        json=shopify_product
    )
    
    print(f"[DEBUG] Shopify å›æ‡‰: {response.status_code}")
    
    if response.status_code == 201:
        created_product = response.json()['product']
        product_id = created_product['id']
        variant_id = created_product['variants'][0]['id']
        
        print(f"[DEBUG] å•†å“å»ºç«‹æˆåŠŸ: ID={product_id}")
        
        # æ›´æ–° variant çš„ cost (æˆæœ¬åƒ¹)
        update_cost_response = requests.put(
            shopify_api_url(f'variants/{variant_id}.json'),
            headers=get_shopify_headers(),
            json={
                'variant': {
                    'id': variant_id,
                    'cost': f"{cost:.2f}"
                }
            }
        )
        print(f"[DEBUG] æ›´æ–° Cost å›æ‡‰: {update_cost_response.status_code}")
        
        # åŠ å…¥ Collection
        if collection_id:
            add_product_to_collection(product_id, collection_id)
        
        # ç™¼å¸ƒåˆ°æ‰€æœ‰æ¸ é“
        publish_to_all_channels(product_id)
        
        return {'success': True, 'product': created_product, 'translated': translated, 'selling_price': selling_price, 'cost': cost}
    else:
        print(f"[ERROR] Shopify éŒ¯èª¤: {response.text}")
        return {'success': False, 'error': response.text}

# ========== Flask è·¯ç”± ==========

@app.route('/')
def index():
    """é¦–é """
    token_loaded = load_shopify_token()
    token_status = '<span style="color: green;">âœ“ å·²è¼‰å…¥</span>' if token_loaded else '<span style="color: red;">âœ— æœªè¨­å®š</span>'
    
    return f'''<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¥æˆ¶é¢¨æœˆå ‚ çˆ¬èŸ²å·¥å…·</title>
    <style>
        * {{ box-sizing: border-box; }}
        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; background: #f5f5f5; }}
        h1 {{ color: #333; border-bottom: 2px solid #8B4513; padding-bottom: 10px; }}
        .card {{ background: white; border-radius: 8px; padding: 20px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        .btn {{ background: #8B4513; color: white; border: none; padding: 12px 24px; border-radius: 5px; cursor: pointer; font-size: 16px; margin-right: 10px; }}
        .btn:hover {{ background: #6B3510; }}
        .btn:disabled {{ background: #ccc; cursor: not-allowed; }}
        .btn-secondary {{ background: #3498db; }}
        .btn-secondary:hover {{ background: #2980b9; }}
        .progress-bar {{ width: 100%; height: 20px; background: #eee; border-radius: 10px; overflow: hidden; margin: 10px 0; }}
        .progress-fill {{ height: 100%; background: linear-gradient(90deg, #8B4513, #D2691E); transition: width 0.3s; }}
        .status {{ padding: 10px; background: #f8f9fa; border-radius: 5px; margin-top: 10px; }}
        .log {{ max-height: 300px; overflow-y: auto; font-family: monospace; font-size: 13px; background: #1e1e1e; color: #d4d4d4; padding: 15px; border-radius: 5px; }}
        .stats {{ display: flex; gap: 15px; margin-top: 15px; flex-wrap: wrap; }}
        .stat {{ flex: 1; min-width: 100px; text-align: center; padding: 15px; background: #f8f9fa; border-radius: 5px; }}
        .stat-number {{ font-size: 24px; font-weight: bold; color: #8B4513; }}
        .stat-label {{ font-size: 12px; color: #666; margin-top: 5px; }}
    </style>
</head>
<body>
    <h1>ğŸª ç¥æˆ¶é¢¨æœˆå ‚ çˆ¬èŸ²å·¥å…·</h1>
    
    <div class="card">
        <h3>Shopify é€£ç·šç‹€æ…‹</h3>
        <p>Token: {token_status}</p>
        <button class="btn btn-secondary" onclick="testShopify()">æ¸¬è©¦é€£ç·š</button>
        <button class="btn btn-secondary" onclick="testScrape()">æ¸¬è©¦çˆ¬å–</button>
    </div>
    
    <div class="card">
        <h3>é–‹å§‹çˆ¬å–</h3>
        <p>çˆ¬å– shop.fugetsudo-kobe.jp å…¨ç«™å•†å“ä¸¦ä¸Šæ¶åˆ° Shopify</p>
        <p style="color: #666; font-size: 14px;">â€» æˆæœ¬åƒ¹ä½æ–¼ Â¥1000 çš„å•†å“å°‡è‡ªå‹•è·³é</p>
        <button class="btn" id="startBtn" onclick="startScrape()">ğŸš€ é–‹å§‹çˆ¬å–</button>
        
        <div id="progressSection" style="display: none;">
            <div class="progress-bar">
                <div class="progress-fill" id="progressFill" style="width: 0%"></div>
            </div>
            <div class="status" id="statusText">æº–å‚™ä¸­...</div>
            
            <div class="stats">
                <div class="stat">
                    <div class="stat-number" id="uploadedCount">0</div>
                    <div class="stat-label">å·²ä¸Šæ¶</div>
                </div>
                <div class="stat">
                    <div class="stat-number" id="skippedCount">0</div>
                    <div class="stat-label">å·²è·³é</div>
                </div>
                <div class="stat">
                    <div class="stat-number" id="filteredCount">0</div>
                    <div class="stat-label">åƒ¹æ ¼éæ¿¾</div>
                </div>
                <div class="stat">
                    <div class="stat-number" id="deletedCount" style="color: #e67e22;">0</div>
                    <div class="stat-label">è¨­ç‚ºè‰ç¨¿</div>
                </div>
                <div class="stat">
                    <div class="stat-number" id="errorCount">0</div>
                    <div class="stat-label">éŒ¯èª¤</div>
                </div>
            </div>
        </div>
    </div>
    
    <div class="card">
        <h3>åŸ·è¡Œæ—¥èªŒ</h3>
        <div class="log" id="logArea">ç­‰å¾…é–‹å§‹...</div>
    </div>

    <script>
        let pollInterval = null;
        
        function log(msg, type = '') {{
            const logArea = document.getElementById('logArea');
            const time = new Date().toLocaleTimeString();
            const color = type === 'success' ? '#4ec9b0' : type === 'error' ? '#f14c4c' : '#d4d4d4';
            logArea.innerHTML += '<div style="color:' + color + '">[' + time + '] ' + msg + '</div>';
            logArea.scrollTop = logArea.scrollHeight;
        }}
        
        function clearLog() {{ document.getElementById('logArea').innerHTML = ''; }}
        
        async function testShopify() {{
            log('æ¸¬è©¦ Shopify é€£ç·š...');
            try {{
                const res = await fetch('/api/test-shopify');
                const data = await res.json();
                if (data.success) {{
                    log('âœ“ é€£ç·šæˆåŠŸï¼å•†åº—: ' + data.shop.name, 'success');
                }} else {{
                    log('âœ— é€£ç·šå¤±æ•—: ' + data.error, 'error');
                }}
            }} catch (e) {{
                log('âœ— è«‹æ±‚å¤±æ•—: ' + e.message, 'error');
            }}
        }}
        
        async function testScrape() {{
            log('æ¸¬è©¦çˆ¬å–...');
            try {{
                const res = await fetch('/api/test-scrape');
                const data = await res.json();
                log('çµæœ: ' + JSON.stringify(data).substring(0, 200) + '...');
            }} catch (e) {{
                log('âœ— è«‹æ±‚å¤±æ•—: ' + e.message, 'error');
            }}
        }}
        
        async function startScrape() {{
            clearLog();
            log('é–‹å§‹çˆ¬å–æµç¨‹...');
            document.getElementById('startBtn').disabled = true;
            document.getElementById('progressSection').style.display = 'block';
            
            try {{
                const res = await fetch('/api/start', {{ method: 'POST' }});
                const data = await res.json();
                if (data.error) {{
                    log('âœ— å•Ÿå‹•å¤±æ•—: ' + data.error, 'error');
                    document.getElementById('startBtn').disabled = false;
                    return;
                }}
                log('âœ“ çˆ¬å–ä»»å‹™å·²å•Ÿå‹•', 'success');
                pollInterval = setInterval(pollStatus, 1000);
            }} catch (e) {{
                log('âœ— è«‹æ±‚å¤±æ•—: ' + e.message, 'error');
                document.getElementById('startBtn').disabled = false;
            }}
        }}
        
        async function pollStatus() {{
            try {{
                const res = await fetch('/api/status');
                const data = await res.json();
                
                const percent = data.total > 0 ? (data.progress / data.total * 100) : 0;
                document.getElementById('progressFill').style.width = percent + '%';
                document.getElementById('statusText').textContent = data.current_product + ' (' + data.progress + '/' + data.total + ')';
                
                document.getElementById('uploadedCount').textContent = data.uploaded;
                document.getElementById('skippedCount').textContent = data.skipped;
                document.getElementById('filteredCount').textContent = data.filtered_by_price || 0;
                document.getElementById('deletedCount').textContent = data.deleted || 0;
                document.getElementById('errorCount').textContent = data.errors.length;
                
                if (!data.running && data.progress > 0) {{
                    clearInterval(pollInterval);
                    document.getElementById('startBtn').disabled = false;
                    log('========== çˆ¬å–å®Œæˆ ==========', 'success');
                    log('ä¸Šæ¶: ' + data.uploaded + ' | è·³é: ' + data.skipped + ' | åƒ¹æ ¼éæ¿¾: ' + (data.filtered_by_price || 0) + ' | è‰ç¨¿: ' + (data.deleted || 0) + ' | éŒ¯èª¤: ' + data.errors.length);
                }}
            }} catch (e) {{
                console.error('Poll error:', e);
            }}
        }}
    </script>
</body>
</html>'''

@app.route('/api/status')
def get_status():
    """å–å¾—çˆ¬å–ç‹€æ…‹"""
    return jsonify(scrape_status)

@app.route('/api/start', methods=['POST'])
def start_scrape():
    """é–‹å§‹çˆ¬å–"""
    global scrape_status
    
    if scrape_status['running']:
        return jsonify({'error': 'çˆ¬å–å·²åœ¨é€²è¡Œä¸­'}), 400
    
    scrape_status = {
        "running": True,
        "progress": 0,
        "total": 0,
        "current_product": "æ­£åœ¨å–å¾—å•†å“åˆ—è¡¨...",
        "products": [],
        "errors": [],
        "uploaded": 0,
        "skipped": 0,
        "filtered_by_price": 0,
        "deleted": 0
    }
    
    if not load_shopify_token():
        scrape_status['running'] = False
        return jsonify({'error': 'è«‹å…ˆå®Œæˆ Shopify OAuth æˆæ¬Š'}), 400
    
    import threading
    thread = threading.Thread(target=run_scrape)
    thread.start()
    
    return jsonify({'message': 'é–‹å§‹çˆ¬å–'})

def run_scrape():
    """åŸ·è¡Œçˆ¬å–æµç¨‹"""
    global scrape_status
    
    try:
        # 1. å–å¾— Shopify æ‰€æœ‰å•†å“ (ç”¨æ–¼æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡è¤‡ä¸Šæ¶)
        scrape_status['current_product'] = "æ­£åœ¨æª¢æŸ¥ Shopify å·²æœ‰å•†å“..."
        existing_products_map = get_existing_products_map()
        existing_skus = set(existing_products_map.keys())
        print(f"[INFO] Shopify å…¨ç«™å·²æœ‰ {len(existing_skus)} å€‹å•†å“")
        
        # 2. å–å¾—æˆ–å»ºç«‹ Collection
        scrape_status['current_product'] = "æ­£åœ¨è¨­å®š Collection..."
        collection_id = get_or_create_collection("ç¥æˆ¶é¢¨æœˆå ‚")
        print(f"[INFO] Collection ID: {collection_id}")
        
        # 2.5 å–å¾— Collection å…§çš„å•†å“ï¼ˆåªæœ‰é€™äº›æ‰æœƒè¢«è¨­ç‚ºè‰ç¨¿ï¼‰
        scrape_status['current_product'] = "æ­£åœ¨å–å¾— Collection å…§å•†å“..."
        collection_products_map = get_collection_products_map(collection_id)
        collection_skus = set(collection_products_map.keys())
        print(f"[INFO] ç¥æˆ¶é¢¨æœˆå ‚ Collection å…§æœ‰ {len(collection_skus)} å€‹å•†å“")
        
        # 3. çˆ¬å–å•†å“åˆ—è¡¨
        scrape_status['current_product'] = "æ­£åœ¨çˆ¬å–å•†å“åˆ—è¡¨..."
        product_list = scrape_product_list()
        scrape_status['total'] = len(product_list)
        print(f"[INFO] æ‰¾åˆ° {len(product_list)} å€‹å•†å“")
        
        # å–å¾—å®˜ç¶²æ‰€æœ‰ SKUï¼ˆç”¨æ–¼è‰ç¨¿æ¯”å°ï¼‰
        website_skus = set(item['sku'] for item in product_list)
        print(f"[INFO] å®˜ç¶² SKU åˆ—è¡¨: {len(website_skus)} å€‹")
        
        # 4. çˆ¬å–æ¯å€‹å•†å“è©³æƒ…ä¸¦ä¸Šå‚³
        for idx, item in enumerate(product_list):
            scrape_status['progress'] = idx + 1
            scrape_status['current_product'] = f"è™•ç†: {item['sku']}"
            
            if item['sku'] in existing_skus:
                print(f"[è·³é] SKU {item['sku']} å·²å­˜åœ¨")
                scrape_status['skipped'] += 1
                continue
            
            product = scrape_product_detail(item['url'])
            if not product:
                scrape_status['errors'].append(f"ç„¡æ³•çˆ¬å–: {item['url']}")
                continue
            
            # æª¢æŸ¥æˆæœ¬åƒ¹é–€æª»
            if product['price'] < MIN_COST_THRESHOLD:
                print(f"[è·³é] SKU {product['sku']} æˆæœ¬åƒ¹ Â¥{product['price']} ä½æ–¼é–€æª» Â¥{MIN_COST_THRESHOLD}")
                scrape_status['filtered_by_price'] += 1
                continue
            
            if not product['in_stock']:
                print(f"[è·³é] SKU {product['sku']} ç„¡åº«å­˜")
                scrape_status['skipped'] += 1
                continue
            
            result = upload_to_shopify(product, collection_id)
            if result['success']:
                print(f"[æˆåŠŸ] ä¸Šå‚³ SKU {product['sku']}")
                existing_skus.add(product['sku'])  # é˜²æ­¢åŒä¸€æ‰¹æ¬¡é‡è¤‡ä¸Šæ¶
                scrape_status['uploaded'] += 1
                scrape_status['products'].append({
                    'sku': product['sku'],
                    'title': result.get('translated', {}).get('title', product['title']),
                    'original_title': product['title'],
                    'price': product['price'],
                    'selling_price': result.get('selling_price', 0),
                    'weight': product['weight'],
                    'status': 'success'
                })
            else:
                print(f"[å¤±æ•—] SKU {product['sku']}: {result['error']}")
                scrape_status['errors'].append(f"ä¸Šå‚³å¤±æ•— {product['sku']}: {result['error']}")
                scrape_status['products'].append({
                    'sku': product['sku'],
                    'title': product['title'],
                    'status': 'failed',
                    'error': result['error']
                })
            
            time.sleep(1)
        
        # 5. è¨­ç‚ºè‰ç¨¿ï¼šåªé‡å° Collection å…§ã€ä½†å®˜ç¶²å·²ä¸‹æ¶çš„å•†å“
        scrape_status['current_product'] = "æ­£åœ¨æª¢æŸ¥å·²ä¸‹æ¶å•†å“..."
        skus_to_draft = collection_skus - website_skus
        
        if skus_to_draft:
            print(f"[INFO] ç™¼ç¾ {len(skus_to_draft)} å€‹å•†å“éœ€è¦è¨­ç‚ºè‰ç¨¿: {skus_to_draft}")
            
            for sku in skus_to_draft:
                scrape_status['current_product'] = f"è¨­ç‚ºè‰ç¨¿: {sku}"
                product_id = collection_products_map.get(sku)
                
                if product_id:
                    if set_product_to_draft(product_id):
                        scrape_status['deleted'] += 1
                        scrape_status['products'].append({
                            'sku': sku,
                            'status': 'draft',
                            'title': f'å·²è¨­ç‚ºè‰ç¨¿ (SKU: {sku})'
                        })
                    else:
                        scrape_status['errors'].append(f"è¨­ç‚ºè‰ç¨¿å¤±æ•—: {sku}")
                    
                    time.sleep(0.5)
        else:
            print("[INFO] æ²’æœ‰éœ€è¦è¨­ç‚ºè‰ç¨¿çš„å•†å“")
        
    except Exception as e:
        print(f"[éŒ¯èª¤] {e}")
        scrape_status['errors'].append(str(e))
    
    finally:
        scrape_status['running'] = False
        scrape_status['current_product'] = "å®Œæˆ"

@app.route('/api/test-shopify')
def test_shopify():
    """æ¸¬è©¦ Shopify é€£ç·š"""
    if not load_shopify_token():
        return jsonify({'error': 'æœªæ‰¾åˆ° Token'}), 400
    
    response = requests.get(
        shopify_api_url('shop.json'),
        headers=get_shopify_headers()
    )
    
    if response.status_code == 200:
        return jsonify({'success': True, 'shop': response.json()['shop']})
    else:
        return jsonify({'success': False, 'error': response.text}), 400

@app.route('/api/test-scrape')
def test_scrape():
    """æ¸¬è©¦çˆ¬å–ï¼ˆä¸ä¸Šæ¶ï¼‰"""
    if not load_shopify_token():
        return jsonify({'error': 'è«‹å…ˆå®Œæˆ Shopify OAuth æˆæ¬Š'}), 400
    
    # å…ˆè¨ªå•é¦–é å–å¾— cookies
    session.get(BASE_URL, timeout=30)
    time.sleep(0.5)
    
    # æ¸¬è©¦æŠ“å–åˆ—è¡¨é ç¬¬ä¸€é 
    products = []
    url = LIST_URL_TEMPLATE.format(page=1)
    
    try:
        response = session.get(url, timeout=30)
        response.encoding = 'euc-jp'
        
        html_content = response.text
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # æ‰¾æ‰€æœ‰é€£çµ
        all_links = soup.find_all('a')
        
        # æ‰¾å«æœ‰ shopdetail çš„é€£çµ
        shopdetail_links = []
        for link in all_links:
            href = link.get('href', '')
            if 'shopdetail' in href and 'brandcode=' in href:
                shopdetail_links.append(href)
        
        # å»é‡ï¼ˆç”¨ brandcodeï¼‰
        seen = set()
        unique_items = []
        for href in shopdetail_links:
            brandcode_match = re.search(r'brandcode=(\d+)', href)
            if brandcode_match:
                brandcode = brandcode_match.group(1)
                if brandcode not in seen:
                    seen.add(brandcode)
                    unique_items.append({'href': href, 'brandcode': brandcode})
        
        # å–å‰ 3 å€‹æ¸¬è©¦
        for item in unique_items[:3]:
            brandcode = item['brandcode']
            full_url = f"{BASE_URL}/shopdetail/{brandcode}/"
            
            product = scrape_product_detail(full_url)
            if product:
                products.append(product)
        
        return jsonify({
            'success': True,
            'message': f'æ‰¾åˆ° {len(unique_items)} å€‹å•†å“é€£çµ',
            'total_links': len(all_links),
            'shopdetail_links': len(shopdetail_links),
            'products': products,
            'sample_links': [item['href'] for item in unique_items[:5]],
            'html_sample': html_content[:3000]  # å›å‚³éƒ¨åˆ† HTML ä¾›æª¢è¦–
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 400

@app.route('/api/test-upload')
def test_upload():
    """æ¸¬è©¦çˆ¬å–ä¸¦ä¸Šæ¶ä¸€å€‹å•†å“"""
    if not load_shopify_token():
        return jsonify({'error': 'è«‹å…ˆå®Œæˆ Shopify OAuth æˆæ¬Š'}), 400
    
    # å…ˆè¨ªå•é¦–é å–å¾— cookies
    session.get(BASE_URL, timeout=30)
    time.sleep(0.5)
    
    # çˆ¬å–åˆ—è¡¨é ç¬¬ä¸€é ï¼Œæ‰¾ç¬¬ä¸€å€‹ç¬¦åˆæ¢ä»¶çš„å•†å“
    url = LIST_URL_TEMPLATE.format(page=1)
    
    try:
        response = session.get(url, timeout=30)
        response.encoding = 'euc-jp'
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # æ‰¾å•†å“é€£çµ - æ ¼å¼: shopdetail.html?brandcode=000000000539
        product_links = soup.find_all('a', href=re.compile(r'shopdetail\.html\?brandcode='))
        
        # å»é‡ï¼ˆç”¨ brandcodeï¼‰
        seen = set()
        unique_items = []
        for link in product_links:
            href = link.get('href', '')
            brandcode_match = re.search(r'brandcode=(\d+)', href)
            if brandcode_match:
                brandcode = brandcode_match.group(1)
                if brandcode not in seen:
                    seen.add(brandcode)
                    unique_items.append({'href': href, 'brandcode': brandcode})
        
        if not unique_items:
            return jsonify({'error': 'æ‰¾ä¸åˆ°å•†å“é€£çµ'}), 400
        
        # æ‰¾ç¬¬ä¸€å€‹åƒ¹æ ¼ >= 1000 çš„å•†å“
        product = None
        for item in unique_items:
            brandcode = item['brandcode']
            full_url = f"{BASE_URL}/shopdetail/{brandcode}/"
            
            p = scrape_product_detail(full_url)
            if p and p['price'] >= MIN_COST_THRESHOLD and p['in_stock']:
                product = p
                break
        
        if not product:
            return jsonify({'error': f'æ‰¾ä¸åˆ°åƒ¹æ ¼ >= Â¥{MIN_COST_THRESHOLD} ä¸”æœ‰åº«å­˜çš„å•†å“'}), 400
        
        print(f"[DEBUG] çˆ¬å–æˆåŠŸ: {product['title']}")
        
        # å–å¾—æˆ–å»ºç«‹ Collection
        collection_id = get_or_create_collection("ç¥æˆ¶é¢¨æœˆå ‚")
        
        # ä¸Šå‚³åˆ° Shopify
        result = upload_to_shopify(product, collection_id)
        
        if result['success']:
            shopify_product = result['product']
            admin_url = f"https://admin.shopify.com/store/{SHOPIFY_SHOP}/products/{shopify_product['id']}"
            
            return jsonify({
                'success': True,
                'message': 'ä¸Šæ¶æˆåŠŸï¼',
                'product': {
                    'sku': product['sku'],
                    'original_title': product['title'],
                    'translated_title': result.get('translated', {}).get('title', ''),
                    'cost': result.get('cost', product['price']),
                    'selling_price': result.get('selling_price', 0),
                    'weight': product['weight'],
                    'shopify_id': shopify_product['id'],
                    'shopify_url': admin_url,
                    'images_count': len(product.get('images', []))
                }
            })
        else:
            return jsonify({
                'success': False,
                'error': result['error'],
                'product': product
            }), 400
            
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 400

if __name__ == '__main__':
    print("=" * 50)
    print("ç¥æˆ¶é¢¨æœˆå ‚çˆ¬èŸ²å·¥å…·")
    print(f"æœ€ä½æˆæœ¬åƒ¹é–€æª»ï¼šÂ¥{MIN_COST_THRESHOLD}")
    print("=" * 50)
    
    port = int(os.environ.get('PORT', 8080))
    print(f"é–‹å•Ÿç€è¦½å™¨è¨ªå•: http://localhost:{port}")
    print("=" * 50)
    
    app.run(host='0.0.0.0', port=port, debug=False)
