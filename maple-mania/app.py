"""
The Maple Mania æ¥“ç³–ç”·å­© å•†å“çˆ¬èŸ² + Shopify ä¸Šæ¶å·¥å…· v2.1
v2.1: ç¿»è­¯ä¿è­·æ©Ÿåˆ¶ã€æ—¥æ–‡å•†å“æƒæã€æ¸¬è©¦ç¿»è­¯
"""

from flask import Flask, jsonify, request
import requests
from bs4 import BeautifulSoup
import re
import json
import os
import time
from urllib.parse import urljoin
import math
import threading
import base64

app = Flask(__name__)

SHOPIFY_SHOP = ""
SHOPIFY_ACCESS_TOKEN = ""
BASE_URL = "https://sucreyshopping.jp"
LIST_PAGES = [
    "https://sucreyshopping.jp/shop/c/c10/?brand=themaplemania",
    "https://sucreyshopping.jp/shop/c/c10_p2/?brand=themaplemania",
    "https://sucreyshopping.jp/shop/c/c10_p3/?brand=themaplemania",
    "https://sucreyshopping.jp/shop/c/c10_p4/?brand=themaplemania",
]
BRAND_PREFIX = "The maple mania æ¥“ç³–ç”·å­©"
MIN_PRICE = 1000
MAX_CONSECUTIVE_TRANSLATION_FAILURES = 3
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")

BROWSER_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
}
session = requests.Session()
session.headers.update(BROWSER_HEADERS)

scrape_status = {
    "running": False, "progress": 0, "total": 0, "current_product": "",
    "products": [], "errors": [], "uploaded": 0, "skipped": 0,
    "skipped_low_price": 0, "skipped_points": 0, "skipped_exists": 0,
    "filtered_by_price": 0, "deleted": 0,
    "translation_failed": 0, "translation_stopped": False
}


def is_japanese_text(text):
    if not text: return False
    check = text.replace('The maple mania', '').replace('æ¥“ç³–ç”·å­©', '').strip()
    if not check: return False
    jp = len(re.findall(r'[\u3040-\u309F\u30A0-\u30FF]', check))
    cn = len(re.findall(r'[\u4e00-\u9fff]', check))
    total = len(re.sub(r'[\s\d\W]', '', check))
    if total == 0: return False
    return jp > 0 and (jp / total > 0.3 or cn == 0)


def load_shopify_token():
    global SHOPIFY_ACCESS_TOKEN, SHOPIFY_SHOP
    env_token = os.environ.get('SHOPIFY_ACCESS_TOKEN', '')
    env_shop = os.environ.get('SHOPIFY_SHOP', '')
    if env_token and env_shop:
        SHOPIFY_ACCESS_TOKEN = env_token
        SHOPIFY_SHOP = env_shop.replace('https://','').replace('http://','').replace('.myshopify.com','').strip('/')
        return True
    token_file = "shopify_token.json"
    if os.path.exists(token_file):
        with open(token_file, 'r') as f:
            data = json.load(f)
            SHOPIFY_ACCESS_TOKEN = data.get('access_token', '')
            shop = data.get('shop', '')
            if shop: SHOPIFY_SHOP = shop.replace('https://','').replace('http://','').replace('.myshopify.com','').strip('/')
            return True
    return False


def get_shopify_headers():
    return {'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN, 'Content-Type': 'application/json'}


def shopify_api_url(endpoint):
    return f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/{endpoint}"


def normalize_sku(sku):
    if not sku: return ""
    return sku.strip().lower()


def calculate_selling_price(cost, weight):
    if not cost or cost <= 0: return 0
    return round((cost + (weight * 1250 if weight else 0)) / 0.7)


def clean_html_for_translation(html_text):
    if not html_text: return ""
    text = html_text
    text = re.sub(r'<style[^>]*>.*?</style>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'<script[^>]*>.*?</script>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'#[\w-]+\s*\{[^}]*\}', '', text, flags=re.DOTALL)
    text = re.sub(r'\.[\w-]+\s*\{[^}]*\}', '', text, flags=re.DOTALL)
    text = re.sub(r'@media[^{]*\{[^}]*\}', '', text, flags=re.DOTALL)
    text = re.sub(r'\s*style\s*=\s*["\'][^"\']*["\']', '', text, flags=re.IGNORECASE)
    text = re.sub(r'<br\s*/?>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'</p>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'</div>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'\n\s*\n', '\n\n', text)
    text = re.sub(r'[ \t]+', ' ', text)
    return text.strip()


def translate_with_chatgpt(title, description):
    clean_desc = clean_html_for_translation(description)
    clean_desc = re.sub(r'[\d,]+\s*å††', '', clean_desc)
    clean_desc = re.sub(r'åƒ¹æ ¼[ï¼š:]\s*[\d,]+\s*æ—¥åœ“', '', clean_desc)
    clean_desc = re.sub(r'ç¨è¾¼[\d,]+å††', '', clean_desc)

    prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚è«‹ç¿»è­¯æˆç¹é«”ä¸­æ–‡ä¸¦å„ªåŒ– SEOã€‚

å•†å“åç¨±ï¼š{title}
å•†å“èªªæ˜ï¼š{clean_desc[:1500]}

å›å‚³ JSONï¼ˆä¸åŠ  markdownï¼‰ï¼š
{{"title":"åç¨±ï¼ˆå‰åŠ  The maple mania æ¥“ç³–ç”·å­©ï¼‰","description":"èªªæ˜ï¼ˆHTMLï¼Œä¸å«åƒ¹æ ¼ï¼‰","page_title":"SEOæ¨™é¡Œ50-60å­—","meta_description":"SEOæè¿°100å­—å…§"}}

è¦å‰‡ï¼š1.æ¥“ç³–ç”·å­©æ±äº¬ä¼´æ‰‹ç¦® 2.é–‹é ­ã€ŒThe maple mania æ¥“ç³–ç”·å­©ã€3.ç¦æ­¢åƒ¹æ ¼ 4.åªå›å‚³JSON"""

    try:
        response = requests.post("https://api.openai.com/v1/chat/completions",
            headers={"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"},
            json={"model": "gpt-4o-mini", "messages": [
                {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚"},
                {"role": "user", "content": prompt}], "temperature": 0, "max_tokens": 1000}, timeout=60)
        if response.status_code == 200:
            content = response.json()['choices'][0]['message']['content'].strip()
            if content.startswith('```'): content = content.split('\n', 1)[1]
            if content.endswith('```'): content = content.rsplit('```', 1)[0]
            translated = json.loads(content.strip())
            t = translated.get('title', title)
            if not t.startswith('The maple mania') and not t.startswith('The Maple Mania'):
                t = f"{BRAND_PREFIX} {t}"
            desc = translated.get('description', description)
            desc = re.sub(r'[\d,]+\s*å††', '', desc)
            desc = re.sub(r'[\d,]+\s*æ—¥åœ“', '', desc)
            return {'success': True, 'title': t, 'description': desc,
                    'page_title': translated.get('page_title', ''), 'meta_description': translated.get('meta_description', '')}
        else:
            em = response.text[:200]
            return {'success': False, 'error': f"HTTP {response.status_code}: {em}",
                    'title': f"{BRAND_PREFIX} {title}", 'description': description, 'page_title': '', 'meta_description': ''}
    except Exception as e:
        return {'success': False, 'error': str(e),
                'title': f"{BRAND_PREFIX} {title}", 'description': description, 'page_title': '', 'meta_description': ''}


def download_image_to_base64(img_url, max_retries=3):
    headers = {'User-Agent': 'Mozilla/5.0', 'Accept': 'image/*', 'Referer': 'https://sucreyshopping.jp/'}
    for attempt in range(max_retries):
        try:
            r = requests.get(img_url, headers=headers, timeout=30)
            if r.status_code == 200:
                ct = r.headers.get('Content-Type', 'image/jpeg')
                fmt = 'image/png' if 'png' in ct else 'image/gif' if 'gif' in ct else 'image/webp' if 'webp' in ct else 'image/jpeg'
                return {'success': True, 'base64': base64.b64encode(r.content).decode('utf-8'), 'content_type': fmt}
        except: pass
        time.sleep(1)
    return {'success': False}


def get_existing_skus():
    return set(get_existing_products_map().keys())


def get_existing_products_map():
    pm = {}
    url = shopify_api_url("products.json?limit=250")
    while url:
        r = requests.get(url, headers=get_shopify_headers())
        if r.status_code != 200: break
        for p in r.json().get('products', []):
            pid = p.get('id')
            for v in p.get('variants', []):
                sk = v.get('sku')
                if sk and pid:
                    n = normalize_sku(sk); pm[n] = pid
                    if sk != n: pm[sk] = pid
        lh = r.headers.get('Link', '')
        m = re.search(r'<([^>]+)>; rel="next"', lh)
        url = m.group(1) if m and 'rel="next"' in lh else None
    return pm


def get_collection_products_map(collection_id):
    pm = {}
    if not collection_id: return pm
    url = shopify_api_url(f"collections/{collection_id}/products.json?limit=250")
    while url:
        r = requests.get(url, headers=get_shopify_headers())
        if r.status_code != 200: break
        for p in r.json().get('products', []):
            pid = p.get('id')
            for v in p.get('variants', []):
                sk = v.get('sku')
                if sk and pid: pm[normalize_sku(sk)] = pid
        lh = r.headers.get('Link', '')
        m = re.search(r'<([^>]+)>; rel="next"', lh)
        url = m.group(1) if m and 'rel="next"' in lh else None
    return pm


def set_product_to_draft(pid):
    return requests.put(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers(),
        json={"product": {"id": pid, "status": "draft"}}).status_code == 200


def delete_product(pid):
    return requests.delete(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers()).status_code == 200


def update_product(pid, data):
    r = requests.put(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers(),
        json={"product": {"id": pid, **data}})
    return r.status_code == 200, r


def get_or_create_collection(ct="The maple mania æ¥“ç³–ç”·å­©"):
    r = requests.get(shopify_api_url(f'custom_collections.json?title={ct}'), headers=get_shopify_headers())
    if r.status_code == 200:
        for c in r.json().get('custom_collections', []):
            if c['title'] == ct: return c['id']
    r = requests.post(shopify_api_url('custom_collections.json'), headers=get_shopify_headers(),
        json={'custom_collection': {'title': ct, 'published': True}})
    if r.status_code == 201: return r.json()['custom_collection']['id']
    return None


def add_product_to_collection(pid, cid):
    return requests.post(shopify_api_url('collects.json'), headers=get_shopify_headers(),
        json={'collect': {'product_id': pid, 'collection_id': cid}}).status_code == 201


def publish_to_all_channels(pid):
    gu = f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/graphql.json"
    hd = {'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN, 'Content-Type': 'application/json'}
    r = requests.post(gu, headers=hd, json={'query': '{ publications(first:20){ edges{ node{ id name }}}}'})
    if r.status_code != 200: return False
    pubs = r.json().get('data', {}).get('publications', {}).get('edges', [])
    seen = set(); uq = []
    for p in pubs:
        if p['node']['name'] not in seen: seen.add(p['node']['name']); uq.append(p['node'])
    mut = """mutation publishablePublish($id:ID!,$input:[PublicationInput!]!){publishablePublish(id:$id,input:$input){userErrors{field message}}}"""
    requests.post(gu, headers=hd, json={'query': mut, 'variables': {"id": f"gid://shopify/Product/{pid}", "input": [{"publicationId": p['id']} for p in uq]}})
    return True


def parse_size_weight(text):
    text = text.replace('Ã—', 'x').replace('ï¼¸', 'x').replace('ï½˜', 'x')
    text = text.replace('ï½ï½', 'mm').replace('ï½‡', 'g').replace('ï½‹ï½‡', 'kg')
    text = text.replace('Î¦', 'x').replace(',', '').replace('ï¼ˆ', '(').replace('ï¼‰', ')')
    dimension = None; weight_kg = None
    for pat in [r'W\s*(\d+(?:\.\d+)?)\s*[xXÃ—]\s*D\s*(\d+(?:\.\d+)?)\s*[xXÃ—]\s*H\s*(\d+(?:\.\d+)?)',
                r'(\d+(?:\.\d+)?)\s*[xXÃ—]\s*(\d+(?:\.\d+)?)\s*[xXÃ—]\s*(\d+(?:\.\d+)?)\s*(?:\(?\s*mm\s*\)?)?']:
        dm = re.search(pat, text, re.IGNORECASE)
        if dm:
            l, w, h = float(dm.group(1)), float(dm.group(2)), float(dm.group(3))
            dimension = {"l": l, "w": w, "h": h, "volume_weight": round((l*w*h)/6000000, 2)}; break
    wm = re.search(r'(\d+(?:\.\d+)?)\s*kg', text, re.IGNORECASE)
    gm = re.search(r'(\d+(?:\.\d+)?)\s*g(?![\w])', text)
    if wm: weight_kg = float(wm.group(1))
    elif gm: weight_kg = float(gm.group(1)) / 1000
    final = 0
    if dimension and weight_kg: final = max(dimension.get('volume_weight', 0), weight_kg)
    elif dimension: final = dimension.get('volume_weight', 0)
    elif weight_kg: final = weight_kg
    return {"dimension": dimension, "actual_weight": weight_kg, "final_weight": round(final, 2)}


def scrape_product_list():
    products = []; seen_skus = set()
    for page_url in LIST_PAGES:
        try:
            r = session.get(page_url, timeout=30)
            if r.status_code != 200: continue
            soup = BeautifulSoup(r.text, 'html.parser')
            for link in soup.select('a[href*="/shop/g/g"]'):
                href = link.get('href', '')
                sm = re.search(r'/shop/g/g([^/]+)/', href)
                if not sm: continue
                sku = normalize_sku(sm.group(1))
                if sku in seen_skus: continue
                seen_skus.add(sku)
                parent = link.find_parent(['dl', 'div', 'li'])
                if parent:
                    pt = parent.get_text()
                    if 'ãƒã‚¤ãƒ³ãƒˆ' in pt and 'å††' not in pt: continue
                    if 'ãŠæ€¥ãä¾¿' in pt: continue
                    pm = re.search(r'([\d,]+)å††', pt)
                    price = int(pm.group(1).replace(',', '')) if pm else 0
                    if 0 < price < MIN_PRICE: continue
                else: price = 0
                products.append({'url': urljoin(BASE_URL, href), 'sku': sku, 'sku_raw': sm.group(1), 'list_price': price})
            time.sleep(1)
        except Exception as e:
            print(f"[ERROR] {e}"); continue
    return products


def scrape_product_detail(url, max_retries=3):
    product = {'url': url, 'title': '', 'price': 0, 'description': '', 'size_weight_text': '',
        'weight': 0, 'images': [], 'sku': '', 'sku_raw': '', 'is_points': False}
    sm = re.search(r'/shop/g/g([^/]+)/', url)
    if sm: product['sku_raw'] = sm.group(1); product['sku'] = normalize_sku(sm.group(1))
    for attempt in range(max_retries):
        try:
            r = session.get(url, timeout=30)
            if r.status_code != 200: continue
            soup = BeautifulSoup(r.text, 'html.parser'); pt = soup.get_text()
            if 'ãƒã‚¤ãƒ³ãƒˆ' in pt and re.search(r'\d+ãƒã‚¤ãƒ³ãƒˆ', pt) and not re.search(r'[\d,]+å††', pt):
                product['is_points'] = True; return product
            for sel in ['h1.goods-name', 'h1[class*="goods"]', '.goods-detail h1', 'h1']:
                el = soup.select_one(sel)
                if el:
                    t = el.get_text(strip=True)
                    if t and len(t) > 2: product['title'] = t; break
            for sel in ['.block-goods-price--price', '.js-enhanced-ecommerce-goods-price', '.price']:
                el = soup.select_one(sel)
                if el:
                    pm = re.search(r'([\d,]+)', el.get_text())
                    if pm: product['price'] = int(pm.group(1).replace(',', '')); break
            if not product['price']:
                pm = re.search(r'([\d,]+)\s*å††', pt)
                if pm: product['price'] = int(pm.group(1).replace(',', ''))
            for sel in ['.goods-description', '.item-description', '.product-description']:
                el = soup.select_one(sel)
                if el: product['description'] = str(el); break
            for dl in soup.select('dl'):
                if 'ç®±ã‚µã‚¤ã‚º' in dl.get_text() or 'ã‚µã‚¤ã‚º' in dl.get_text():
                    dd = dl.select_one('dd')
                    if dd:
                        product['size_weight_text'] = dd.get_text()
                        wi = parse_size_weight(dd.get_text())
                        if wi['final_weight'] > 0: product['weight'] = wi['final_weight']; break
            if product['weight'] == 0:
                sm2 = re.search(r'W\s*(\d+)\s*[Ã—xX]\s*D\s*(\d+)\s*[Ã—xX]\s*H\s*(\d+)', pt)
                if sm2: product['weight'] = round((float(sm2.group(1))*float(sm2.group(2))*float(sm2.group(3)))/6000000, 2)
            if product['weight'] == 0:
                wm = re.search(r'(\d+(?:,\d+)?)\s*[gG](?!ift)', pt)
                if wm: product['weight'] = round(float(wm.group(1).replace(',',''))/1000, 2)
            if product['weight'] == 0: product['weight'] = 0.5
            images = []
            for img in soup.select('img[src*="/img/goods/"]'):
                src = img.get('src') or img.get('data-src')
                if src:
                    src = src.replace('/S/', '/L/').replace('/M/', '/L/')
                    if src.startswith('//'): src = 'https:' + src
                    elif not src.startswith('http'): src = urljoin(BASE_URL, src)
                    if src not in images: images.append(src)
            if not images:
                og = soup.select_one('meta[property="og:image"]')
                if og and og.get('content'):
                    s = og.get('content')
                    if not s.startswith('http'): s = urljoin(BASE_URL, s)
                    images.append(s)
            product['images'] = images[:10]
            return product
        except Exception as e:
            if attempt < max_retries - 1: time.sleep(3)
    return product


def upload_to_shopify(product, collection_id=None):
    translated = translate_with_chatgpt(product['title'], product.get('description', ''))
    if not translated['success']:
        return {'success': False, 'error': 'translation_failed', 'translated': translated}
    cost = product['price']; weight = product.get('weight', 0)
    selling_price = calculate_selling_price(cost, weight)
    images_b64 = []
    for idx, iu in enumerate(product.get('images', [])):
        if not iu or not iu.startswith('http'): continue
        result = download_image_to_base64(iu)
        if result['success']:
            images_b64.append({'attachment': result['base64'], 'position': idx+1, 'filename': f"maple_mania_{product['sku']}_{idx+1}.jpg"})
        time.sleep(0.5)
    sp = {'product': {
        'title': translated['title'], 'body_html': translated['description'],
        'vendor': 'The maple mania æ¥“ç³–ç”·å­©', 'product_type': 'ã‚¯ãƒƒã‚­ãƒ¼ãƒ»æ´‹è“å­',
        'status': 'active', 'published': True,
        'variants': [{'sku': product['sku'], 'price': f"{selling_price:.2f}", 'weight': weight,
            'weight_unit': 'kg', 'inventory_management': None, 'inventory_policy': 'continue', 'requires_shipping': True}],
        'images': images_b64,
        'tags': 'The maple mania, æ¥“ç³–ç”·å­©, ãƒ¡ãƒ¼ãƒ—ãƒ«ãƒãƒ‹ã‚¢, æ—¥æœ¬, æ±äº¬, ä¼´æ‰‹ç¦®, æ±äº¬åœŸç”£, æ—¥æœ¬ä»£è³¼, æ¥“ç³–é¤…ä¹¾',
        'metafields_global_title_tag': translated['page_title'],
        'metafields_global_description_tag': translated['meta_description'],
        'metafields': [{'namespace': 'custom', 'key': 'link', 'value': product['url'], 'type': 'url'}]
    }}
    r = requests.post(shopify_api_url('products.json'), headers=get_shopify_headers(), json=sp)
    if r.status_code == 201:
        cp = r.json()['product']; pid = cp['id']; vid = cp['variants'][0]['id']
        requests.put(shopify_api_url(f'variants/{vid}.json'), headers=get_shopify_headers(),
            json={'variant': {'id': vid, 'cost': f"{cost:.2f}"}})
        if collection_id: add_product_to_collection(pid, collection_id)
        publish_to_all_channels(pid)
        return {'success': True, 'product': cp, 'translated': translated, 'selling_price': selling_price, 'cost': cost}
    return {'success': False, 'error': r.text}


def run_scrape():
    global scrape_status
    try:
        scrape_status.update({"running": True, "progress": 0, "total": 0, "current_product": "",
            "products": [], "errors": [], "uploaded": 0, "skipped": 0,
            "skipped_low_price": 0, "skipped_points": 0, "skipped_exists": 0,
            "filtered_by_price": 0, "deleted": 0,
            "translation_failed": 0, "translation_stopped": False})
        scrape_status['current_product'] = "æª¢æŸ¥ Shopify å·²æœ‰å•†å“..."
        all_pm = get_existing_products_map(); existing_skus = set(all_pm.keys())
        scrape_status['current_product'] = "è¨­å®š Collection..."
        collection_id = get_or_create_collection("The maple mania æ¥“ç³–ç”·å­©")
        scrape_status['current_product'] = "å–å¾— Collection å•†å“..."
        cpm = get_collection_products_map(collection_id); collection_skus = set(cpm.keys())
        scrape_status['current_product'] = "çˆ¬å–å•†å“åˆ—è¡¨..."
        product_list = scrape_product_list(); scrape_status['total'] = len(product_list)
        website_skus = set(item['sku'] for item in product_list)
        ctf = 0
        for idx, item in enumerate(product_list):
            scrape_status['progress'] = idx + 1
            scrape_status['current_product'] = f"è™•ç†: {item['sku']}"
            if item['sku'] in existing_skus:
                scrape_status['skipped_exists'] += 1; scrape_status['skipped'] += 1; continue
            product = scrape_product_detail(item['url'])
            if not product: scrape_status['errors'].append({'sku': item['sku'], 'error': 'çˆ¬å–å¤±æ•—'}); continue
            if product.get('sku') and product['sku'] in existing_skus:
                scrape_status['skipped_exists'] += 1; scrape_status['skipped'] += 1; continue
            if product.get('is_points'):
                scrape_status['skipped_points'] += 1; scrape_status['skipped'] += 1; continue
            if 'ãŠæ€¥ãä¾¿' in product.get('title', ''):
                scrape_status['skipped'] += 1; continue
            if product.get('price', 0) < MIN_PRICE:
                scrape_status['skipped_low_price'] += 1; scrape_status['filtered_by_price'] += 1; scrape_status['skipped'] += 1; continue
            if not product.get('title') or not product.get('price'):
                scrape_status['errors'].append({'sku': item['sku'], 'error': 'è³‡è¨Šä¸å®Œæ•´'}); continue
            result = upload_to_shopify(product, collection_id)
            if result['success']:
                existing_skus.add(product['sku']); scrape_status['uploaded'] += 1
                scrape_status['products'].append({'sku': product['sku'],
                    'title': result.get('translated', {}).get('title', product['title']),
                    'price': product['price'], 'selling_price': result.get('selling_price', 0),
                    'weight': product['weight'], 'status': 'success'})
                ctf = 0
            elif result.get('error') == 'translation_failed':
                scrape_status['translation_failed'] += 1; ctf += 1
                scrape_status['errors'].append({'sku': product['sku'], 'error': 'ç¿»è­¯å¤±æ•—'})
                if ctf >= MAX_CONSECUTIVE_TRANSLATION_FAILURES:
                    scrape_status['translation_stopped'] = True
                    scrape_status['errors'].append({'error': f'ç¿»è­¯é€£çºŒå¤±æ•— {ctf} æ¬¡ï¼Œè‡ªå‹•åœæ­¢'})
                    break
            else:
                scrape_status['errors'].append({'sku': product['sku'], 'error': result.get('error', '')})
                ctf = 0
            time.sleep(1)
        if not scrape_status['translation_stopped']:
            scrape_status['current_product'] = "æª¢æŸ¥å·²ä¸‹æ¶å•†å“..."
            for sku in (collection_skus - website_skus):
                pid = cpm.get(sku)
                if pid and set_product_to_draft(pid): scrape_status['deleted'] += 1
                time.sleep(0.5)
        scrape_status['current_product'] = "å®Œæˆï¼" if not scrape_status['translation_stopped'] else "ç¿»è­¯ç•°å¸¸åœæ­¢"
    except Exception as e:
        scrape_status['errors'].append({'error': str(e)})
    finally:
        scrape_status['running'] = False


# ========== Flask è·¯ç”± ==========

@app.route('/')
def index():
    token_loaded = load_shopify_token()
    tc = 'green' if token_loaded else 'red'
    ts = 'âœ“ å·²è¼‰å…¥' if token_loaded else 'âœ— æœªè¨­å®š'
    return f"""<!DOCTYPE html>
<html lang="zh-TW">
<head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>æ¥“ç³–ç”·å­© çˆ¬èŸ²å·¥å…·</title>
<style>*{{{{box-sizing:border-box}}}}body{{{{font-family:-apple-system,sans-serif;max-width:900px;margin:0 auto;padding:20px;background:#f5f5f5}}}}h1{{{{color:#333;border-bottom:2px solid #8B4513;padding-bottom:10px}}}}.card{{{{background:white;border-radius:8px;padding:20px;margin-bottom:20px;box-shadow:0 2px 4px rgba(0,0,0,0.1);}}}}.btn{{{{background:#8B4513;color:white;border:none;padding:12px 24px;border-radius:5px;cursor:pointer;font-size:16px;margin-right:10px;margin-bottom:10px;text-decoration:none;display:inline-block}}}}.btn:hover{{{{background:#6B3510}}}}.btn:disabled{{{{background:#ccc}}}}.btn-secondary{{{{background:#3498db}}}}.btn-success{{{{background:#27ae60}}}}.progress-bar{{{{width:100%;height:20px;background:#eee;border-radius:10px;overflow:hidden;margin:10px 0}}}}.progress-fill{{{{height:100%;background:linear-gradient(90deg,#8B4513,#D2691E);transition:width 0.3s}}}}.status{{{{padding:10px;background:#f8f9fa;border-radius:5px;margin-top:10px}}}}.log{{{{max-height:300px;overflow-y:auto;font-family:monospace;font-size:13px;background:#1e1e1e;color:#d4d4d4;padding:15px;border-radius:5px}}}}.stats{{{{display:flex;gap:15px;margin-top:15px;flex-wrap:wrap}}}}.stat{{{{flex:1;min-width:70px;text-align:center;padding:15px;background:#f8f9fa;border-radius:5px}}}}.stat-number{{{{font-size:24px;font-weight:bold;color:#8B4513}}}}.stat-label{{{{font-size:10px;color:#666;margin-top:5px}}}}.nav{{{{margin-bottom:20px}}}}.nav a{{{{margin-right:15px;color:#8B4513;text-decoration:none;font-weight:bold}}}}.alert{{{{padding:12px 16px;border-radius:5px;margin-bottom:15px}}}}.alert-danger{{{{background:#fee;border:1px solid #fcc;color:#c0392b}}}}</style></head>
<body>
<div class="nav"><a href="/">ğŸ  é¦–é </a><a href="/japanese-scan">ğŸ‡¯ğŸ‡µ æ—¥æ–‡æƒæ</a></div>
<h1>ğŸ æ¥“ç³–ç”·å­© çˆ¬èŸ²å·¥å…· <small style="font-size:14px;color:#999">v2.1</small></h1>
<div class="card"><h3>Shopify é€£ç·š</h3><p>Token: <span style="color:{{tc}};">{{ts}}</span></p>
<button class="btn btn-secondary" onclick="testShopify()">æ¸¬è©¦é€£ç·š</button>
<button class="btn btn-secondary" onclick="testTranslate()">æ¸¬è©¦ç¿»è­¯</button>
<a href="/japanese-scan" class="btn btn-success">ğŸ‡¯ğŸ‡µ æ—¥æ–‡æƒæ</a></div>
<div class="card"><h3>é–‹å§‹çˆ¬å–</h3>
<p style="color:#666;font-size:14px">â€» &lt;Â¥1000ã€é»æ•¸ã€ãŠæ€¥ãä¾¿è·³é | <b style="color:#e74c3c">ç¿»è­¯ä¿è­·</b> é€£çºŒå¤±æ•— {MAX_CONSECUTIVE_TRANSLATION_FAILURES} æ¬¡åœæ­¢</p>
<button class="btn" id="startBtn" onclick="startScrape()">ğŸš€ é–‹å§‹çˆ¬å–</button>
<div id="progressSection" style="display:none">
<div id="translationAlert" class="alert alert-danger" style="display:none">âš ï¸ ç¿»è­¯åŠŸèƒ½ç•°å¸¸ï¼Œå·²è‡ªå‹•åœæ­¢ï¼</div>
<div class="progress-bar"><div class="progress-fill" id="progressFill" style="width:0%"></div></div>
<div class="status" id="statusText">æº–å‚™ä¸­...</div>
<div class="stats">
<div class="stat"><div class="stat-number" id="uploadedCount">0</div><div class="stat-label">å·²ä¸Šæ¶</div></div>
<div class="stat"><div class="stat-number" id="skippedCount">0</div><div class="stat-label">å·²è·³é</div></div>
<div class="stat"><div class="stat-number" id="translationFailedCount" style="color:#e74c3c">0</div><div class="stat-label">ç¿»è­¯å¤±æ•—</div></div>
<div class="stat"><div class="stat-number" id="filteredCount">0</div><div class="stat-label">åƒ¹æ ¼éæ¿¾</div></div>
<div class="stat"><div class="stat-number" id="deletedCount" style="color:#e67e22">0</div><div class="stat-label">è¨­ç‚ºè‰ç¨¿</div></div>
<div class="stat"><div class="stat-number" id="errorCount" style="color:#e74c3c">0</div><div class="stat-label">éŒ¯èª¤</div></div>
</div></div></div>
<div class="card"><h3>åŸ·è¡Œæ—¥èªŒ</h3><div class="log" id="logArea">ç­‰å¾…é–‹å§‹...</div></div>
<script>let pollInterval=null;function log(m,t){{{{const l=document.getElementById('logArea');const tm=new Date().toLocaleTimeString();const c={{{{success:'#4ec9b0',error:'#f14c4c'}}}}[t]||'#d4d4d4';l.innerHTML+='<div style="color:'+c+'">['+tm+'] '+m+'</div>';l.scrollTop=l.scrollHeight}}}}function clearLog(){{{{document.getElementById('logArea').innerHTML=''}}}}async function testShopify(){{{{log('æ¸¬è©¦é€£ç·š...');try{{{{const r=await fetch('/api/test-shopify');const d=await r.json();if(d.success)log('âœ“ '+d.shop.name,'success');else log('âœ— '+d.error,'error')}}}}catch(e){{{{log('âœ— '+e.message,'error')}}}}}}}}async function testTranslate(){{{{log('æ¸¬è©¦ç¿»è­¯...');try{{{{const r=await fetch('/api/test-translate');const d=await r.json();if(d.error)log('âœ— '+d.error,'error');else if(d.success)log('âœ“ '+d.title,'success');else log('âœ— ç¿»è­¯å¤±æ•—','error')}}}}catch(e){{{{log('âœ— '+e.message,'error')}}}}}}}}async function startScrape(){{{{clearLog();log('é–‹å§‹çˆ¬å–...');document.getElementById('startBtn').disabled=true;document.getElementById('progressSection').style.display='block';document.getElementById('translationAlert').style.display='none';try{{{{const r=await fetch('/api/start-scrape',{{{{method:'POST'}}}});const d=await r.json();if(!d.success){{{{log('âœ— '+d.error,'error');document.getElementById('startBtn').disabled=false;return}}}}log('âœ“ å·²å•Ÿå‹•','success');pollInterval=setInterval(pollStatus,1000)}}}}catch(e){{{{log('âœ— '+e.message,'error');document.getElementById('startBtn').disabled=false}}}}}}}}async function pollStatus(){{{{try{{{{const r=await fetch('/api/status');const d=await r.json();const p=d.total>0?(d.progress/d.total*100):0;document.getElementById('progressFill').style.width=p+'%';document.getElementById('statusText').textContent=d.current_product+' ('+d.progress+'/'+d.total+')';document.getElementById('uploadedCount').textContent=d.uploaded;document.getElementById('skippedCount').textContent=d.skipped;document.getElementById('translationFailedCount').textContent=d.translation_failed||0;document.getElementById('filteredCount').textContent=d.filtered_by_price||0;document.getElementById('deletedCount').textContent=d.deleted||0;document.getElementById('errorCount').textContent=d.errors.length;if(d.translation_stopped)document.getElementById('translationAlert').style.display='block';if(!d.running&&d.progress>0){{{{clearInterval(pollInterval);document.getElementById('startBtn').disabled=false;if(d.translation_stopped)log('âš ï¸ ç¿»è­¯ç•°å¸¸åœæ­¢','error');else log('========== å®Œæˆ ==========','success')}}}}}}}}catch(e){{{{console.error(e)}}}}}}}}</script></body></html>"""





@app.route('/japanese-scan')
def japanese_scan_page():
    return '''<!DOCTYPE html>
<html lang="zh-TW">
<head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>æ—¥æ–‡å•†å“æƒæ - æ¥“ç³–ç”·å­©</title>
<style>*{box-sizing:border-box}body{font-family:-apple-system,BlinkMacSystemFont,sans-serif;max-width:1200px;margin:0 auto;padding:20px;background:#f5f5f5}h1{color:#333;border-bottom:2px solid #27ae60;padding-bottom:10px}.card{background:white;border-radius:8px;padding:20px;margin-bottom:20px;box-shadow:0 2px 4px rgba(0,0,0,0.1)}.btn{background:#8B4513;color:white;border:none;padding:10px 20px;border-radius:5px;cursor:pointer;font-size:14px;margin-right:10px;margin-bottom:10px}.btn:disabled{background:#ccc}.btn-danger{background:#e74c3c}.btn-success{background:#27ae60}.btn-sm{padding:5px 10px;font-size:12px}.nav{margin-bottom:20px}.nav a{margin-right:15px;color:#8B4513;text-decoration:none;font-weight:bold}.stats{display:flex;gap:15px;margin:20px 0;flex-wrap:wrap}.stat{flex:1;min-width:150px;text-align:center;padding:20px;background:#f8f9fa;border-radius:8px}.stat-number{font-size:36px;font-weight:bold}.stat-label{font-size:14px;color:#666;margin-top:5px}.product-item{display:flex;align-items:center;padding:15px;border-bottom:1px solid #eee;gap:15px}.product-item:last-child{border-bottom:none}.product-item img{width:60px;height:60px;object-fit:cover;border-radius:4px}.product-item .info{flex:1}.product-item .info .title{font-weight:bold;margin-bottom:5px;color:#c0392b}.product-item .info .meta{font-size:12px;color:#666}.no-image{width:60px;height:60px;background:#eee;display:flex;align-items:center;justify-content:center;border-radius:4px;color:#999;font-size:10px}.retranslate-status{font-size:12px;margin-top:5px}.action-bar{position:sticky;top:0;background:white;padding:15px;margin:-20px -20px 20px -20px;border-bottom:1px solid #ddd;z-index:100;display:flex;justify-content:space-between;align-items:center;flex-wrap:wrap;gap:10px}</style></head>
<body>
<div class="nav"><a href="/">ğŸ  é¦–é </a><a href="/japanese-scan">ğŸ‡¯ğŸ‡µ æ—¥æ–‡æƒæ</a></div>
<h1>ğŸ‡¯ğŸ‡µ æ—¥æ–‡å•†å“æƒæ - æ¥“ç³–ç”·å­©</h1>
<div class="card"><p>æƒæ Shopify ä¸­æ¥“ç³–ç”·å­©çš„æ—¥æ–‡ï¼ˆæœªç¿»è­¯ï¼‰å•†å“ã€‚</p><button class="btn" id="scanBtn" onclick="startScan()">ğŸ” é–‹å§‹æƒæ</button><span id="scanStatus"></span></div>
<div class="stats" id="statsSection" style="display:none"><div class="stat"><div class="stat-number" id="totalProducts" style="color:#3498db">0</div><div class="stat-label">æ¥“ç³–ç”·å­©å•†å“æ•¸</div></div><div class="stat"><div class="stat-number" id="japaneseCount" style="color:#e74c3c">0</div><div class="stat-label">æ—¥æ–‡å•†å“</div></div></div>
<div class="card" id="resultsCard" style="display:none"><div class="action-bar"><div><button class="btn btn-success" id="retranslateAllBtn" onclick="retranslateAll()" disabled>ğŸ”„ å…¨éƒ¨ç¿»è­¯</button><button class="btn btn-danger" id="deleteAllBtn" onclick="deleteAllJP()" disabled>ğŸ—‘ï¸ å…¨éƒ¨åˆªé™¤</button></div><div id="progressText"></div></div><div id="results"></div></div>
<script>let jp=[];async function startScan(){document.getElementById('scanBtn').disabled=true;document.getElementById('scanStatus').textContent='æƒæä¸­...';try{const r=await fetch('/api/scan-japanese');const d=await r.json();if(d.error){alert(d.error);return}jp=d.japanese_products;document.getElementById('totalProducts').textContent=d.total_products;document.getElementById('japaneseCount').textContent=d.japanese_count;document.getElementById('statsSection').style.display='flex';renderResults(d.japanese_products);document.getElementById('resultsCard').style.display='block';document.getElementById('retranslateAllBtn').disabled=jp.length===0;document.getElementById('deleteAllBtn').disabled=jp.length===0;document.getElementById('scanStatus').textContent='å®Œæˆï¼'}catch(e){alert(e.message)}finally{document.getElementById('scanBtn').disabled=false}}function renderResults(p){const c=document.getElementById('results');if(!p.length){c.innerHTML='<p style="text-align:center;color:#27ae60;font-size:18px">âœ… æ²’æœ‰æ—¥æ–‡å•†å“</p>';return}let h='';p.forEach(i=>{const img=i.image?`<img src="${i.image}">`:`<div class="no-image">ç„¡åœ–</div>`;h+=`<div class="product-item" id="product-${i.id}">${img}<div class="info"><div class="title">${i.title}</div><div class="meta">SKU:${i.sku||'ç„¡'}|Â¥${i.price}|${i.status}</div><div class="retranslate-status" id="status-${i.id}"></div></div><div class="actions"><button class="btn btn-success btn-sm" onclick="rt1('${i.id}')" id="rt-${i.id}">ğŸ”„</button><button class="btn btn-danger btn-sm" onclick="del1('${i.id}')" id="del-${i.id}">ğŸ—‘ï¸</button></div></div>`});c.innerHTML=h}async function rt1(id){const b=document.getElementById(`rt-${id}`);const s=document.getElementById(`status-${id}`);b.disabled=true;b.textContent='...';try{const r=await fetch('/api/retranslate-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:id})});const d=await r.json();if(d.success){s.innerHTML=`<span style="color:#27ae60">âœ… ${d.new_title}</span>`;const t=document.querySelector(`#product-${id} .title`);if(t){t.textContent=d.new_title;t.style.color='#27ae60'}b.textContent='âœ“'}else{s.innerHTML=`<span style="color:#e74c3c">âŒ ${d.error}</span>`;b.disabled=false;b.textContent='ğŸ”„'}}catch(e){s.innerHTML=`<span style="color:#e74c3c">âŒ ${e.message}</span>`;b.disabled=false;b.textContent='ğŸ”„'}}async function del1(id){if(!confirm('ç¢ºå®šåˆªé™¤ï¼Ÿ'))return;const b=document.getElementById(`del-${id}`);b.disabled=true;try{const r=await fetch('/api/delete-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:id})});const d=await r.json();if(d.success)document.getElementById(`product-${id}`).remove();else{alert('å¤±æ•—');b.disabled=false}}catch(e){alert(e.message);b.disabled=false}}async function retranslateAll(){if(!confirm(`ç¿»è­¯å…¨éƒ¨ ${jp.length} å€‹ï¼Ÿ`))return;const b=document.getElementById('retranslateAllBtn');b.disabled=true;b.textContent='ç¿»è­¯ä¸­...';let s=0,f=0;for(let i=0;i<jp.length;i++){document.getElementById('progressText').textContent=`${i+1}/${jp.length}`;try{const r=await fetch('/api/retranslate-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:jp[i].id})});const d=await r.json();const st=document.getElementById(`status-${jp[i].id}`);if(d.success){s++;if(st)st.innerHTML=`<span style="color:#27ae60">âœ… ${d.new_title}</span>`;const t=document.querySelector(`#product-${jp[i].id} .title`);if(t){t.textContent=d.new_title;t.style.color='#27ae60'}}else{f++;if(st)st.innerHTML=`<span style="color:#e74c3c">âŒ ${d.error}</span>`;if(f>=3){alert('é€£çºŒå¤±æ•—');break}}}catch(e){f++}await new Promise(r=>setTimeout(r,1500))}alert(`æˆåŠŸ:${s} å¤±æ•—:${f}`);b.textContent='ğŸ”„ å…¨éƒ¨ç¿»è­¯';b.disabled=false;document.getElementById('progressText').textContent=''}async function deleteAllJP(){if(!confirm(`åˆªé™¤å…¨éƒ¨ ${jp.length} å€‹ï¼Ÿ`))return;const b=document.getElementById('deleteAllBtn');b.disabled=true;let s=0,f=0;for(let i=0;i<jp.length;i++){document.getElementById('progressText').textContent=`${i+1}/${jp.length}`;try{const r=await fetch('/api/delete-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:jp[i].id})});const d=await r.json();if(d.success){s++;const el=document.getElementById(`product-${jp[i].id}`);if(el)el.remove()}else f++}catch(e){f++}await new Promise(r=>setTimeout(r,300))}alert(`æˆåŠŸ:${s} å¤±æ•—:${f}`);b.textContent='ğŸ—‘ï¸ å…¨éƒ¨åˆªé™¤';b.disabled=false;document.getElementById('progressText').textContent=''}</script></body></html>'''




@app.route('/api/scan-japanese')
def api_scan_japanese():
    if not load_shopify_token():
        return jsonify({'error': 'æœªè¨­å®š Token'}), 400
    products = []
    url = shopify_api_url("products.json?limit=250&vendor=The+maple+mania+æ¥“ç³–ç”·å­©")
    while url:
        r = requests.get(url, headers=get_shopify_headers())
        if r.status_code != 200: break
        for p in r.json().get('products', []):
            sku = ''; price = ''
            for v in p.get('variants', []): sku = v.get('sku', ''); price = v.get('price', ''); break
            products.append({'id': p.get('id'), 'title': p.get('title', ''), 'handle': p.get('handle', ''),
                'sku': sku, 'price': price, 'vendor': p.get('vendor', ''), 'status': p.get('status', ''),
                'created_at': p.get('created_at', ''), 'image': p.get('image', {}).get('src', '') if p.get('image') else ''})
        lh = r.headers.get('Link', '')
        m = re.search(r'<([^>]+)>; rel="next"', lh)
        url = m.group(1) if m and 'rel="next"' in lh else None
    jp = [p for p in products if is_japanese_text(p.get('title', ''))]
    return jsonify({'total_products': len(products), 'japanese_count': len(jp), 'japanese_products': jp})




@app.route('/api/retranslate-product', methods=['POST'])
def api_retranslate_product():
    if not load_shopify_token():
        return jsonify({'error': 'æœªè¨­å®š Token'}), 400
    data = request.get_json()
    pid = data.get('product_id')
    if not pid:
        return jsonify({'error': 'ç¼ºå°‘ product_id'}), 400
    resp = requests.get(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers())
    if resp.status_code != 200:
        return jsonify({'error': f'ç„¡æ³•å–å¾—: {resp.status_code}'}), 400
    product = resp.json().get('product', {})
    translated = translate_with_chatgpt(product.get('title', ''), product.get('body_html', ''))
    if not translated['success']:
        return jsonify({'success': False, 'error': f"ç¿»è­¯å¤±æ•—: {translated.get('error', 'æœªçŸ¥')}"})
    ok, r = update_product(pid, {
        'title': translated['title'],
        'body_html': translated['description'],
        'metafields_global_title_tag': translated['page_title'],
        'metafields_global_description_tag': translated['meta_description']
    })
    if ok:
        return jsonify({'success': True, 'old_title': product.get('title', ''), 'new_title': translated['title'], 'product_id': pid})
    return jsonify({'success': False, 'error': f'æ›´æ–°å¤±æ•—: {r.text[:200]}'})




@app.route('/api/delete-product', methods=['POST'])
def api_delete_product():
    if not load_shopify_token():
        return jsonify({'error': 'æœªè¨­å®š Token'}), 400
    data = request.get_json()
    pid = data.get('product_id')
    if not pid:
        return jsonify({'error': 'ç¼ºå°‘ product_id'}), 400
    return jsonify({'success': delete_product(pid), 'product_id': pid})




@app.route('/api/test-translate')
def api_test_translate():
    api_key = os.environ.get("OPENAI_API_KEY", "")
    if not api_key:
        return jsonify({'error': 'OPENAI_API_KEY æœªè¨­å®š'})
    key_preview = f"{api_key[:8]}...{api_key[-4:]}" if len(api_key) > 12 else "å¤ªçŸ­"
    result = translate_with_chatgpt("ãƒ¡ãƒ¼ãƒ—ãƒ«ãƒã‚¿ãƒ¼ã‚¯ãƒƒã‚­ãƒ¼ 9æšå…¥", "ãƒ¡ãƒ¼ãƒ—ãƒ«ã‚·ãƒ¥ã‚¬ãƒ¼ã‚’ãŸã£ã·ã‚Šä½¿ã£ãŸç„¼ãè“å­ã§ã™")
    result['key_preview'] = key_preview
    result['key_length'] = len(api_key)
    return jsonify(result)




@app.route('/api/status')
def get_status():
    return jsonify(scrape_status)


@app.route('/api/start-scrape', methods=['POST'])
def start_scrape():
    global scrape_status
    if scrape_status['running']: return jsonify({'success': False, 'error': 'çˆ¬å–æ­£åœ¨é€²è¡Œä¸­'})
    if not load_shopify_token(): return jsonify({'success': False, 'error': 'æœªè¨­å®šç’°å¢ƒè®Šæ•¸'})
    test = translate_with_chatgpt("ãƒ†ã‚¹ãƒˆå•†å“", "ãƒ†ã‚¹ãƒˆèª¬æ˜")
    if not test['success']:
        return jsonify({'success': False, 'error': f"ç¿»è­¯åŠŸèƒ½ç•°å¸¸: {test.get('error', 'æœªçŸ¥')}"})
    threading.Thread(target=run_scrape).start()
    return jsonify({'success': True, 'message': 'é–‹å§‹çˆ¬å–'})


@app.route('/api/start', methods=['POST'])
def cron_trigger():
    global scrape_status
    if scrape_status['running']:
        return jsonify({'success': False, 'error': 'çˆ¬å–æ­£åœ¨é€²è¡Œä¸­'}), 409
    if not load_shopify_token():
        return jsonify({'success': False, 'error': 'æœªè¨­å®šç’°å¢ƒè®Šæ•¸'}), 500
    test = translate_with_chatgpt("ãƒ†ã‚¹ãƒˆå•†å“", "ãƒ†ã‚¹ãƒˆèª¬æ˜")
    if not test['success']:
        return jsonify({'success': False, 'error': f"ç¿»è­¯åŠŸèƒ½ç•°å¸¸: {test.get('error', 'æœªçŸ¥')}"}), 400
    threading.Thread(target=run_scrape).start()
    return jsonify({'success': True, 'message': 'Cron job triggered', 'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')})


@app.route('/api/test-shopify')
def test_shopify():
    if not load_shopify_token(): return jsonify({'success': False, 'error': 'æœªè¨­å®šç’°å¢ƒè®Šæ•¸'})
    r = requests.get(shopify_api_url('shop.json'), headers=get_shopify_headers())
    if r.status_code == 200: return jsonify({'success': True, 'shop': r.json()['shop']})
    return jsonify({'success': False, 'error': r.text}), 400


@app.route('/api/test-scrape')
def test_scrape():
    product = scrape_product_detail("https://sucreyshopping.jp/shop/g/gtmm01107/")
    if product.get('price') and product.get('weight'):
        product['selling_price'] = calculate_selling_price(product['price'], product['weight'])
    return jsonify(product)


if __name__ == '__main__':
    print("=" * 50)
    print("The Maple Mania æ¥“ç³–ç”·å­© çˆ¬èŸ²å·¥å…· v2.1")
    print("æ–°å¢: ç¿»è­¯ä¿è­·ã€æ—¥æ–‡å•†å“æƒæ")
    print("=" * 50)
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port, debug=False)
