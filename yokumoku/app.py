"""
YOKUMOKU å•†å“çˆ¬èŸ² + Shopify ä¸Šæ¶å·¥å…· v2.2
v2.1: ç¿»è­¯ä¿è­·æ©Ÿåˆ¶ã€æ—¥æ–‡å•†å“æƒæã€ç¿»è­¯é©—è­‰é‡è©¦ã€ç’°å¢ƒè®Šæ•¸ã€Docker/Zeabur éƒ¨ç½²
v2.2: ç¼ºè²¨å•†å“è‡ªå‹•åˆªé™¤ - å®˜ç¶²æ¶ˆå¤±æˆ–ç¼ºè²¨çš†ç›´æ¥åˆªé™¤
"""

from flask import Flask, jsonify, request
import requests
import re
import json
import os
import time
from urllib.parse import urljoin
import math
from playwright.sync_api import sync_playwright
import threading
import base64

app = Flask(__name__)

SHOPIFY_SHOP = ""
SHOPIFY_ACCESS_TOKEN = ""
BASE_URL = "https://www.yokumoku.jp"
SEARCH_URL = "https://www.yokumoku.jp/search?including_oos=1"
BRAND_PREFIX = "YOKUMOKU"
MIN_PRICE = 1000
MAX_CONSECUTIVE_TRANSLATION_FAILURES = 3
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")

scrape_status = {
    "running": False, "progress": 0, "total": 0, "current_product": "",
    "products": [], "errors": [], "uploaded": 0, "skipped": 0,
    "skipped_frozen": 0, "skipped_oos": 0, "skipped_exists": 0,
    "skipped_low_price": 0, "filtered_by_price": 0,
    "out_of_stock": 0, "deleted": 0,
    "translation_failed": 0, "translation_stopped": False
}


def is_japanese_text(text):
    if not text: return False
    check = text.replace('YOKUMOKU', '').strip()
    if not check: return False
    jp = len(re.findall(r'[\u3040-\u309F\u30A0-\u30FF]', check))
    cn = len(re.findall(r'[\u4e00-\u9fff]', check))
    total = len(re.sub(r'[\s\d\W]', '', check))
    if total == 0: return False
    return jp > 0 and (jp / total > 0.3 or cn == 0)


def load_shopify_token():
    global SHOPIFY_ACCESS_TOKEN, SHOPIFY_SHOP
    env_token = os.environ.get('SHOPIFY_ACCESS_TOKEN', '')
    env_shop = os.environ.get('SHOPIFY_SHOP', '')
    if env_token and env_shop:
        SHOPIFY_ACCESS_TOKEN = env_token
        SHOPIFY_SHOP = env_shop.replace('https://','').replace('http://','').replace('.myshopify.com','').strip('/')
        return True
    tf = "shopify_token.json"
    if os.path.exists(tf):
        with open(tf, 'r') as f:
            d = json.load(f)
            SHOPIFY_ACCESS_TOKEN = d.get('access_token', '')
            s = d.get('shop', '')
            if s: SHOPIFY_SHOP = s.replace('https://','').replace('http://','').replace('.myshopify.com','').strip('/')
            return True
    return False


def get_shopify_headers():
    return {'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN, 'Content-Type': 'application/json'}


def shopify_api_url(endpoint):
    return f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/{endpoint}"


def normalize_sku(sku):
    if not sku: return ""
    return sku.strip().lower()


def calculate_selling_price(cost, weight):
    if not cost or cost <= 0: return 0
    return round((cost + (weight * 1250 if weight else 0)) / 0.7)


def clean_html_for_translation(html_text):
    if not html_text: return ""
    text = html_text
    text = re.sub(r'<style[^>]*>.*?</style>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'<script[^>]*>.*?</script>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'#[\w-]+\s*\{[^}]*\}', '', text, flags=re.DOTALL)
    text = re.sub(r'\.[\w-]+\s*\{[^}]*\}', '', text, flags=re.DOTALL)
    text = re.sub(r'@media[^{]*\{[^}]*\}', '', text, flags=re.DOTALL)
    text = re.sub(r'\s*style\s*=\s*["\'][^"\']*["\']', '', text, flags=re.IGNORECASE)
    text = re.sub(r'<br\s*/?>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'</p>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'</div>', '\n', text, flags=re.IGNORECASE)
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'\n\s*\n', '\n\n', text)
    text = re.sub(r'[ \t]+', ' ', text)
    return text.strip()


def translate_with_chatgpt(title, description, retry=False):
    clean_description = clean_html_for_translation(description)
    prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚è«‹å°‡ä»¥ä¸‹æ—¥æœ¬ç”œé»å•†å“è³‡è¨Šç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼Œä¸¦å„ªåŒ– SEOã€‚

å•†å“åç¨±ï¼ˆæ—¥æ–‡ï¼‰ï¼š{title}
å•†å“èªªæ˜ï¼ˆæ—¥æ–‡ï¼‰ï¼š{clean_description[:1500]}

è«‹å›å‚³ JSON æ ¼å¼ï¼ˆä¸è¦åŠ  markdown æ¨™è¨˜ï¼‰ï¼š
{{"title":"ç¿»è­¯å¾Œçš„å•†å“åç¨±ï¼ˆå‰é¢åŠ ä¸Š YOKUMOKUï¼‰","description":"ç¿»è­¯å¾Œçš„å•†å“èªªæ˜ï¼ˆHTMLï¼‰","page_title":"SEOæ¨™é¡Œ50-60å­—","meta_description":"SEOæè¿°100å­—å…§"}}

è¦å‰‡ï¼š1.YOKUMOKUé«˜ç´šæ´‹è“å­ 2.é–‹é ­ã€ŒYOKUMOKUã€3.ã‚·ã‚¬ãƒ¼ãƒ«â†’é›ªèŒ„è›‹æ²ï¼ˆéé¦™è¸è›‹æ²ï¼‰4.ç¦æ—¥æ–‡ 5.åªå›å‚³JSON"""
    if retry:
        prompt += "\n\nã€åš´é‡è­¦å‘Šã€‘ä¸Šæ¬¡ç¿»è­¯çµæœä»ç„¶åŒ…å«æ—¥æ–‡å­—å…ƒï¼ˆå¹³å‡å/ç‰‡å‡åï¼‰ï¼é€™æ¬¡ä½ å¿…é ˆï¼š\n1. å°‡æ‰€æœ‰æ—¥æ–‡å¹³å‡åã€ç‰‡å‡åå®Œå…¨ç¿»è­¯æˆç¹é«”ä¸­æ–‡\n2. ã‚·ã‚¬ãƒ¼ãƒ«â†’é›ªèŒ„è›‹æ²ã€ã‚µãƒ³ã‚¯ãƒ‡ãƒªã‚¹â†’äº”å‘³ç²¾é¸ã€ãƒ“ã‚¨â†’è–„é¤…ã€ã‚·ãƒ§ã‚³ãƒ©â†’å·§å…‹åŠ›ã€ãƒ©ãƒ³ã‚°ãƒ‰ã‚·ãƒ£ãƒ¼â†’è²“èˆŒé¤…ä¹¾ã€ã‚ªãƒ¬â†’ç‰›å¥¶ã€è©°åˆã›â†’ç¶œåˆç¦®ç›’\n3. çµ•å°ä¸å¯ä»¥å‡ºç¾ä»»ä½• ã²ã‚‰ãŒãª æˆ– ã‚«ã‚¿ã‚«ãƒŠ\n4. å•†å“åä¸­çš„æ—¥æ–‡å¿…é ˆå…¨éƒ¨æ„è­¯æˆä¸­æ–‡"
    try:
        r = requests.post("https://api.openai.com/v1/chat/completions",
            headers={"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"},
            json={"model": "gpt-4o-mini", "messages": [
                {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„æ—¥æœ¬å•†å“ç¿»è­¯å’Œ SEO å°ˆå®¶ã€‚ä½ çš„è¼¸å‡ºå¿…é ˆå®Œå…¨ä½¿ç”¨ç¹é«”ä¸­æ–‡å’Œè‹±æ–‡ï¼Œçµ•å°ç¦æ­¢å‡ºç¾ä»»ä½•æ—¥æ–‡å­—å…ƒã€‚"},
                {"role": "user", "content": prompt}], "temperature": 0, "max_tokens": 1000}, timeout=60)
        if r.status_code == 200:
            c = r.json()['choices'][0]['message']['content'].strip()
            if c.startswith('```'): c = c.split('\n', 1)[1]
            if c.endswith('```'): c = c.rsplit('```', 1)[0]
            t = json.loads(c.strip())
            tt = t.get('title', title)
            if not tt.startswith('YOKUMOKU'): tt = f"YOKUMOKU {tt}"
            return {'success': True, 'title': tt, 'description': t.get('description', description),
                    'page_title': t.get('page_title', ''), 'meta_description': t.get('meta_description', '')}
        else:
            return {'success': False, 'error': f"HTTP {r.status_code}: {r.text[:200]}",
                    'title': f"YOKUMOKU {title}", 'description': description, 'page_title': '', 'meta_description': ''}
    except Exception as e:
        return {'success': False, 'error': str(e),
                'title': f"YOKUMOKU {title}", 'description': description, 'page_title': '', 'meta_description': ''}


def download_image_to_base64(img_url, max_retries=3):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
               'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8', 'Referer': 'https://www.yokumoku.jp/'}
    for attempt in range(max_retries):
        try:
            r = requests.get(img_url, headers=headers, timeout=30)
            if r.status_code == 200:
                ct = r.headers.get('Content-Type', 'image/jpeg')
                fmt = 'image/png' if 'png' in ct else 'image/gif' if 'gif' in ct else 'image/webp' if 'webp' in ct else 'image/jpeg'
                return {'success': True, 'base64': base64.b64encode(r.content).decode('utf-8'), 'content_type': fmt}
        except Exception as e:
            print(f"[åœ–ç‰‡ä¸‹è¼‰] ç¬¬ {attempt+1} æ¬¡ç•°å¸¸: {e}")
        time.sleep(1)
    return {'success': False}


# ========== Shopify å·¥å…·å‡½æ•¸ ==========

def get_existing_products_map():
    pm = {}
    url = shopify_api_url("products.json?limit=250")
    while url:
        r = requests.get(url, headers=get_shopify_headers())
        if r.status_code != 200: break
        for p in r.json().get('products', []):
            pid = p.get('id')
            for v in p.get('variants', []):
                sk = v.get('sku')
                if sk and pid:
                    n = normalize_sku(sk)
                    pm[n] = pid
                    if sk != n: pm[sk] = pid
        lh = r.headers.get('Link', '')
        m = re.search(r'<([^>]+)>; rel="next"', lh)
        url = m.group(1) if m and 'rel="next"' in lh else None
    return pm


def get_collection_products_map(collection_id):
    pm = {}
    if not collection_id: return pm
    url = shopify_api_url(f"collections/{collection_id}/products.json?limit=250")
    while url:
        r = requests.get(url, headers=get_shopify_headers())
        if r.status_code != 200: break
        for p in r.json().get('products', []):
            pid = p.get('id')
            for v in p.get('variants', []):
                sk = v.get('sku')
                if sk and pid: pm[normalize_sku(sk)] = pid
        lh = r.headers.get('Link', '')
        m = re.search(r'<([^>]+)>; rel="next"', lh)
        url = m.group(1) if m and 'rel="next"' in lh else None
    return pm


def delete_product(pid):
    return requests.delete(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers()).status_code == 200


def update_product(pid, data):
    r = requests.put(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers(),
        json={"product": {"id": pid, **data}})
    return r.status_code == 200, r


def get_or_create_collection(ct="YOKUMOKU"):
    r = requests.get(shopify_api_url(f'custom_collections.json?title={ct}'), headers=get_shopify_headers())
    if r.status_code == 200:
        for c in r.json().get('custom_collections', []):
            if c['title'] == ct: return c['id']
    r = requests.post(shopify_api_url('custom_collections.json'), headers=get_shopify_headers(),
        json={'custom_collection': {'title': ct, 'published': True}})
    if r.status_code == 201: return r.json()['custom_collection']['id']
    return None


def add_product_to_collection(pid, cid):
    return requests.post(shopify_api_url('collects.json'), headers=get_shopify_headers(),
        json={'collect': {'product_id': pid, 'collection_id': cid}}).status_code == 201


def publish_to_all_channels(pid):
    gu = f"https://{SHOPIFY_SHOP}.myshopify.com/admin/api/2024-01/graphql.json"
    hd = {'X-Shopify-Access-Token': SHOPIFY_ACCESS_TOKEN, 'Content-Type': 'application/json'}
    r = requests.post(gu, headers=hd, json={'query': '{ publications(first:20){ edges{ node{ id name }}}}'})
    if r.status_code != 200: return False
    pubs = r.json().get('data', {}).get('publications', {}).get('edges', [])
    seen = set(); uq = []
    for p in pubs:
        if p['node']['name'] not in seen: seen.add(p['node']['name']); uq.append(p['node'])
    mut = """mutation publishablePublish($id:ID!,$input:[PublicationInput!]!){publishablePublish(id:$id,input:$input){userErrors{field message}}}"""
    requests.post(gu, headers=hd, json={'query': mut, 'variables': {"id": f"gid://shopify/Product/{pid}", "input": [{"publicationId": p['id']} for p in uq]}})
    return True


def parse_size_weight(text):
    text = text.replace('Ã—', 'x').replace('ï¼¸', 'x').replace('ï½˜', 'x')
    text = text.replace('ï½ï½', 'mm').replace('ï½‡', 'g').replace('ï½‹ï½‡', 'kg')
    text = text.replace('Î¦', 'x').replace(',', '')
    dimension = None; weight_kg = None
    for pat in [r'(\d+(?:\.\d+)?)\s*[xX]\s*(\d+(?:\.\d+)?)\s*[xX]\s*(\d+(?:\.\d+)?)\s*mm',
                r'(\d+)\s*[xX]\s*(\d+)\s*[xX]\s*(\d+)']:
        dm = re.search(pat, text, re.IGNORECASE)
        if dm:
            l, w, h = float(dm.group(1)), float(dm.group(2)), float(dm.group(3))
            dimension = {"l": l, "w": w, "h": h, "volume_weight": round((l*w*h)/6000000, 2)}
            break
    if not dimension:
        cm = re.search(r'(\d+(?:\.\d+)?)\s*[xX]\s*(\d+(?:\.\d+)?)\s*mm', text, re.IGNORECASE)
        if cm:
            d, h = float(cm.group(1)), float(cm.group(2))
            vol = math.pi * (d/2)**2 * h
            dimension = {"diameter": d, "height": h, "volume_weight": round(vol/6000000, 2)}
    wm = re.search(r'(\d+(?:\.\d+)?)\s*kg', text, re.IGNORECASE)
    gm = re.search(r'(\d+(?:\.\d+)?)\s*g(?![\w])', text)
    if wm: weight_kg = float(wm.group(1))
    elif gm: weight_kg = float(gm.group(1)) / 1000
    final = 0
    if dimension and weight_kg: final = max(dimension.get('volume_weight', 0), weight_kg)
    elif dimension: final = dimension.get('volume_weight', 0)
    elif weight_kg: final = weight_kg
    return {"dimension": dimension, "actual_weight": weight_kg, "final_weight": round(final, 2)}


# ========== Playwright çˆ¬èŸ² ==========

def scrape_product_list():
    products = []
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        page = context.new_page()
        print("[INFO] æ­£åœ¨è¼‰å…¥å•†å“åˆ—è¡¨é é¢...")
        page.goto(SEARCH_URL, wait_until='networkidle', timeout=60000)
        time.sleep(3)
        last_height = 0; scroll_attempts = 0
        while scroll_attempts < 50:
            page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
            time.sleep(1.5)
            new_height = page.evaluate('document.body.scrollHeight')
            if new_height == last_height:
                scroll_attempts += 1
                if scroll_attempts >= 3: break
            else: scroll_attempts = 0
            last_height = new_height
            current_count = len(page.query_selector_all('a[href*="/products/"]'))
            print(f"[é€²åº¦] å·²è¼‰å…¥ç´„ {current_count // 2} å€‹å•†å“...")
        all_links = page.query_selector_all('a[href*="/products/"]')
        seen_skus = set()
        for link in all_links:
            try:
                href = link.get_attribute('href')
                if not href or '/products/' not in href: continue
                sku_match = re.search(r'/products/([a-f0-9]+)/', href)
                if not sku_match: continue
                sku = sku_match.group(1)
                if sku in seen_skus: continue
                seen_skus.add(sku)
                is_frozen = False
                try:
                    card = link.evaluate_handle('el => el.closest(".p-product-list__item") || el.closest("article") || el.closest("div")')
                    card_html = card.evaluate('el => el.innerHTML')
                    if 'å†·å‡' in card_html: is_frozen = True
                except: pass
                if is_frozen:
                    print(f"[è·³é] å†·å‡å•†å“: {sku}"); continue
                products.append({'url': urljoin(BASE_URL, href), 'sku': sku})
            except: continue
        browser.close()
    print(f"[INFO] å…±æ”¶é›† {len(products)} å€‹å•†å“")
    return products


def check_product_in_stock(url):
    """v2.2: å¿«é€Ÿæª¢æŸ¥å•†å“åº«å­˜ç‹€æ…‹ï¼ˆä¸æŠ“å®Œæ•´è©³æƒ…ï¼‰"""
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            context = browser.new_context(user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
            page = context.new_page()
            page.goto(url, wait_until='networkidle', timeout=30000)
            time.sleep(2)
            oos_btn = page.query_selector('button.oos') or page.query_selector('.oos')
            in_stock = True
            if oos_btn:
                oos_text = oos_btn.inner_text()
                if 'å“åˆ‡ã‚Œ' in oos_text or 'åœ¨åº«ãªã—' in oos_text:
                    in_stock = False
            # ä¹Ÿæª¢æŸ¥é é¢æ–‡å­—
            if in_stock:
                pt = page.inner_text('body')
                if any(k in pt for k in ['å“åˆ‡ã‚Œ', 'åœ¨åº«ãŒã‚ã‚Šã¾ã›ã‚“', 'åœ¨åº«åˆ‡ã‚Œ', 'SOLD OUT', 'å£²ã‚Šåˆ‡ã‚Œ', 'å®Œå£²', 'è²©å£²çµ‚äº†']):
                    in_stock = False
            browser.close()
            return in_stock
    except Exception as e:
        print(f"[åº«å­˜æª¢æŸ¥éŒ¯èª¤] {url}: {e}")
        return True  # éŒ¯èª¤æ™‚é è¨­æœ‰åº«å­˜ï¼Œé¿å…èª¤åˆª


def scrape_product_detail(url):
    product = {'url': url, 'title': '', 'subtitle': '', 'price': 0, 'description': '',
               'size_weight_text': '', 'weight': 0, 'images': [], 'in_stock': True, 'is_frozen': False, 'sku': ''}
    sku_match = re.search(r'/products/([a-f0-9]+)/', url)
    if sku_match: product['sku'] = sku_match.group(1)
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                                      viewport={'width': 1920, 'height': 1080})
        page = context.new_page()
        try:
            page.goto(url, wait_until='networkidle', timeout=60000)
            try: page.wait_for_selector('.p-details', timeout=10000)
            except: pass
            time.sleep(5)
            page.evaluate('window.scrollTo(0, document.body.scrollHeight / 2)')
            time.sleep(1)
            page.evaluate('window.scrollTo(0, 0)')
            time.sleep(1)
            oos_btn = page.query_selector('button.oos') or page.query_selector('.oos')
            if oos_btn:
                oos_text = oos_btn.inner_text()
                if 'å“åˆ‡ã‚Œ' in oos_text or 'åœ¨åº«ãªã—' in oos_text: product['in_stock'] = False
            # === v2.2: æ“´å……ç¼ºè²¨åµæ¸¬ ===
            if product['in_stock']:
                pt = page.inner_text('body')
                if any(k in pt for k in ['å“åˆ‡ã‚Œ', 'åœ¨åº«ãŒã‚ã‚Šã¾ã›ã‚“', 'åœ¨åº«åˆ‡ã‚Œ', 'SOLD OUT', 'å£²ã‚Šåˆ‡ã‚Œ', 'å®Œå£²', 'è²©å£²çµ‚äº†']):
                    product['in_stock'] = False
            for sel in ['h1.h3.u-weight-bold', 'h1.u-weight-bold', '.p-details__title h1', '.p-details h1', 'h1']:
                el = page.query_selector(sel)
                if el:
                    t = el.inner_text().strip()
                    if t and len(t) > 2: product['title'] = t; break
            for sel in ['p.u-color-gray', '.p-details__subtitle', '.u-color-gray']:
                el = page.query_selector(sel)
                if el:
                    t = el.inner_text().strip()
                    if t and len(t) > 2: product['subtitle'] = t; break
            for sel in ['.p-price__price', '.p-price', '[class*="price"]', '.price']:
                el = page.query_selector(sel)
                if el:
                    pm = re.search(r'([\d,]+)', el.inner_text().replace('Â¥', '').replace('ï¿¥', ''))
                    if pm: product['price'] = int(pm.group(1).replace(',', '')); break
            for sel in ['.p-details__description', '.description', '[class*="description"]']:
                el = page.query_selector(sel)
                if el: product['description'] = el.inner_html(); break
            for dd in page.query_selector_all('dd'):
                text = dd.inner_text()
                has_size = (re.search(r'\d+\s*[Ã—xXÎ¦]\s*\d+\s*[Ã—xX]\s*\d+', text) or
                            re.search(r'\d+\s*Î¦\s*[Ã—xX]\s*\d+', text) or
                            re.search(r'\d+\s*[Ã—xX]\s*\d+(?:\.\d+)?\s*mm', text))
                has_weight = re.search(r'\d+(?:,\d+)?\s*[gG]', text)
                if has_size or has_weight:
                    product['size_weight_text'] = text
                    wi = parse_size_weight(text)
                    product['weight'] = wi['final_weight']; break
            if not product['weight']:
                page_text = page.inner_text('body')
                wm = re.search(r'(\d+(?:,\d+)?)\s*[gG](?![\w])', page_text)
                if wm: product['weight'] = round(float(wm.group(1).replace(',', '')) / 1000, 2)
            if product['weight'] == 0: product['weight'] = 0.5
            images = []
            skip_patterns = ['dummy_product_thumbnail', 'play_button', 'details/caution/', 'about_clack', 'about_shopper', 'data:image/png;base64']
            try:
                for _ in range(3):
                    nb = page.query_selector('.slick-next')
                    if nb: nb.click(); time.sleep(0.3)
            except: pass
            tc = page.query_selector('.p-details__thumbnails')
            if tc:
                for img in tc.query_selector_all('img'):
                    src = img.get_attribute('data-src') or img.get_attribute('src')
                    if not src or any(pat in src for pat in skip_patterns): continue
                    src = re.sub(r'/ex/[\d.]+/[\d.]+/', '/full/', src)
                    src = re.sub(r'/ex/[\d.]+/', '/full/', src)
                    if src.startswith('//'): src = 'https:' + src
                    elif not src.startswith('http'): src = urljoin(BASE_URL, src)
                    if src not in images: images.append(src)
            if len(images) < 3:
                sc = page.query_selector('.p-details__mainimage')
                if sc:
                    for img in sc.query_selector_all('.slick-slide:not(.slick-cloned) img'):
                        src = img.get_attribute('data-src') or img.get_attribute('src')
                        if not src or any(pat in src for pat in skip_patterns): continue
                        src = re.sub(r'/ex/[\d.]+/', '/full/', src)
                        if src.startswith('//'): src = 'https:' + src
                        elif not src.startswith('http'): src = urljoin(BASE_URL, src)
                        if src not in images: images.append(src)
            if len(images) < 3:
                for img in page.query_selector_all('img[src*="cloudfront.net/full/goods/"], img[data-src*="cloudfront.net/full/goods/"]'):
                    src = img.get_attribute('data-src') or img.get_attribute('src')
                    if src and src not in images:
                        if src.startswith('//'): src = 'https:' + src
                        images.append(src)
            if not images:
                og = page.query_selector('meta[property="og:image"]')
                if og:
                    src = og.get_attribute('content')
                    if src: images.append(src)
            product['images'] = images[:10]
        except Exception as e:
            print(f"[ERROR] çˆ¬å–å•†å“è©³ç´°å¤±æ•—: {e}")
        finally:
            browser.close()
    return product


def upload_to_shopify(product, collection_id=None):
    original_title = product['title']
    if product.get('subtitle'): original_title = f"{product['title']} - {product['subtitle']}"
    translated = translate_with_chatgpt(original_title, product.get('description', ''))
    if not translated['success']:
        return {'success': False, 'error': 'translation_failed', 'translated': translated}
    if is_japanese_text(translated['title']):
        print(f"[ç¿»è­¯é©—è­‰] æ¨™é¡Œä»å«æ—¥æ–‡ï¼Œé‡è©¦åŠ å¼·ç¿»è­¯: {translated['title']}")
        retry_result = translate_with_chatgpt(original_title, product.get('description', ''), retry=True)
        if retry_result['success'] and not is_japanese_text(retry_result['title']):
            translated = retry_result
            print(f"[ç¿»è­¯é©—è­‰] é‡è©¦æˆåŠŸ: {translated['title']}")
        else:
            print(f"[ç¿»è­¯é©—è­‰] é‡è©¦ä»å«æ—¥æ–‡ï¼Œè¦–ç‚ºå¤±æ•—")
            return {'success': False, 'error': 'translation_failed', 'translated': translated}
    cost = product['price']; weight = product.get('weight', 0)
    selling_price = calculate_selling_price(cost, weight)
    images_b64 = []
    for idx, iu in enumerate(product.get('images', [])):
        if not iu or not iu.startswith('http'): continue
        result = download_image_to_base64(iu)
        if result['success']:
            images_b64.append({'attachment': result['base64'], 'position': idx+1,
                               'filename': f"yokumoku_{product['sku']}_{idx+1}.jpg"})
        time.sleep(0.5)
    sp = {'product': {
        'title': translated['title'], 'body_html': translated['description'],
        'vendor': 'YOKUMOKU', 'product_type': 'ã‚¯ãƒƒã‚­ãƒ¼ãƒ»æ´‹è“å­',
        'status': 'active', 'published': True,
        'variants': [{'sku': product['sku'], 'price': f"{selling_price:.2f}", 'weight': weight,
                      'weight_unit': 'kg', 'inventory_management': None, 'inventory_policy': 'continue', 'requires_shipping': True}],
        'images': images_b64,
        'tags': 'YOKUMOKU, ãƒ¨ãƒƒã‚¯ãƒ¢ãƒƒã‚¯, æ—¥æœ¬, æ´‹è“å­, ã‚¯ãƒƒã‚­ãƒ¼, ã‚·ã‚¬ãƒ¼ãƒ«, ä¼´æ‰‹ç¦®, æ—¥æœ¬ä»£è³¼, é›ªèŒ„è›‹æ²',
        'metafields_global_title_tag': translated['page_title'],
        'metafields_global_description_tag': translated['meta_description'],
        'metafields': [{'namespace': 'custom', 'key': 'link', 'value': product['url'], 'type': 'url'}]
    }}
    r = requests.post(shopify_api_url('products.json'), headers=get_shopify_headers(), json=sp)
    if r.status_code == 201:
        cp = r.json()['product']; pid = cp['id']; vid = cp['variants'][0]['id']
        requests.put(shopify_api_url(f'variants/{vid}.json'), headers=get_shopify_headers(),
            json={'variant': {'id': vid, 'cost': f"{cost:.2f}"}})
        if collection_id: add_product_to_collection(pid, collection_id)
        publish_to_all_channels(pid)
        return {'success': True, 'product': cp, 'translated': translated, 'selling_price': selling_price, 'cost': cost}
    return {'success': False, 'error': r.text}


def run_scrape():
    global scrape_status
    try:
        scrape_status.update({"running": True, "progress": 0, "total": 0, "current_product": "",
            "products": [], "errors": [], "uploaded": 0, "skipped": 0,
            "skipped_frozen": 0, "skipped_oos": 0, "skipped_exists": 0,
            "skipped_low_price": 0, "filtered_by_price": 0,
            "out_of_stock": 0, "deleted": 0,
            "translation_failed": 0, "translation_stopped": False})

        scrape_status['current_product'] = "æª¢æŸ¥ Shopify å·²æœ‰å•†å“..."
        all_pm = get_existing_products_map()
        existing_skus = set(all_pm.keys())

        scrape_status['current_product'] = "è¨­å®š Collection..."
        collection_id = get_or_create_collection("YOKUMOKU")

        scrape_status['current_product'] = "å–å¾— Collection å•†å“..."
        cpm = get_collection_products_map(collection_id)
        collection_skus = set(cpm.keys())

        scrape_status['current_product'] = "çˆ¬å–å•†å“åˆ—è¡¨ï¼ˆéœ€è¦æ™‚é–“ï¼‰..."
        product_list = scrape_product_list()
        scrape_status['total'] = len(product_list)

        website_skus = set(item['sku'] for item in product_list)
        # === v2.2: è¨˜éŒ„ç¼ºè²¨çš„ SKU ===
        out_of_stock_skus = set()
        ctf = 0

        for idx, item in enumerate(product_list):
            scrape_status['progress'] = idx + 1
            scrape_status['current_product'] = f"è™•ç†: {item['sku']}"

            if item['sku'] in existing_skus:
                # === v2.2: å·²ä¸Šæ¶å•†å“æª¢æŸ¥åº«å­˜ ===
                if item['sku'] in collection_skus:
                    if not check_product_in_stock(item['url']):
                        out_of_stock_skus.add(item['sku'])
                        scrape_status['out_of_stock'] += 1
                    time.sleep(0.5)
                scrape_status['skipped_exists'] += 1
                scrape_status['skipped'] += 1
                continue

            product = scrape_product_detail(item['url'])

            if product.get('is_frozen'):
                scrape_status['skipped_frozen'] += 1
                scrape_status['skipped'] += 1; continue

            # === v2.2: ç¼ºè²¨ â†’ è¨˜éŒ„ SKUï¼Œä¸ä¸Šæ¶ ===
            if not product.get('in_stock', True):
                out_of_stock_skus.add(item['sku'])
                scrape_status['skipped_oos'] += 1
                scrape_status['out_of_stock'] += 1
                continue

            if product.get('price', 0) < MIN_PRICE:
                scrape_status['skipped_low_price'] += 1
                scrape_status['filtered_by_price'] += 1
                scrape_status['skipped'] += 1; continue

            if not product.get('title') or not product.get('price'):
                scrape_status['errors'].append({'sku': item['sku'], 'error': 'è³‡è¨Šä¸å®Œæ•´'}); continue

            result = upload_to_shopify(product, collection_id)
            if result['success']:
                existing_skus.add(product['sku'])
                scrape_status['uploaded'] += 1
                scrape_status['products'].append({
                    'sku': product['sku'], 'title': result.get('translated', {}).get('title', product['title']),
                    'price': product['price'], 'selling_price': result.get('selling_price', 0),
                    'weight': product['weight'], 'status': 'success'})
                ctf = 0
            elif result.get('error') == 'translation_failed':
                scrape_status['translation_failed'] += 1; ctf += 1
                scrape_status['errors'].append({'sku': product['sku'], 'error': 'ç¿»è­¯å¤±æ•—'})
                if ctf >= MAX_CONSECUTIVE_TRANSLATION_FAILURES:
                    scrape_status['translation_stopped'] = True
                    scrape_status['errors'].append({'error': f'ç¿»è­¯é€£çºŒå¤±æ•— {ctf} æ¬¡ï¼Œè‡ªå‹•åœæ­¢'}); break
            else:
                scrape_status['errors'].append({'sku': product['sku'], 'error': result.get('error', '')}); ctf = 0
            time.sleep(1)

        # === v2.2: åˆä½µéœ€è¦åˆªé™¤çš„ SKU ===
        if not scrape_status['translation_stopped']:
            scrape_status['current_product'] = "æ¸…ç†ç¼ºè²¨/ä¸‹æ¶å•†å“..."
            skus_to_delete = (collection_skus - website_skus) | (collection_skus & out_of_stock_skus)
            if skus_to_delete:
                print(f"[v2.2] æº–å‚™åˆªé™¤ {len(skus_to_delete)} å€‹å•†å“")
                for sku in skus_to_delete:
                    scrape_status['current_product'] = f"åˆªé™¤: {sku}"
                    pid = cpm.get(sku)
                    if pid:
                        if delete_product(pid):
                            scrape_status['deleted'] += 1
                            print(f"[å·²åˆªé™¤] SKU: {sku}, Product ID: {pid}")
                        else:
                            scrape_status['errors'].append({'sku': sku, 'error': 'åˆªé™¤å¤±æ•—'})
                    time.sleep(0.3)

        scrape_status['current_product'] = "å®Œæˆï¼" if not scrape_status['translation_stopped'] else "ç¿»è­¯ç•°å¸¸åœæ­¢"
    except Exception as e:
        scrape_status['errors'].append({'error': str(e)})
    finally:
        scrape_status['running'] = False


# ========== Flask è·¯ç”± ==========

@app.route('/')
def index():
    token_loaded = load_shopify_token()
    tc = 'green' if token_loaded else 'red'
    ts = 'âœ“ å·²è¼‰å…¥' if token_loaded else 'âœ— æœªè¨­å®š'
    html = """<!DOCTYPE html>
<html lang="zh-TW">
<head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>YOKUMOKU çˆ¬èŸ²å·¥å…·</title>
<style>*{box-sizing:border-box}body{font-family:-apple-system,sans-serif;max-width:900px;margin:0 auto;padding:20px;background:#f5f5f5}h1{color:#333;border-bottom:2px solid #1a1a2e;padding-bottom:10px}.card{background:white;border-radius:8px;padding:20px;margin-bottom:20px;box-shadow:0 2px 4px rgba(0,0,0,0.1)}.btn{background:#e94560;color:white;border:none;padding:12px 24px;border-radius:5px;cursor:pointer;font-size:16px;margin-right:10px;margin-bottom:10px;text-decoration:none;display:inline-block}.btn:hover{background:#c2185b}.btn:disabled{background:#ccc}.btn-secondary{background:#3498db}.btn-success{background:#27ae60}.progress-bar{width:100%;height:20px;background:#eee;border-radius:10px;overflow:hidden;margin:10px 0}.progress-fill{height:100%;background:linear-gradient(90deg,#e94560,#ff6b6b);transition:width 0.3s}.status{padding:10px;background:#f8f9fa;border-radius:5px;margin-top:10px}.log{max-height:300px;overflow-y:auto;font-family:monospace;font-size:13px;background:#1e1e1e;color:#d4d4d4;padding:15px;border-radius:5px}.stats{display:flex;gap:15px;margin-top:15px;flex-wrap:wrap}.stat{flex:1;min-width:70px;text-align:center;padding:15px;background:#f8f9fa;border-radius:5px}.stat-number{font-size:24px;font-weight:bold;color:#e94560}.stat-label{font-size:10px;color:#666;margin-top:5px}.nav{margin-bottom:20px}.nav a{margin-right:15px;color:#e94560;text-decoration:none;font-weight:bold}.alert{padding:12px 16px;border-radius:5px;margin-bottom:15px}.alert-danger{background:#fee;border:1px solid #fcc;color:#c0392b}.formula{background:#1a1a2e;color:#4ade80;padding:15px;border-radius:8px;font-family:monospace;margin:10px 0;font-size:13px}</style></head>
<body>
<div class="nav"><a href="/">ğŸ  é¦–é </a><a href="/japanese-scan">ğŸ‡¯ğŸ‡µ æ—¥æ–‡æƒæ</a></div>
<h1>ğŸª YOKUMOKU çˆ¬èŸ²å·¥å…· <small style="font-size:14px;color:#999">v2.2</small></h1>
<div class="card"><h3>Shopify é€£ç·š</h3><p>Token: <span style="color:__TC__;">__TS__</span></p>
<div class="formula">å”®åƒ¹ = (æˆæœ¬åƒ¹ + é‡é‡ Ã— 1250) / 0.7<br>é‡é‡ = max(æç©é‡é‡, å¯¦éš›é‡é‡)</div>
<button class="btn btn-secondary" onclick="testShopify()">æ¸¬è©¦é€£ç·š</button>
<button class="btn btn-secondary" onclick="testTranslate()">æ¸¬è©¦ç¿»è­¯</button>
<a href="/japanese-scan" class="btn btn-success">ğŸ‡¯ğŸ‡µ æ—¥æ–‡æƒæ</a></div>
<div class="card"><h3>é–‹å§‹çˆ¬å–</h3>
<p style="color:#666;font-size:14px">â€» æ’é™¤å†·å‡å•†å“ | &lt;Â¥__MIN_COST__ è·³é | <b style="color:#e74c3c">ç¿»è­¯ä¿è­·</b> é€£çºŒå¤±æ•— __MAX_FAIL__ æ¬¡åœæ­¢ | <b style="color:#e67e22">ç¼ºè²¨è‡ªå‹•åˆªé™¤</b><br>âš ï¸ ä½¿ç”¨ Playwright ç„¡é ­ç€è¦½å™¨ï¼Œå•†å“åˆ—è¡¨è¼‰å…¥éœ€è¦è¼ƒé•·æ™‚é–“</p>
<button class="btn" id="startBtn" onclick="startScrape()">ğŸš€ é–‹å§‹çˆ¬å–</button>
<div id="progressSection" style="display:none">
<div id="translationAlert" class="alert alert-danger" style="display:none">âš ï¸ ç¿»è­¯åŠŸèƒ½ç•°å¸¸ï¼Œå·²è‡ªå‹•åœæ­¢ï¼</div>
<div class="progress-bar"><div class="progress-fill" id="progressFill" style="width:0%"></div></div>
<div class="status" id="statusText">æº–å‚™ä¸­...</div>
<div class="stats">
<div class="stat"><div class="stat-number" id="uploadedCount">0</div><div class="stat-label">å·²ä¸Šæ¶</div></div>
<div class="stat"><div class="stat-number" id="skippedCount">0</div><div class="stat-label">å·²è·³é</div></div>
<div class="stat"><div class="stat-number" id="translationFailedCount" style="color:#e74c3c">0</div><div class="stat-label">ç¿»è­¯å¤±æ•—</div></div>
<div class="stat"><div class="stat-number" id="filteredCount">0</div><div class="stat-label">åƒ¹æ ¼éæ¿¾</div></div>
<div class="stat"><div class="stat-number" id="outOfStockCount">0</div><div class="stat-label">ç„¡åº«å­˜</div></div>
<div class="stat"><div class="stat-number" id="deletedCount" style="color:#e67e22">0</div><div class="stat-label">å·²åˆªé™¤</div></div>
<div class="stat"><div class="stat-number" id="errorCount" style="color:#e74c3c">0</div><div class="stat-label">éŒ¯èª¤</div></div>
</div></div></div>
<div class="card"><h3>åŸ·è¡Œæ—¥èªŒ</h3><div class="log" id="logArea">ç­‰å¾…é–‹å§‹...</div></div>
<script>let pollInterval=null;function log(m,t){const l=document.getElementById('logArea');const tm=new Date().toLocaleTimeString();const c={success:'#4ec9b0',error:'#f14c4c'}[t]||'#d4d4d4';l.innerHTML+='<div style="color:'+c+'">['+tm+'] '+m+'</div>';l.scrollTop=l.scrollHeight}function clearLog(){document.getElementById('logArea').innerHTML=''}async function testShopify(){log('æ¸¬è©¦é€£ç·š...');try{const r=await fetch('/api/test-shopify');const d=await r.json();if(d.success)log('âœ“ '+d.shop.name,'success');else log('âœ— '+d.error,'error')}catch(e){log('âœ— '+e.message,'error')}}async function testTranslate(){log('æ¸¬è©¦ç¿»è­¯...');try{const r=await fetch('/api/test-translate');const d=await r.json();if(d.error)log('âœ— '+d.error,'error');else if(d.success)log('âœ“ '+d.title,'success');else log('âœ— ç¿»è­¯å¤±æ•—','error')}catch(e){log('âœ— '+e.message,'error')}}async function startScrape(){clearLog();log('é–‹å§‹çˆ¬å–...');document.getElementById('startBtn').disabled=true;document.getElementById('progressSection').style.display='block';document.getElementById('translationAlert').style.display='none';try{const r=await fetch('/api/start-scrape',{method:'POST'});const d=await r.json();if(!d.success){log('âœ— '+d.error,'error');document.getElementById('startBtn').disabled=false;return}log('âœ“ å·²å•Ÿå‹•ï¼ˆå•†å“åˆ—è¡¨è¼‰å…¥éœ€è¦æ™‚é–“ï¼‰','success');pollInterval=setInterval(pollStatus,2000)}catch(e){log('âœ— '+e.message,'error');document.getElementById('startBtn').disabled=false}}async function pollStatus(){try{const r=await fetch('/api/status');const d=await r.json();const p=d.total>0?(d.progress/d.total*100):0;document.getElementById('progressFill').style.width=p+'%';document.getElementById('statusText').textContent=d.current_product+' ('+d.progress+'/'+d.total+')';document.getElementById('uploadedCount').textContent=d.uploaded;document.getElementById('skippedCount').textContent=d.skipped;document.getElementById('translationFailedCount').textContent=d.translation_failed||0;document.getElementById('filteredCount').textContent=d.filtered_by_price||0;document.getElementById('outOfStockCount').textContent=d.out_of_stock||0;document.getElementById('deletedCount').textContent=d.deleted||0;document.getElementById('errorCount').textContent=d.errors.length;if(d.translation_stopped)document.getElementById('translationAlert').style.display='block';if(!d.running&&d.progress>0){clearInterval(pollInterval);document.getElementById('startBtn').disabled=false;if(d.translation_stopped)log('âš ï¸ ç¿»è­¯ç•°å¸¸åœæ­¢','error');else log('========== å®Œæˆ ==========','success')}}catch(e){console.error(e)}}</script></body></html>"""
    return html.replace('__TC__', tc).replace('__TS__', ts).replace('__MIN_COST__', str(MIN_PRICE)).replace('__MAX_FAIL__', str(MAX_CONSECUTIVE_TRANSLATION_FAILURES))


@app.route('/japanese-scan')
def japanese_scan_page():
    return '''<!DOCTYPE html>
<html lang="zh-TW">
<head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>æ—¥æ–‡å•†å“æƒæ - YOKUMOKU</title>
<style>*{box-sizing:border-box}body{font-family:-apple-system,sans-serif;max-width:1200px;margin:0 auto;padding:20px;background:#f5f5f5}h1{color:#333;border-bottom:2px solid #27ae60;padding-bottom:10px}.card{background:white;border-radius:8px;padding:20px;margin-bottom:20px;box-shadow:0 2px 4px rgba(0,0,0,0.1)}.btn{background:#e94560;color:white;border:none;padding:10px 20px;border-radius:5px;cursor:pointer;font-size:14px;margin-right:10px;margin-bottom:10px}.btn:disabled{background:#ccc}.btn-danger{background:#e74c3c}.btn-success{background:#27ae60}.btn-sm{padding:5px 10px;font-size:12px}.nav{margin-bottom:20px}.nav a{margin-right:15px;color:#e94560;text-decoration:none;font-weight:bold}.stats{display:flex;gap:15px;margin:20px 0;flex-wrap:wrap}.stat{flex:1;min-width:150px;text-align:center;padding:20px;background:#f8f9fa;border-radius:8px}.stat-number{font-size:36px;font-weight:bold}.stat-label{font-size:14px;color:#666;margin-top:5px}.product-item{display:flex;align-items:center;padding:15px;border-bottom:1px solid #eee;gap:15px}.product-item:last-child{border-bottom:none}.product-item img{width:60px;height:60px;object-fit:cover;border-radius:4px}.product-item .info{flex:1}.product-item .info .title{font-weight:bold;margin-bottom:5px;color:#c0392b}.product-item .info .meta{font-size:12px;color:#666}.no-image{width:60px;height:60px;background:#eee;display:flex;align-items:center;justify-content:center;border-radius:4px;color:#999;font-size:10px}.retranslate-status{font-size:12px;margin-top:5px}.action-bar{position:sticky;top:0;background:white;padding:15px;margin:-20px -20px 20px -20px;border-bottom:1px solid #ddd;z-index:100;display:flex;justify-content:space-between;align-items:center;flex-wrap:wrap;gap:10px}</style></head>
<body>
<div class="nav"><a href="/">ğŸ  é¦–é </a><a href="/japanese-scan">ğŸ‡¯ğŸ‡µ æ—¥æ–‡æƒæ</a></div>
<h1>ğŸ‡¯ğŸ‡µ æ—¥æ–‡å•†å“æƒæ - YOKUMOKU</h1>
<div class="card"><p>æƒæ Shopify ä¸­ YOKUMOKU çš„æ—¥æ–‡ï¼ˆæœªç¿»è­¯ï¼‰å•†å“ã€‚</p><button class="btn" id="scanBtn" onclick="startScan()">ğŸ” é–‹å§‹æƒæ</button><span id="scanStatus"></span></div>
<div class="stats" id="statsSection" style="display:none"><div class="stat"><div class="stat-number" id="totalProducts" style="color:#3498db">0</div><div class="stat-label">YOKUMOKU å•†å“æ•¸</div></div><div class="stat"><div class="stat-number" id="japaneseCount" style="color:#e74c3c">0</div><div class="stat-label">æ—¥æ–‡å•†å“</div></div></div>
<div class="card" id="resultsCard" style="display:none"><div class="action-bar"><div><button class="btn btn-success" id="retranslateAllBtn" onclick="retranslateAll()" disabled>ğŸ”„ å…¨éƒ¨ç¿»è­¯</button><button class="btn btn-danger" id="deleteAllBtn" onclick="deleteAllJP()" disabled>ğŸ—‘ï¸ å…¨éƒ¨åˆªé™¤</button></div><div id="progressText"></div></div><div id="results"></div></div>
<script>let jp=[];async function startScan(){document.getElementById('scanBtn').disabled=true;document.getElementById('scanStatus').textContent='æƒæä¸­...';try{const r=await fetch('/api/scan-japanese');const d=await r.json();if(d.error){alert(d.error);return}jp=d.japanese_products;document.getElementById('totalProducts').textContent=d.total_products;document.getElementById('japaneseCount').textContent=d.japanese_count;document.getElementById('statsSection').style.display='flex';renderResults(d.japanese_products);document.getElementById('resultsCard').style.display='block';document.getElementById('retranslateAllBtn').disabled=jp.length===0;document.getElementById('deleteAllBtn').disabled=jp.length===0;document.getElementById('scanStatus').textContent='å®Œæˆï¼'}catch(e){alert(e.message)}finally{document.getElementById('scanBtn').disabled=false}}function renderResults(p){const c=document.getElementById('results');if(!p.length){c.innerHTML='<p style="text-align:center;color:#27ae60;font-size:18px">âœ… æ²’æœ‰æ—¥æ–‡å•†å“</p>';return}let h='';p.forEach(i=>{const img=i.image?`<img src="${i.image}">`:`<div class="no-image">ç„¡åœ–</div>`;h+=`<div class="product-item" id="product-${i.id}">${img}<div class="info"><div class="title">${i.title}</div><div class="meta">SKU:${i.sku||'ç„¡'}|Â¥${i.price}|${i.status}</div><div class="retranslate-status" id="status-${i.id}"></div></div><div class="actions"><button class="btn btn-success btn-sm" onclick="rt1('${i.id}')" id="rt-${i.id}">ğŸ”„</button><button class="btn btn-danger btn-sm" onclick="del1('${i.id}')" id="del-${i.id}">ğŸ—‘ï¸</button></div></div>`});c.innerHTML=h}async function rt1(id){const b=document.getElementById(`rt-${id}`);const s=document.getElementById(`status-${id}`);b.disabled=true;b.textContent='...';try{const r=await fetch('/api/retranslate-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:id})});const d=await r.json();if(d.success){s.innerHTML=`<span style="color:#27ae60">âœ… ${d.new_title}</span>`;const t=document.querySelector(`#product-${id} .title`);if(t){t.textContent=d.new_title;t.style.color='#27ae60'}b.textContent='âœ“'}else{s.innerHTML=`<span style="color:#e74c3c">âŒ ${d.error}</span>`;b.disabled=false;b.textContent='ğŸ”„'}}catch(e){s.innerHTML=`<span style="color:#e74c3c">âŒ ${e.message}</span>`;b.disabled=false;b.textContent='ğŸ”„'}}async function del1(id){if(!confirm('ç¢ºå®šåˆªé™¤ï¼Ÿ'))return;const b=document.getElementById(`del-${id}`);b.disabled=true;try{const r=await fetch('/api/delete-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:id})});const d=await r.json();if(d.success)document.getElementById(`product-${id}`).remove();else{alert('å¤±æ•—');b.disabled=false}}catch(e){alert(e.message);b.disabled=false}}async function retranslateAll(){if(!confirm(`ç¿»è­¯å…¨éƒ¨ ${jp.length} å€‹ï¼Ÿ`))return;const b=document.getElementById('retranslateAllBtn');b.disabled=true;b.textContent='ç¿»è­¯ä¸­...';let s=0,f=0;for(let i=0;i<jp.length;i++){document.getElementById('progressText').textContent=`${i+1}/${jp.length}`;try{const r=await fetch('/api/retranslate-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:jp[i].id})});const d=await r.json();const st=document.getElementById(`status-${jp[i].id}`);if(d.success){s++;if(st)st.innerHTML=`<span style="color:#27ae60">âœ… ${d.new_title}</span>`;const t=document.querySelector(`#product-${jp[i].id} .title`);if(t){t.textContent=d.new_title;t.style.color='#27ae60'}}else{f++;if(st)st.innerHTML=`<span style="color:#e74c3c">âŒ ${d.error}</span>`;if(f>=3){alert('é€£çºŒå¤±æ•—');break}}}catch(e){f++}await new Promise(r=>setTimeout(r,1500))}alert(`æˆåŠŸ:${s} å¤±æ•—:${f}`);b.textContent='ğŸ”„ å…¨éƒ¨ç¿»è­¯';b.disabled=false;document.getElementById('progressText').textContent=''}async function deleteAllJP(){if(!confirm(`åˆªé™¤å…¨éƒ¨ ${jp.length} å€‹ï¼Ÿ`))return;const b=document.getElementById('deleteAllBtn');b.disabled=true;let s=0,f=0;for(let i=0;i<jp.length;i++){document.getElementById('progressText').textContent=`${i+1}/${jp.length}`;try{const r=await fetch('/api/delete-product',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({product_id:jp[i].id})});const d=await r.json();if(d.success){s++;const el=document.getElementById(`product-${jp[i].id}`);if(el)el.remove()}else f++}catch(e){f++}await new Promise(r=>setTimeout(r,300))}alert(`æˆåŠŸ:${s} å¤±æ•—:${f}`);b.textContent='ğŸ—‘ï¸ å…¨éƒ¨åˆªé™¤';b.disabled=false;document.getElementById('progressText').textContent=''}</script></body></html>'''


# ========== API è·¯ç”± ==========

@app.route('/api/scan-japanese')
def api_scan_japanese():
    if not load_shopify_token(): return jsonify({'error': 'æœªè¨­å®š Token'}), 400
    products = []
    url = shopify_api_url("products.json?limit=250&vendor=YOKUMOKU")
    while url:
        r = requests.get(url, headers=get_shopify_headers())
        if r.status_code != 200: break
        for p in r.json().get('products', []):
            sku = ''; price = ''
            for v in p.get('variants', []): sku = v.get('sku', ''); price = v.get('price', ''); break
            products.append({'id': p.get('id'), 'title': p.get('title', ''), 'handle': p.get('handle', ''),
                'sku': sku, 'price': price, 'vendor': p.get('vendor', ''), 'status': p.get('status', ''),
                'created_at': p.get('created_at', ''), 'image': p.get('image', {}).get('src', '') if p.get('image') else ''})
        lh = r.headers.get('Link', '')
        m = re.search(r'<([^>]+)>; rel="next"', lh)
        url = m.group(1) if m and 'rel="next"' in lh else None
    jp = [p for p in products if is_japanese_text(p.get('title', ''))]
    return jsonify({'total_products': len(products), 'japanese_count': len(jp), 'japanese_products': jp})


@app.route('/api/retranslate-product', methods=['POST'])
def api_retranslate_product():
    if not load_shopify_token(): return jsonify({'error': 'æœªè¨­å®š Token'}), 400
    data = request.get_json(); pid = data.get('product_id')
    if not pid: return jsonify({'error': 'ç¼ºå°‘ product_id'}), 400
    resp = requests.get(shopify_api_url(f"products/{pid}.json"), headers=get_shopify_headers())
    if resp.status_code != 200: return jsonify({'error': f'ç„¡æ³•å–å¾—: {resp.status_code}'}), 400
    product = resp.json().get('product', {})
    translated = translate_with_chatgpt(product.get('title', ''), product.get('body_html', ''))
    if not translated['success']:
        return jsonify({'success': False, 'error': f"ç¿»è­¯å¤±æ•—: {translated.get('error', 'æœªçŸ¥')}"})
    if is_japanese_text(translated['title']):
        retry_result = translate_with_chatgpt(product.get('title', ''), product.get('body_html', ''), retry=True)
        if retry_result['success'] and not is_japanese_text(retry_result['title']): translated = retry_result
        else: return jsonify({'success': False, 'error': 'ç¿»è­¯å¾Œä»å«æ—¥æ–‡ï¼Œè«‹æ‰‹å‹•ä¿®æ”¹'})
    ok, r = update_product(pid, {'title': translated['title'], 'body_html': translated['description'],
        'metafields_global_title_tag': translated['page_title'], 'metafields_global_description_tag': translated['meta_description']})
    if ok: return jsonify({'success': True, 'old_title': product.get('title', ''), 'new_title': translated['title'], 'product_id': pid})
    return jsonify({'success': False, 'error': f'æ›´æ–°å¤±æ•—: {r.text[:200]}'})


@app.route('/api/delete-product', methods=['POST'])
def api_delete_product():
    if not load_shopify_token(): return jsonify({'error': 'æœªè¨­å®š Token'}), 400
    data = request.get_json(); pid = data.get('product_id')
    if not pid: return jsonify({'error': 'ç¼ºå°‘ product_id'}), 400
    return jsonify({'success': delete_product(pid), 'product_id': pid})


@app.route('/api/test-translate')
def api_test_translate():
    api_key = os.environ.get("OPENAI_API_KEY", "")
    if not api_key: return jsonify({'error': 'OPENAI_API_KEY æœªè¨­å®š'})
    kp = f"{api_key[:8]}...{api_key[-4:]}" if len(api_key) > 12 else "å¤ªçŸ­"
    result = translate_with_chatgpt("ã€5ç¨® 40å€‹å…¥ã‚Šã€‘ã‚µãƒ³ã‚¯ ãƒ‡ãƒªã‚¹", "ã‚·ã‚¬ãƒ¼ãƒ«ã¨å­£ç¯€é™å®šã‚¯ãƒƒã‚­ãƒ¼ã®è©°ã‚åˆã‚ã›ã§ã™")
    result['key_preview'] = kp; result['key_length'] = len(api_key)
    return jsonify(result)


@app.route('/api/status')
def get_status():
    return jsonify(scrape_status)


@app.route('/api/start-scrape', methods=['POST'])
def start_scrape():
    global scrape_status
    if scrape_status['running']: return jsonify({'success': False, 'error': 'çˆ¬å–æ­£åœ¨é€²è¡Œä¸­'})
    if not load_shopify_token(): return jsonify({'success': False, 'error': 'æœªè¨­å®šç’°å¢ƒè®Šæ•¸'})
    test = translate_with_chatgpt("ãƒ†ã‚¹ãƒˆå•†å“", "ãƒ†ã‚¹ãƒˆèª¬æ˜")
    if not test['success']:
        return jsonify({'success': False, 'error': f"ç¿»è­¯åŠŸèƒ½ç•°å¸¸: {test.get('error', 'æœªçŸ¥')}"})
    threading.Thread(target=run_scrape).start()
    return jsonify({'success': True, 'message': 'é–‹å§‹çˆ¬å–'})


@app.route('/api/start', methods=['POST'])
def cron_trigger():
    global scrape_status
    if scrape_status['running']: return jsonify({'success': False, 'error': 'çˆ¬å–æ­£åœ¨é€²è¡Œä¸­'}), 409
    if not load_shopify_token(): return jsonify({'success': False, 'error': 'æœªè¨­å®šç’°å¢ƒè®Šæ•¸'}), 500
    test = translate_with_chatgpt("ãƒ†ã‚¹ãƒˆå•†å“", "ãƒ†ã‚¹ãƒˆèª¬æ˜")
    if not test['success']:
        return jsonify({'success': False, 'error': f"ç¿»è­¯åŠŸèƒ½ç•°å¸¸: {test.get('error', 'æœªçŸ¥')}"}), 400
    threading.Thread(target=run_scrape).start()
    return jsonify({'success': True, 'message': 'Cron job triggered', 'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')})


@app.route('/api/test-shopify')
def test_shopify():
    if not load_shopify_token(): return jsonify({'success': False, 'error': 'æœªè¨­å®šç’°å¢ƒè®Šæ•¸'})
    r = requests.get(shopify_api_url('shop.json'), headers=get_shopify_headers())
    if r.status_code == 200: return jsonify({'success': True, 'shop': r.json()['shop']})
    return jsonify({'success': False, 'error': r.text}), 400


@app.route('/api/test-scrape')
def test_scrape():
    product = scrape_product_detail("https://www.yokumoku.jp/products/5d70b5f1dbbfdc006fd21f3c/%E3%80%905%E7%A8%AE-40%E5%80%8B%E5%85%A5%E3%82%8A%E3%80%91%E3%82%B5%E3%83%B3%E3%82%AF-%E3%83%87%E3%83%AA%E3%82%B9")
    if product.get('price') and product.get('weight'):
        product['selling_price'] = calculate_selling_price(product['price'], product['weight'])
    return jsonify(product)


if __name__ == '__main__':
    print("=" * 50)
    print("YOKUMOKU çˆ¬èŸ²å·¥å…· v2.2")
    print("æ–°å¢: ç¼ºè²¨å•†å“è‡ªå‹•åˆªé™¤")
    print("=" * 50)
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port, debug=False)
